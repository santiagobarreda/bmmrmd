<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</title>
  <meta name="description" content="Bayesian Models for Repeated Measures" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Bayesian Models for Repeated Measures" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  
  <meta name="twitter:description" content="Bayesian Models for Repeated Measures" />
  

<meta name="author" content="Santiago Bareda and Noah Silbert" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression-and-signal-detection-theory-models.html"/>
<link rel="next" href="multinomial-and-ordinal-regression.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Repeated Measures data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bayesian-multilevel-models-and-repeated-measures-data"><i class="fa fa-check"></i>Bayesian Multilevel models and repeated measures data</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#whats-missing-from-this-book"><i class="fa fa-check"></i>What’s missing from this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#statistics-as-procedural-knowledge"><i class="fa fa-check"></i>Statistics as Procedural knowledge</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practice-vs-brain-power"><i class="fa fa-check"></i>Practice vs brain power</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i>How to use this book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#supplemental-resources"><i class="fa fa-check"></i>Supplemental Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#our-target-audience"><i class="fa fa-check"></i>Our target audience</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-self-starter"><i class="fa fa-check"></i>The self-starter</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-convert"><i class="fa fa-check"></i>The convert</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-instructor"><i class="fa fa-check"></i>The instructor</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-you-need-installed-to-use-this-book"><i class="fa fa-check"></i>What you need installed to use this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-go-bayesian"><i class="fa fa-check"></i>Why go Bayesian?</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-brms"><i class="fa fa-check"></i>Why brms?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#it-takes-a-village-of-books"><i class="fa fa-check"></i>It takes a village (of books)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html"><i class="fa fa-check"></i><b>1</b> Introduction: Experiments and Variables</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#chapter-pre-cap"><i class="fa fa-check"></i><b>1.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-and-effects"><i class="fa fa-check"></i><b>1.2</b> Experiments and effects</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-and-inference"><i class="fa fa-check"></i><b>1.2.1</b> Experiments and inference</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp"><i class="fa fa-check"></i><b>1.3</b> Our experiment</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-intro"><i class="fa fa-check"></i><b>1.3.1</b> Our experiment: Introduction</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-methods"><i class="fa fa-check"></i><b>1.3.2</b> Our experimental methods</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-research-questions"><i class="fa fa-check"></i><b>1.3.3</b> Our research questions</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-data"><i class="fa fa-check"></i><b>1.3.4</b> Our experimental data</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-variables"><i class="fa fa-check"></i><b>1.4</b> Variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-pops-and-samps"><i class="fa fa-check"></i><b>1.4.1</b> Populations and samples</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-dep-and-indep"><i class="fa fa-check"></i><b>1.4.2</b> Dependent and Independent Variables</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-categorical"><i class="fa fa-check"></i><b>1.4.3</b> Categorical variables and ‘factors’</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-quantitative"><i class="fa fa-check"></i><b>1.4.4</b> Quantitative variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-logical"><i class="fa fa-check"></i><b>1.4.5</b> Logical variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting"><i class="fa fa-check"></i><b>1.5</b> Inspecting our data</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-categorical"><i class="fa fa-check"></i><b>1.5.1</b> Inspecting categorical variables</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-quantitative"><i class="fa fa-check"></i><b>1.5.2</b> Inspecting quantitative variables</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-together"><i class="fa fa-check"></i><b>1.5.3</b> Exploring continuous and categorical variables together</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
<li class="chapter" data-level="1.7" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#references"><i class="fa fa-check"></i><b>1.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html"><i class="fa fa-check"></i><b>2</b> Probabilities, likelihood, and inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#chapter-pre-cap-1"><i class="fa fa-check"></i><b>2.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="2.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-data"><i class="fa fa-check"></i><b>2.2</b> Data and research questions</a></li>
<li class="chapter" data-level="2.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-empirical-prob"><i class="fa fa-check"></i><b>2.3</b> Empirical Probabilities</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-conditional"><i class="fa fa-check"></i><b>2.3.1</b> Conditional and marginal probabilities</a></li>
<li class="chapter" data-level="2.3.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-joint"><i class="fa fa-check"></i><b>2.3.2</b> Joint probabilities</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-theoretical"><i class="fa fa-check"></i><b>2.4</b> Probability distributions</a></li>
<li class="chapter" data-level="2.5" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-normal"><i class="fa fa-check"></i><b>2.5</b> The normal distribution</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-sample-mean"><i class="fa fa-check"></i><b>2.5.1</b> The sample mean</a></li>
<li class="chapter" data-level="2.5.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-sample-variance"><i class="fa fa-check"></i><b>2.5.2</b> The sample variance (or standard deviation)</a></li>
<li class="chapter" data-level="2.5.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-normal-density"><i class="fa fa-check"></i><b>2.5.3</b> The normal density</a></li>
<li class="chapter" data-level="2.5.4" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-standard-normal"><i class="fa fa-check"></i><b>2.5.4</b> The standard normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-models-and-inference"><i class="fa fa-check"></i><b>2.6</b> Models and inference</a></li>
<li class="chapter" data-level="2.7" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-likelihoods"><i class="fa fa-check"></i><b>2.7</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-chars-of-likelihoods"><i class="fa fa-check"></i><b>2.7.1</b> Characteristics of likelihoods</a></li>
<li class="chapter" data-level="2.7.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-logarithms"><i class="fa fa-check"></i><b>2.7.2</b> A brief aside on logarithms</a></li>
<li class="chapter" data-level="2.7.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-chars-of-likelihoods-2"><i class="fa fa-check"></i><b>2.7.3</b> Characteristics of likelihoods, continued</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-inference-and-likelihood"><i class="fa fa-check"></i><b>2.8</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.9" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#exercises-1"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
<li class="chapter" data-level="2.10" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#references-1"><i class="fa fa-check"></i><b>2.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html"><i class="fa fa-check"></i><b>3</b> Fitting Bayesian regression models with <em>brms</em></a>
<ul>
<li class="chapter" data-level="3.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#chapter-pre-cap-2"><i class="fa fa-check"></i><b>3.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="3.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-what-is-reg"><i class="fa fa-check"></i><b>3.2</b> What are regression models?</a></li>
<li class="chapter" data-level="3.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-whats-bayes"><i class="fa fa-check"></i><b>3.3</b> What’s ‘Bayesian’ about these models?</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-priors"><i class="fa fa-check"></i><b>3.3.1</b> Prior probabilities</a></li>
<li class="chapter" data-level="3.3.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-posterior"><i class="fa fa-check"></i><b>3.3.2</b> Posterior distributions</a></li>
<li class="chapter" data-level="3.3.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-characteristics-posteriors"><i class="fa fa-check"></i><b>3.3.3</b> Posterior distributions and shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-sampling"><i class="fa fa-check"></i><b>3.4</b> Sampling from the posterior using <em>Stan</em> and <em>brms</em></a></li>
<li class="chapter" data-level="3.5" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-estimating"><i class="fa fa-check"></i><b>3.5</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-data-qs-1"><i class="fa fa-check"></i><b>3.5.1</b> Data and Research Questions</a></li>
<li class="chapter" data-level="3.5.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-description-1"><i class="fa fa-check"></i><b>3.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="3.5.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-errors-and-residuals"><i class="fa fa-check"></i><b>3.5.3</b> Errors and residuals</a></li>
<li class="chapter" data-level="3.5.4" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-model-formula"><i class="fa fa-check"></i><b>3.5.4</b> The model formula</a></li>
<li class="chapter" data-level="3.5.5" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-calling-brm"><i class="fa fa-check"></i><b>3.5.5</b> Fitting the model: Calling the <em>brm</em> function</a></li>
<li class="chapter" data-level="3.5.6" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-interpreting-print"><i class="fa fa-check"></i><b>3.5.6</b> Interpreting the model: The print statement</a></li>
<li class="chapter" data-level="3.5.7" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-seeing-samples"><i class="fa fa-check"></i><b>3.5.7</b> Seeing the samples</a></li>
<li class="chapter" data-level="3.5.8" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-getting-residuals"><i class="fa fa-check"></i><b>3.5.8</b> Getting the residuals</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-checking-convergence"><i class="fa fa-check"></i><b>3.6</b> Checking model convergence</a></li>
<li class="chapter" data-level="3.7" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-specifying-priors"><i class="fa fa-check"></i><b>3.7</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="3.8" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-log-posterior"><i class="fa fa-check"></i><b>3.8</b> The log prior and log posterior densities</a></li>
<li class="chapter" data-level="3.9" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-answering-qs"><i class="fa fa-check"></i><b>3.9</b> Answering our research questions</a></li>
<li class="chapter" data-level="3.10" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-frequentist"><i class="fa fa-check"></i><b>3.10</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-vs-ttest"><i class="fa fa-check"></i><b>3.10.1</b> One-sample t-test vs. intercept-only Bayesian models</a></li>
<li class="chapter" data-level="3.10.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-vs-ols"><i class="fa fa-check"></i><b>3.10.2</b> Intercept-only ordinary-least-squares regression vs. intercept-only Bayesian models</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#exercises-2"><i class="fa fa-check"></i><b>3.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>4</b> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#chapter-pre-cap-3"><i class="fa fa-check"></i><b>4.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-multilevel"><i class="fa fa-check"></i><b>4.2</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-levels"><i class="fa fa-check"></i><b>4.2.1</b> Multilevel models and ‘levels’ of variation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-many-levels"><i class="fa fa-check"></i><b>4.3</b> Representing predictors with many levels</a></li>
<li class="chapter" data-level="4.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-strategies"><i class="fa fa-check"></i><b>4.4</b> Strategies for estimating factors with many levels</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-complete-pooling"><i class="fa fa-check"></i><b>4.4.1</b> Complete pooling</a></li>
<li class="chapter" data-level="4.4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-no-pooling"><i class="fa fa-check"></i><b>4.4.2</b> No pooling</a></li>
<li class="chapter" data-level="4.4.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-partial-pooling"><i class="fa fa-check"></i><b>4.4.3</b> (Adaptive) Partial pooling</a></li>
<li class="chapter" data-level="4.4.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#hyperpriors"><i class="fa fa-check"></i><b>4.4.4</b> Hyperpriors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-estimating1"><i class="fa fa-check"></i><b>4.5</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-data-and-qs-1"><i class="fa fa-check"></i><b>4.5.1</b> Data and Research questions</a></li>
<li class="chapter" data-level="4.5.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model"><i class="fa fa-check"></i><b>4.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="4.5.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-fitting-1"><i class="fa fa-check"></i><b>4.5.3</b> Fitting the model</a></li>
<li class="chapter" data-level="4.5.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model"><i class="fa fa-check"></i><b>4.5.4</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-random-effects"><i class="fa fa-check"></i><b>4.6</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-inspecting-random-effects"><i class="fa fa-check"></i><b>4.6.1</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-simulating"><i class="fa fa-check"></i><b>4.7</b> Simulating data using our model parameters</a></li>
<li class="chapter" data-level="4.8" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-second-random-effect"><i class="fa fa-check"></i><b>4.8</b> Adding a second random effect</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-updating-model"><i class="fa fa-check"></i><b>4.8.1</b> Updating the model description</a></li>
<li class="chapter" data-level="4.8.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-and-interpreting-the-model"><i class="fa fa-check"></i><b>4.8.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-investigating-shrinkage"><i class="fa fa-check"></i><b>4.9</b> Investigating ‘shrinkage’</a></li>
<li class="chapter" data-level="4.10" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-answering-question"><i class="fa fa-check"></i><b>4.10</b> Answering our research questions</a></li>
<li class="chapter" data-level="4.11" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-frequentist"><i class="fa fa-check"></i><b>4.11</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="4.11.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-vs-lmer"><i class="fa fa-check"></i><b>4.11.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#exercises-3"><i class="fa fa-check"></i><b>4.12</b> Exercises</a></li>
<li class="chapter" data-level="4.13" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#references-2"><i class="fa fa-check"></i><b>4.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html"><i class="fa fa-check"></i><b>5</b> Comparing two groups of observations: Factors and contrasts</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#chapter-pre-cap-4"><i class="fa fa-check"></i><b>5.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparing-two-groups"><i class="fa fa-check"></i><b>5.2</b> Comparing two groups</a></li>
<li class="chapter" data-level="5.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#distribution-of-repeated-measures-across-factor-levels"><i class="fa fa-check"></i><b>5.3</b> Distribution of repeated measures across factor levels</a></li>
<li class="chapter" data-level="5.4" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-data-and-qs"><i class="fa fa-check"></i><b>5.4</b> Data and research questions</a></li>
<li class="chapter" data-level="5.5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-two-means"><i class="fa fa-check"></i><b>5.5</b> Estimating the difference between two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model"><i class="fa fa-check"></i><b>5.5.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model-1"><i class="fa fa-check"></i><b>5.5.2</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-contrasts"><i class="fa fa-check"></i><b>5.6</b> Contrasts</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-treatment-coding"><i class="fa fa-check"></i><b>5.6.1</b> Treatment coding</a></li>
<li class="chapter" data-level="5.6.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-sum-coding"><i class="fa fa-check"></i><b>5.6.2</b> Sum coding</a></li>
<li class="chapter" data-level="5.6.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-comparison-sum-treatment"><i class="fa fa-check"></i><b>5.6.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-refittin-sum"><i class="fa fa-check"></i><b>5.7</b> Sum coding and the decomposition of variation</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-description-1"><i class="fa fa-check"></i><b>5.7.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.7.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-1"><i class="fa fa-check"></i><b>5.7.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.7.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>5.7.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-working-with-posteriors"><i class="fa fa-check"></i><b>5.8</b> Inspecting and manipulating the posterior samples</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-using-hypothesis"><i class="fa fa-check"></i><b>5.8.1</b> Using the <em>hypothesis</em> function</a></li>
<li class="chapter" data-level="5.8.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-manipulating-random-effects"><i class="fa fa-check"></i><b>5.8.2</b> Working with the random effects</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-robustness"><i class="fa fa-check"></i><b>5.9</b> Making our models more robust: The (non-standardized) t distribution</a></li>
<li class="chapter" data-level="5.10" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#re-fitting-with-t-distributed-errors."><i class="fa fa-check"></i><b>5.10</b> Re-fitting with t-distributed errors</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#description-of-the-model-1"><i class="fa fa-check"></i><b>5.10.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.10.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-and-interpreting-the-model-1"><i class="fa fa-check"></i><b>5.10.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-simulating"><i class="fa fa-check"></i><b>5.11</b> Simulating the two-group model</a></li>
<li class="chapter" data-level="5.12" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-answering-qs"><i class="fa fa-check"></i><b>5.12</b> Answering our research questions</a></li>
<li class="chapter" data-level="5.13" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-frequentist"><i class="fa fa-check"></i><b>5.13</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#bayesian-multilevel-models-vs.-lmer"><i class="fa fa-check"></i><b>5.13.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#exercises-4"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html"><i class="fa fa-check"></i><b>6</b> Variation in parameters (‘random effects’) and model comparison</a>
<ul>
<li class="chapter" data-level="6.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#chapter-pre-cap-5"><i class="fa fa-check"></i><b>6.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="6.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-data-and-qs"><i class="fa fa-check"></i><b>6.2</b> Data and research questions</a></li>
<li class="chapter" data-level="6.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-variation-sources"><i class="fa fa-check"></i><b>6.3</b> Variation in parameters across sources of data</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#description-of-our-model"><i class="fa fa-check"></i><b>6.3.1</b> Description of our model</a></li>
<li class="chapter" data-level="6.3.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-correlations"><i class="fa fa-check"></i><b>6.3.2</b> Correlations between random parameters</a></li>
<li class="chapter" data-level="6.3.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-random-and-mvn"><i class="fa fa-check"></i><b>6.3.3</b> Random effects and the multivariate normal distribution</a></li>
<li class="chapter" data-level="6.3.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-mvn-priors"><i class="fa fa-check"></i><b>6.3.4</b> Specifying priors for a multivariate normal distribution</a></li>
<li class="chapter" data-level="6.3.5" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#updating-our-model-description"><i class="fa fa-check"></i><b>6.3.5</b> Updating our model description</a></li>
<li class="chapter" data-level="6.3.6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-fitting"><i class="fa fa-check"></i><b>6.3.6</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-model-comparison"><i class="fa fa-check"></i><b>6.4</b> Model Comparison</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-in-and-out-prediction"><i class="fa fa-check"></i><b>6.4.1</b> In-sample and out-of-sample prediction</a></li>
<li class="chapter" data-level="6.4.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-out-sample-adjust"><i class="fa fa-check"></i><b>6.4.2</b> Out-of-sample prediction: Adjusting predictive accuracy</a></li>
<li class="chapter" data-level="6.4.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-out-sample-crossval"><i class="fa fa-check"></i><b>6.4.3</b> Out-of-sample prediction: Cross validation</a></li>
<li class="chapter" data-level="6.4.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#selecting-a-model"><i class="fa fa-check"></i><b>6.4.4</b> Selecting a model</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-answering"><i class="fa fa-check"></i><b>6.5</b> Answering our research questions</a></li>
<li class="chapter" data-level="6.6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-frequentist"><i class="fa fa-check"></i><b>6.6</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-vs-lmer"><i class="fa fa-check"></i><b>6.6.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#exercises-5"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#references-3"><i class="fa fa-check"></i><b>6.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><i class="fa fa-check"></i><b>7</b> Comparing many groups, interactions, and posterior predictive checks</a>
<ul>
<li class="chapter" data-level="7.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#chapter-pre-cap-6"><i class="fa fa-check"></i><b>7.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="7.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#comparing-four-or-any-number-of-groups"><i class="fa fa-check"></i><b>7.2</b> Comparing four (or any number of) groups</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions"><i class="fa fa-check"></i><b>7.2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.2.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-description-1"><i class="fa fa-check"></i><b>7.2.2</b> Description of our model</a></li>
<li class="chapter" data-level="7.2.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-2"><i class="fa fa-check"></i><b>7.2.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#investigating-multiple-factors-simultaneously"><i class="fa fa-check"></i><b>7.3</b> Investigating multiple factors simultaneously</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>7.3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.3.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#description-of-the-model-2"><i class="fa fa-check"></i><b>7.3.2</b> Description of the model</a></li>
<li class="chapter" data-level="7.3.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-3"><i class="fa fa-check"></i><b>7.3.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-posterior-prediction"><i class="fa fa-check"></i><b>7.4</b> Posterior prediction: Using our models to predict new data</a></li>
<li class="chapter" data-level="7.5" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-interactions-and-plots"><i class="fa fa-check"></i><b>7.5</b> Interactions and interaction plots</a></li>
<li class="chapter" data-level="7.6" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#investigating-interactions-with-a-model"><i class="fa fa-check"></i><b>7.6</b> Investigating interactions with a model</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>7.6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.6.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#model-formulas"><i class="fa fa-check"></i><b>7.6.2</b> Model formulas</a></li>
<li class="chapter" data-level="7.6.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#description-of-our-model-1"><i class="fa fa-check"></i><b>7.6.3</b> Description of our model</a></li>
<li class="chapter" data-level="7.6.4" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-4"><i class="fa fa-check"></i><b>7.6.4</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="7.6.5" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-calc-means"><i class="fa fa-check"></i><b>7.6.5</b> Caulculating group means in the presence of interactions</a></li>
<li class="chapter" data-level="7.6.6" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#calculating-simple-effects-in-the-presence-of-interactions"><i class="fa fa-check"></i><b>7.6.6</b> Calculating simple effects in the presence of interactions</a></li>
<li class="chapter" data-level="7.6.7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#assessing-model-fit-bayesian-r2"><i class="fa fa-check"></i><b>7.6.7</b> Assessing model fit: Bayesian <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-answering"><i class="fa fa-check"></i><b>7.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="7.8" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>7.8</b> Factors with more than two levels</a></li>
<li class="chapter" data-level="7.9" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-frequentist"><i class="fa fa-check"></i><b>7.9</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#bayesian-multilevel-models-vs.-lmer-1"><i class="fa fa-check"></i><b>7.9.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#exercises-6"><i class="fa fa-check"></i><b>7.10</b> Exercises</a></li>
<li class="chapter" data-level="7.11" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#references-4"><i class="fa fa-check"></i><b>7.11</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html"><i class="fa fa-check"></i><b>8</b> Varying variances, more about priors, and prior predictive checks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#chapter-pre-cap-7"><i class="fa fa-check"></i><b>8.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="8.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#data-and-research-questions-3"><i class="fa fa-check"></i><b>8.2</b> Data and Research questions</a></li>
<li class="chapter" data-level="8.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#more-about-priors"><i class="fa fa-check"></i><b>8.3</b> More about priors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-prior-prediction"><i class="fa fa-check"></i><b>8.3.1</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.3.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#more-specific-priors"><i class="fa fa-check"></i><b>8.3.2</b> More specific priors</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#heteroskedasticity-and-distributional-or-mixture-models"><i class="fa fa-check"></i><b>8.4</b> Heteroskedasticity and distributional (or mixture) models</a></li>
<li class="chapter" data-level="8.5" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#a-simple-model-error-varies-according-to-a-single-fixed-effect"><i class="fa fa-check"></i><b>8.5</b> A ‘simple’ model: Error varies according to a single fixed effect</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#description-of-our-model-2"><i class="fa fa-check"></i><b>8.5.1</b> Description of our model</a></li>
<li class="chapter" data-level="8.5.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#prior-predictive-checks"><i class="fa fa-check"></i><b>8.5.2</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.5.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#fitting-and-interpreting-the-model-5"><i class="fa fa-check"></i><b>8.5.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#a-complex-model-error-varies-according-to-fixed-and-random-effects"><i class="fa fa-check"></i><b>8.6</b> A ‘complex’ model: Error varies according to fixed and random effects</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-description-2"><i class="fa fa-check"></i><b>8.6.1</b> Description of our model</a></li>
<li class="chapter" data-level="8.6.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#fitting-and-interpreting-the-model-6"><i class="fa fa-check"></i><b>8.6.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#answering-our-research-questions"><i class="fa fa-check"></i><b>8.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="8.8" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-identifiability"><i class="fa fa-check"></i><b>8.8</b> Building identifiable and supportable models</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#collinearity"><i class="fa fa-check"></i><b>8.8.1</b> Collinearity</a></li>
<li class="chapter" data-level="8.8.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#predictable-values-of-categorical-predictors"><i class="fa fa-check"></i><b>8.8.2</b> Predictable values of categorical predictors</a></li>
<li class="chapter" data-level="8.8.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#saturated-and-nearly-saturated-models"><i class="fa fa-check"></i><b>8.8.3</b> Saturated, and ‘nearly-saturated’, models</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#exercises-7"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
<li class="chapter" data-level="8.10" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#references-5"><i class="fa fa-check"></i><b>8.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html"><i class="fa fa-check"></i><b>9</b> Quantitative predictors and their interactions with factors</a>
<ul>
<li class="chapter" data-level="9.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#chapter-pre-cap-8"><i class="fa fa-check"></i><b>9.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="9.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#data-and-research-questions-4"><i class="fa fa-check"></i><b>9.2</b> Data and research questions</a></li>
<li class="chapter" data-level="9.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#modeling-variation-along-lines"><i class="fa fa-check"></i><b>9.3</b> Modeling variation along lines</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-3"><i class="fa fa-check"></i><b>9.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.3.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-centering"><i class="fa fa-check"></i><b>9.3.2</b> Centering quantitative predictors</a></li>
<li class="chapter" data-level="9.3.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-an-interpreting-the-model"><i class="fa fa-check"></i><b>9.3.3</b> Fitting an interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-intercepts-but-shared-slopes"><i class="fa fa-check"></i><b>9.4</b> Models with group-dependent intercepts, but shared slopes</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-4"><i class="fa fa-check"></i><b>9.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.4.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-and-interpreting-the-model-7"><i class="fa fa-check"></i><b>9.4.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.4.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-shared-non-zero-slopes"><i class="fa fa-check"></i><b>9.4.3</b> Interpreting group effects in the presence of shared (non-zero) slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-slopes-and-intercepts"><i class="fa fa-check"></i><b>9.5</b> Models with group-dependent slopes and intercepts</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-5"><i class="fa fa-check"></i><b>9.5.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.5.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-fitting-3"><i class="fa fa-check"></i><b>9.5.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.5.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-varying-slopes"><i class="fa fa-check"></i><b>9.5.3</b> Interpreting group effects in the presence of varying slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#answering-our-research-questions-interim-discussion"><i class="fa fa-check"></i><b>9.6</b> Answering our research questions: Interim discussion</a></li>
<li class="chapter" data-level="9.7" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#data-and-research-questions-updated"><i class="fa fa-check"></i><b>9.7</b> Data and research questions: Updated</a></li>
<li class="chapter" data-level="9.8" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-intercepts-and-slopes-for-each-level-of-a-grouping-factor-i.e.-random-slopes"><i class="fa fa-check"></i><b>9.8</b> Models with intercepts and slopes for each level of a grouping factor (i.e. ‘random slopes’)</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-6"><i class="fa fa-check"></i><b>9.8.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.8.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-and-interpreting-the-model-8"><i class="fa fa-check"></i><b>9.8.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-multiple-predictors-for-each-level-of-a-grouping-factor"><i class="fa fa-check"></i><b>9.9</b> Models with multiple predictors for each level of a grouping factor</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-7"><i class="fa fa-check"></i><b>9.9.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.9.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-fitting-5"><i class="fa fa-check"></i><b>9.9.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.9.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#model-selection"><i class="fa fa-check"></i><b>9.9.3</b> Model selection</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#answering-our-research-questions-updated"><i class="fa fa-check"></i><b>9.10</b> Answering our research questions: Updated</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#a-word-on-causality"><i class="fa fa-check"></i><b>9.10.1</b> A word on causality</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#exercises-8"><i class="fa fa-check"></i><b>9.11</b> Exercises</a></li>
<li class="chapter" data-level="9.12" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#references-6"><i class="fa fa-check"></i><b>9.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html"><i class="fa fa-check"></i><b>10</b> Logistic regression and signal detection theory models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#chapter-pre-cap-9"><i class="fa fa-check"></i><b>10.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-dichotomous"><i class="fa fa-check"></i><b>10.2</b> Dichotomous variables and data</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#generalizing-our-linear-models"><i class="fa fa-check"></i><b>10.3</b> Generalizing our linear models</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logits"><i class="fa fa-check"></i><b>10.4.1</b> Logits</a></li>
<li class="chapter" data-level="10.4.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-inverse-logit"><i class="fa fa-check"></i><b>10.4.2</b> The inverse logit link function</a></li>
<li class="chapter" data-level="10.4.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#building-intuitions-about-logits-and-the-inverse-logit-function"><i class="fa fa-check"></i><b>10.4.3</b> Building intuitions about logits and the inverse logit function</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logistic-regression-with-one-quantitative-predictor"><i class="fa fa-check"></i><b>10.5</b> Logistic regression with one quantitative predictor</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#data-and-research-questions-5"><i class="fa fa-check"></i><b>10.5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="10.5.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#description-of-the-model-8"><i class="fa fa-check"></i><b>10.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="10.5.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-fitting-0"><i class="fa fa-check"></i><b>10.5.3</b> Fitting the model</a></li>
<li class="chapter" data-level="10.5.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-fitting-1"><i class="fa fa-check"></i><b>10.5.4</b> Interpreting the model</a></li>
<li class="chapter" data-level="10.5.5" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-classification"><i class="fa fa-check"></i><b>10.5.5</b> Using logistic models to understand classification</a></li>
<li class="chapter" data-level="10.5.6" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#answering-our-research-question"><i class="fa fa-check"></i><b>10.5.6</b> Answering our research question</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#measuring-sensitivity-and-bias"><i class="fa fa-check"></i><b>10.6</b> Measuring sensitivity and bias</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#data-and-research-questions-6"><i class="fa fa-check"></i><b>10.6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="10.6.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#description-of-the-model-9"><i class="fa fa-check"></i><b>10.6.2</b> Description of the model</a></li>
<li class="chapter" data-level="10.6.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#fitting-and-interpreting-the-model-9"><i class="fa fa-check"></i><b>10.6.3</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="10.6.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#answering-our-research-questions-1"><i class="fa fa-check"></i><b>10.6.4</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#exercises-9"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
<li class="chapter" data-level="10.8" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#references-7"><i class="fa fa-check"></i><b>10.8</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><i class="fa fa-check"></i><b>11</b> Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#chapter-pre-cap-10"><i class="fa fa-check"></i><b>11.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="11.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#models-with-multiple-quantitative-predictors"><i class="fa fa-check"></i><b>11.2</b> Models with multiple quantitative predictors</a></li>
<li class="chapter" data-level="11.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#interactions-between-quantitative-predictors"><i class="fa fa-check"></i><b>11.3</b> Interactions between quantitative predictors</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#centering-quantitative-predictors-when-including-interactions"><i class="fa fa-check"></i><b>11.3.1</b> Centering quantitative predictors when including interactions</a></li>
<li class="chapter" data-level="11.3.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-7"><i class="fa fa-check"></i><b>11.3.2</b> Data and research questions</a></li>
<li class="chapter" data-level="11.3.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-description-1"><i class="fa fa-check"></i><b>11.3.3</b> Description of the model</a></li>
<li class="chapter" data-level="11.3.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-the-model-2"><i class="fa fa-check"></i><b>11.3.4</b> Fitting the model</a></li>
<li class="chapter" data-level="11.3.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#advantages-of-bayesian-multilevel-models-for-large-models"><i class="fa fa-check"></i><b>11.3.5</b> Advantages of Bayesian multilevel models for large models</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-BANOVA"><i class="fa fa-check"></i><b>11.4</b> Bayesian Analysis of Variance</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#getting-the-standard-deviations-from-our-models-manually"><i class="fa fa-check"></i><b>11.4.1</b> Getting the standard deviations from our models ‘manually’</a></li>
<li class="chapter" data-level="11.4.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#using-the-banova-function"><i class="fa fa-check"></i><b>11.4.2</b> Using the <code>banova</code> function</a></li>
<li class="chapter" data-level="11.4.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-comparing-the-reduced-model"><i class="fa fa-check"></i><b>11.4.3</b> Fitting and comparing the reduced model</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#a-logistic-regression-model-with-multiple-quantitative-predictors"><i class="fa fa-check"></i><b>11.5</b> A logistic regression model with multiple quantitative predictors</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-8"><i class="fa fa-check"></i><b>11.5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="11.5.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#description-of-the-model-10"><i class="fa fa-check"></i><b>11.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="11.5.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-the-model-and-applying-a-bayesian-anova"><i class="fa fa-check"></i><b>11.5.3</b> Fitting and the model and applying a Bayesian ANOVA</a></li>
<li class="chapter" data-level="11.5.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c12-2d-categorization"><i class="fa fa-check"></i><b>11.5.4</b> Categorization in two dimensions</a></li>
<li class="chapter" data-level="11.5.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#model-selection-and-misspecification"><i class="fa fa-check"></i><b>11.5.5</b> Model selection and misspecification</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#exercises-10"><i class="fa fa-check"></i><b>11.6</b> Exercises</a></li>
<li class="chapter" data-level="11.7" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#references-8"><i class="fa fa-check"></i><b>11.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html"><i class="fa fa-check"></i><b>12</b> Multinomial and Ordinal regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#chapter-pre-cap-11"><i class="fa fa-check"></i><b>12.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="12.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>12.2</b> Multinomial logistic regression</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#multinomial-logits-and-the-softmax-function"><i class="fa fa-check"></i><b>12.2.1</b> Multinomial logits and the softmax function</a></li>
<li class="chapter" data-level="12.2.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#comparison-to-logistic-regression"><i class="fa fa-check"></i><b>12.2.2</b> Comparison to logistic regression</a></li>
<li class="chapter" data-level="12.2.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#data-and-research-questions-9"><i class="fa fa-check"></i><b>12.2.3</b> Data and research questions</a></li>
<li class="chapter" data-level="12.2.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#description-of-our-model-3"><i class="fa fa-check"></i><b>12.2.4</b> Description of our model</a></li>
<li class="chapter" data-level="12.2.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#fitting-the-model-3"><i class="fa fa-check"></i><b>12.2.5</b> Fitting the model</a></li>
<li class="chapter" data-level="12.2.6" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#interpreting-the-model-2"><i class="fa fa-check"></i><b>12.2.6</b> Interpreting the model</a></li>
<li class="chapter" data-level="12.2.7" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#c12-multinomial-territorial-maps"><i class="fa fa-check"></i><b>12.2.7</b> Multinomial models and territorial maps</a></li>
<li class="chapter" data-level="12.2.8" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#refitting-the-model-without-speaker-random-effects"><i class="fa fa-check"></i><b>12.2.8</b> Refitting the model without speaker random effects</a></li>
<li class="chapter" data-level="12.2.9" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#answering-our-research-questions-2"><i class="fa fa-check"></i><b>12.2.9</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>12.3</b> Ordinal (logistic) regression</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#c12-cumulative-density"><i class="fa fa-check"></i><b>12.3.1</b> Cumulative distribution functions</a></li>
<li class="chapter" data-level="12.3.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#data-and-research-questions-10"><i class="fa fa-check"></i><b>12.3.2</b> Data and research questions</a></li>
<li class="chapter" data-level="12.3.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#description-of-the-model-11"><i class="fa fa-check"></i><b>12.3.3</b> Description of the model</a></li>
<li class="chapter" data-level="12.3.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#fitting-and-interpreting-the-model-10"><i class="fa fa-check"></i><b>12.3.4</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="12.3.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#listener-specific-discrimination-terms"><i class="fa fa-check"></i><b>12.3.5</b> Listener-specific discrimination terms</a></li>
<li class="chapter" data-level="12.3.6" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#answering-our-research-questions-3"><i class="fa fa-check"></i><b>12.3.6</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#exercises-11"><i class="fa fa-check"></i><b>12.4</b> Exercises</a></li>
<li class="chapter" data-level="12.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#references-9"><i class="fa fa-check"></i><b>12.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><i class="fa fa-check"></i><b>13</b> Writing up experiments: An investigation of the perception of apparent speaker characteristics from speech acoustics</a>
<ul>
<li class="chapter" data-level="13.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#introduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#fundamental-frequency-and-voice-pitch"><i class="fa fa-check"></i><b>13.1.1</b> Fundamental frequency and voice pitch</a></li>
<li class="chapter" data-level="13.1.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#variation-in-fundamental-frequency-between-speakers"><i class="fa fa-check"></i><b>13.1.2</b> Variation in fundamental frequency between speakers</a></li>
<li class="chapter" data-level="13.1.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#voice-resonance-and-vocal-tract-length"><i class="fa fa-check"></i><b>13.1.3</b> Voice resonance and vocal-tract length</a></li>
<li class="chapter" data-level="13.1.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-estimating-vtl"><i class="fa fa-check"></i><b>13.1.4</b> Estimating vocal-tracts length from speech</a></li>
<li class="chapter" data-level="13.1.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#variation-in-vocal-tract-length-between-speakers"><i class="fa fa-check"></i><b>13.1.5</b> Variation in vocal-tract length between speakers</a></li>
<li class="chapter" data-level="13.1.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-perception-of-chars"><i class="fa fa-check"></i><b>13.1.6</b> Perception of age, gender and size</a></li>
<li class="chapter" data-level="13.1.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#category-dependent-behavior"><i class="fa fa-check"></i><b>13.1.7</b> Category-dependent behavior</a></li>
<li class="chapter" data-level="13.1.8" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#the-current-experiment"><i class="fa fa-check"></i><b>13.1.8</b> The current experiment</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#methods"><i class="fa fa-check"></i><b>13.2</b> Methods</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#participants"><i class="fa fa-check"></i><b>13.2.1</b> Participants</a></li>
<li class="chapter" data-level="13.2.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-stimuli"><i class="fa fa-check"></i><b>13.2.2</b> Stimuli</a></li>
<li class="chapter" data-level="13.2.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#procedure"><i class="fa fa-check"></i><b>13.2.3</b> Procedure</a></li>
<li class="chapter" data-level="13.2.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#data-screening"><i class="fa fa-check"></i><b>13.2.4</b> Data screening</a></li>
<li class="chapter" data-level="13.2.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#loading-the-data-and-packages"><i class="fa fa-check"></i><b>13.2.5</b> Loading the data and packages</a></li>
<li class="chapter" data-level="13.2.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#statistical-analysis-apparent-height"><i class="fa fa-check"></i><b>13.2.6</b> Statistical Analysis: Apparent height</a></li>
<li class="chapter" data-level="13.2.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#statistical-analysis-apparent-gender"><i class="fa fa-check"></i><b>13.2.7</b> Statistical Analysis: Apparent gender</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#results-apparent-height-judgments"><i class="fa fa-check"></i><b>13.3</b> Results: Apparent height judgments</a></li>
<li class="chapter" data-level="13.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#discussion-apparent-height"><i class="fa fa-check"></i><b>13.4</b> Discussion: Apparent height</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#age-dependent-use-of-vtl-cues-on-apparent-height"><i class="fa fa-check"></i><b>13.4.1</b> Age-dependent use of VTL cues on apparent height</a></li>
<li class="chapter" data-level="13.4.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#the-effect-for-apparent-gender-on-apparent-height"><i class="fa fa-check"></i><b>13.4.2</b> The effect for apparent gender on apparent height</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#conclusion-apparent-height-judgments"><i class="fa fa-check"></i><b>13.5</b> Conclusion: Apparent height judgments</a></li>
<li class="chapter" data-level="13.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#results-apparent-gender-judgments"><i class="fa fa-check"></i><b>13.6</b> Results: Apparent gender judgments</a></li>
<li class="chapter" data-level="13.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#discussion-apparent-gender-judgments"><i class="fa fa-check"></i><b>13.7</b> Discussion: Apparent gender judgments</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#effect-of-apparent-age-on-the-perception-of-femaleness"><i class="fa fa-check"></i><b>13.7.1</b> Effect of apparent age on the perception of femaleness</a></li>
<li class="chapter" data-level="13.7.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#between-listener-variation-in-gender-perception"><i class="fa fa-check"></i><b>13.7.2</b> Between-listener variation in gender perception</a></li>
<li class="chapter" data-level="13.7.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#beyond-gross-acoustic-cues-in-gender-perception"><i class="fa fa-check"></i><b>13.7.3</b> Beyond gross acoustic cues in gender perception</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#conclusion-apparent-gender"><i class="fa fa-check"></i><b>13.8</b> Conclusion: Apparent gender</a></li>
<li class="chapter" data-level="13.9" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#next-steps"><i class="fa fa-check"></i><b>13.9</b> Next steps</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#research-design-variable-selection-etc."><i class="fa fa-check"></i><b>13.9.1</b> Research design, variable selection, etc.</a></li>
<li class="chapter" data-level="13.9.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#non-linear-models"><i class="fa fa-check"></i><b>13.9.2</b> Non-linear models</a></li>
<li class="chapter" data-level="13.9.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#other-data-distributions"><i class="fa fa-check"></i><b>13.9.3</b> Other data distributions</a></li>
<li class="chapter" data-level="13.9.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#multivariate-analyses"><i class="fa fa-check"></i><b>13.9.4</b> Multivariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#references-10"><i class="fa fa-check"></i><b>13.10</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/santiagobarreda/bmmrmd" target="blank">Book GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In this chapter we introduce models with multiple quantitative predictors and interactions between them. After that, we will have covered the basic modeling concepts necessary to fit most linear models. The models you fit to your own data will include some combination of the elements covered in the previous chapters, and can potentially result in large models with hundreds (or thousands) of estimated parameters. Traditionally, models with many estimated parameters have had three general problems:</p>
<ol style="list-style-type: decimal">
<li><p>A model with many predictors may have ‘too many’ predictors. We will vaguely define ‘extra’ predictors as those which have no meaningful statistical association with your dependent variable, and which do not appreciably improve your model in any way. Sometimes, the ‘extra’ predictors have estimated values that are difficult to distinguish from those of the ‘real’ parameters, leading to incorrect conclusions.</p></li>
<li><p>A model with many parameters may have more difficulties with fitting/convergence, meaning you can’t get good estimates for the model coefficients. Regardless of the approach to parameter estimation, more-complicated models make it more difficult to find the optimal parameter values given the data and chosen model structure.</p></li>
<li><p>It can be difficult to interpret a model with hundreds (or thousands) of parameters. With so many parameters it is important to not miss the forest for the trees, that is, not consider every parameter in isolation to the detriment of understanding what information your fitted model provides in general.</p></li>
</ol>
<p>In this chapter we’re going to cover a Bayesian approach to working with large models. First we’re going to discuss how working with multilevel Bayesian models can help us with problems (1) and (2) above. After that we’re going to discuss an easy way to approach problem (3) using our Bayesian models.</p>
<p>Before continuing, we should note that designs with many quantitative predictors, factors, and interactions between these can result in very complicated models which then have to be interpreted. However, the researcher is ultimately the one who determines the complexity of the analysis they are then faced with. Once when Santiago was buying a backpack for traveling, he was looking for the biggest backpack possible. One of the reviews said “1/5 stars, it was way too heavy when I filled it all the way up with my stuff”. However, if we buy a large backpack and fill it with many heavy things, it doesn’t seem fair to blame the backpack when it becomes difficult to carry. In the same way, if you are faced with a complex model that you then need to interpret, you shouldn’t blame the model, <code>brms</code>, or us, for your predicament.</p>
<p>In order to avoid a situation where you end up with data you can’t analyze or a model you can’t interpret, it’s worth considering the following questions <em>before</em> advancing to the data collection stage of your experiment:</p>
<ul>
<li>How will I analyze the data? Will I be able to carry out my planned analysis?</li>
<li>What will the model structure be?</li>
<li>What kind of results am I expecting?</li>
<li>How will expected results be reflected by the model parameters? How would different results manifest in the model parameters?</li>
</ul>
<div id="chapter-pre-cap-10" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Chapter pre-cap<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#chapter-pre-cap-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we discuss why Bayesian multilevel models are well suited for the analysis of complex models with large numbers of parameters, and some strategies for interpreting these models are presented. A model with two quantitative predictors and an interaction between them is outlined, and the model is fit and interpreted. We introduce Bayesian analysis of variance (BANOVA) and Bayesian ANOVA plots, and use these to investigate the initial model presented in the chapter. Following that, a multivariate logistic regression model is fit and interpreted using a Bayesian ANOVA. After this, we explain how multivariate logistic models can be used to interpret classification and listener behavior. Finally, we discuss model selection and misspecification, and some diagnostics that can help find and diagnose problems in large models.</p>
</div>
<div id="models-with-multiple-quantitative-predictors" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Models with multiple quantitative predictors<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#models-with-multiple-quantitative-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Our regression models so far have only involved at most a single quantitative predictor. This means that the relationship between the dependent variable and our predictor formed surfaces with a single dimension: Lines. In the left and middle plots in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a> we see the linear relationships between speaker vocal-tract length (VTL) and fundamental frequency (f0) with apparent speaker height (see chapter 1, or 13, for more information on these variables). In each case, the expected value for the y-axis variable is the value of the line at each x-axis location. The residual, the error in the prediction of each observation, is the vertical distance between the line and the observation.</p>
<div class="figure"><span style="display:block;" id="fig:F11-1"></span>
<img src="_main_files/figure-html/F11-1-1.jpeg" alt="(left) Average apparent height reported for each speaker plotted against speaker vocal-tract length (VTL). Point size reflects average apparent height. (middle) Same as the left plot but comparing apparent height to f0. (right) A comparison of VTL and f0 for each speaker." width="4800" />
<p class="caption">
Figure 11.1: (left) Average apparent height reported for each speaker plotted against speaker vocal-tract length (VTL). Point size reflects average apparent height. (middle) Same as the left plot but comparing apparent height to f0. (right) A comparison of VTL and f0 for each speaker.
</p>
</div>
<p>We can also think about how apparent height, VTL, and f0 vary together. Every point in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a> has a specific value of f0, VTL, and apparent height. These three quantitative variables can be thought of as defining a single location in a 3-dimensional space. Imagine you had a clear plastic cube containing points arranged as in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a> inside it, where each dimension along the cube represented one of the dimensions in the figure. Looking ‘through’ the cube at different orientations would result in arrangements just like the plots in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a>. The first plot shows the view through the VTL side, and the second plot shows the view down the f0 side, a 1/4 rotation of the cube. The final plot shows the view down through the top of the cube.</p>
<p>It may be easier to see what we mean in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-2">11.2</a>, which attempts to present our points in three dimensions. The left plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-2">11.2</a> corresponds (more or less) to the left plot in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a>, while the right plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-2">11.2</a> corresponds (more or less) to the middle plot in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a>. When we have two quantitative predictors, our models predict values along <strong>planes</strong> rather than lines. If we want to predict apparent height based on speaker f0 and VTL, we are basically asking: Can we predict the height of a point in our 3-dimensional space (i.e., location on the vertical z axis) based on its x and y-axis location?</p>
<div class="figure"><span style="display:block;" id="fig:F11-2"></span>
<img src="../wrong_plots/Figure 11.2.jpg" alt="(left) A three-dimensional plot of the variables presented in figure \@ref(fig:F11-1). (right) The same as the left plot but with a different orientation of the variables."  />
<p class="caption">
Figure 11.2: (left) A three-dimensional plot of the variables presented in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-1">11.1</a>. (right) The same as the left plot but with a different orientation of the variables.
</p>
</div>
<p>For example, any given point in the room you are sitting in right now can be specified using three variables that determine its location along the width, depth, and height of the room. Imagine the points in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-2">11.2</a> were floating in the room with you, arranged just as in the figure. You are given a large flat board (a <em>plane</em>) and asked to find the ‘best’ orientation for the board. When we fit lines, we preferred those that tended to minimize the residuals, the y-axis distance of the points to the line. The same principle holds when we fit models with two (or more) quantitative predictors. In general, planes are ‘better’ when they minimize the distance from each point to the surface of the plane along the axis representing the dependent variable. Though it’s a bit more complicated than this for multilevel models, this general principle (i.e. the minimization of the residuals) still applies. In figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-2">11.2</a>, we see the plane that results in the smallest residuals for our points, i.e. the smallest distances between the surface of the plane and the points along the apparent height axis.</p>
<p>In equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-1">(11.1)</a> we see that the height of the plane along the z axis is determined by an intercept (<span class="math inline">\(a\)</span>) plus the product of the x axis coordinate and its slope (<span class="math inline">\(b\)</span>), and the product of the y axis coordinate and its slope (<span class="math inline">\(c\)</span>). When we fit a model that includes two quantitative predictors, the model represents the planes it estimates using their <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span> parameters.</p>
<p><span class="math display" id="eq:11-1">\[
\begin{equation}
z =  \mathrm{a} + \mathrm{b} \cdot x + \mathrm{c} \cdot y
\tag{11.1}
\end{equation}
\]</span></p>
<p>Since the plane has two dimensions it has two slopes: A field can be uphill/downhill away from you, but also be up/downhill left to right. The slope coefficient for each quantitative predictor changes the slope of the plane independently for each dimension. In fact, the slope of each predictor reflects the expected change in the dependent variable when all other predictors are <em>held constant</em>. The intercept of the model slides the planes up/down the z axis without changing their slopes along either the x or y dimensions.</p>
<p>Our discussion above has been entirely about planes, and we will stick to two quantitative predictors for our models. However, your model can include any number of quantitative predictors, it just gets harder to have good intuitions about the geometry involved. If your model has <span class="math inline">\(n\)</span> quantitative predictors, your data specifies points in an <span class="math inline">\(n+1\)</span> dimensional space, where dimension <span class="math inline">\(n+1\)</span> represents the dependent variable. Residuals in such models represent the difference between the surface of the <span class="math inline">\(n\)</span> dimensional shape specified by the predictors, and the position of each point along the <span class="math inline">\(n+1\)</span> dimension.</p>
</div>
<div id="interactions-between-quantitative-predictors" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Interactions between quantitative predictors<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#interactions-between-quantitative-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Models with two quantitative predictors model variation in the dependent variable along planes. The ‘interaction’ between quantitative variables in regression models is represented by adding a new predictor, the <strong>cross-product</strong> (i.e. <span class="math inline">\(x \cdot y\)</span>) of the two variables. We can add a term representing the interaction between our two quantitative predictors to equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-2">(11.2)</a>. It’s common to refer to this term as the ‘interaction’ between our quantitative predictors, and we will adopt this convention. Just keep in mind that we are actually referring to the product of the two variables.</p>
<p><span class="math display" id="eq:11-2">\[
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y) + (\mathrm{d} \cdot x \cdot y)
\tag{11.2}
\end{equation}
\]</span></p>
<p>In general, interaction terms are parameters that allow for the effect of a predictor to vary according to the value of some other predictor. When it comes to quantitative predictors, an interaction means that the slope of each predictor continuously increases/decreases as a function of the value of the <em>other</em> predictor. Consider the equation below which omits the term <span class="math inline">\((c \cdot y)\)</span> for the sake of simplicity. If we factor out the x from the second and third terms on the right, we can see that the slope for the x dimension, <span class="math inline">\(b\)</span>, will vary as a function of the value of y and the interaction coefficient <span class="math inline">\(d\)</span>.</p>
<p><span class="math display" id="eq:11-3">\[
\begin{equation}
\begin{split}
z =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{d} \cdot x \cdot y) \\
z =  \mathrm{a} + (\mathrm{b}) \cdot x + (\mathrm{d} \cdot y) \cdot x \\
z =  \mathrm{a} + (\mathrm{b} + \mathrm{d} \cdot y) \cdot x \\
\end{split}
\tag{11.3}
\end{equation}
\]</span></p>
<p>Imagine a case where the slope (<span class="math inline">\(b\)</span>) along the <span class="math inline">\(x\)</span> dimension is fixed at 2 and the interaction term (<span class="math inline">\(d\)</span>) is equal to zero. In this case there is no interaction between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>. When this happens the slope of <span class="math inline">\(x\)</span> is constant and does not change based on the value of <span class="math inline">\(y\)</span>, as in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-4">(11.4)</a>.</p>
<p><span class="math display" id="eq:11-4">\[
\begin{equation}
\begin{split}
b = 2, \; d = 0 \\
z =  \mathrm{a} + (\mathrm{b} + \mathrm{d} \cdot y) \cdot x \\
z =  \mathrm{a} + (2 + 0 \cdot y) \cdot x \\
z =  \mathrm{a} + 2  \cdot x \\
\end{split}
\tag{11.4}
\end{equation}
\]</span></p>
<p>Now consider a situation where the interaction term has some non-zero value (e.g. 1). In this case we <em>will</em> see the slope along x change as a function of the value of y. In <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-5">(11.5)</a> we see that as y increases from 1 to 5, the effective slope along the x axis increases from 3 to 7. This reasoning also holds for the y dimension and also means that negative interactions result in a <em>decrease</em> in slopes as the value of variables increase.</p>
<p><span class="math display" id="eq:11-5">\[
\begin{equation}
\begin{split}
b = 2 , \; d = 1 , \; y = 1   \\
z =  \mathrm{a} + (2 + 1 \cdot 1) \cdot x \\
z =  \mathrm{a} + 3 \cdot x \\ \\
b = 2 , \; d = 1 , \; y = 5   \\
z =  \mathrm{a} + (2 + 1 \cdot 5) \cdot x \\
z =  \mathrm{a} + 7 \cdot x \\
\end{split}
\tag{11.5}
\end{equation}
\]</span></p>
<p>The inclusion of cross-product terms means that we are not modeling variation along planes anymore, but rather along <strong>hyperbolic parabaloids</strong>. Sometimes these sorts of surfaces are referred to as <strong>saddle surfaces</strong> because they contain what’s known as a <strong>saddle point</strong>, a point where the slopes along the x and y dimension are both equal to zero. Informally, a saddle point can be thought of as the flat spot in the middle of a shape that curves along two dimensions in a manner resembling a horse saddle. We’re often going to refer to hyperbolic parabaloids as <em>saddles</em> because their full name is a bit of a mouthful, and because we are mainly interested in contrasting these with planes. However, it’s important to keep in mind that hyperbolic parabaloids are one among many types of saddle surface.</p>
<p>The function for a hyperbolic parabaloid can be seen below, where the height of the surface is equal to the product of some parameter <span class="math inline">\(d\)</span> and its <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> coordinates.</p>
<p><span class="math display" id="eq:11-6">\[
\begin{equation}
z = d \cdot x \cdot y
\tag{11.6}
\end{equation}
\]</span></p>
<p>Clearly, the interaction of quantitative predictors results in a saddle shape as defined in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-6">(11.6)</a>. When our models include effects for x, y, <em>and</em> their interactions (cross product), we are effectively modeling a surface that combines a plane and a saddle shape, as in equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-2">(11.2)</a>. In figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-3">11.3</a> we can see a comparison of a plane in the top row and a saddle shape in the middle row. In the middle row on the left we can imagine that if we were walking ‘into’ the plot, the ground would first be sloping down left to right. However, as we proceeded into the plot the ground would gradually change so that it is sloping up from left to right further into the figure. In other words, the left-to-right slope would gradually increase as we walk further into the plot.</p>
<div class="figure"><span style="display:block;" id="fig:F11-3"></span>
<img src="_main_files/figure-html/F11-3-1.jpeg" alt="(top row) Three perspectives of the same plane. (middle row) Three perspectives of the same saddle shape. (bottom row) Three perspectives of the sum of the plane and the saddle shape in the top two rows." width="4800" />
<p class="caption">
Figure 11.3: (top row) Three perspectives of the same plane. (middle row) Three perspectives of the same saddle shape. (bottom row) Three perspectives of the sum of the plane and the saddle shape in the top two rows.
</p>
</div>
<p>We can combine a plane and a saddle, as in the bottom row of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-3">11.3</a>. The general formula for such a shape is presented below, and we’ve placed the terms in parentheses just to make it easier to interpret the equation. Notice that all we really did was add the term for the saddle shape in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-6">(11.6)</a> to the plane in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-1">(11.1)</a>.</p>
<p><span class="math display" id="eq:11-7">\[
\begin{equation}
z =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y) + (\mathrm{d} \cdot x \cdot y)
\tag{11.7}
\end{equation}
\]</span></p>
<div id="centering-quantitative-predictors-when-including-interactions" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Centering quantitative predictors when including interactions<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#centering-quantitative-predictors-when-including-interactions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When you include interactions between quantitative predictors in your regression models, it may be useful to center these predictors because this can improve your model convergence statistics, and can also improve the interpretability of the model. Convergence statistics can be improved by centering because this can reduce the correlation between the predictors and their cross product in many cases. To see why, consider the very simple example shown below:</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb403-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>)</span>
<span id="cb403-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-3" aria-hidden="true" tabindex="-1"></a>x1x2 <span class="ot">=</span> x1 <span class="sc">*</span> x2 </span>
<span id="cb403-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-4" aria-hidden="true" tabindex="-1"></a>x1x2</span>
<span id="cb403-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1 4 9</span></span>
<span id="cb403-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb403-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span> (<span class="fu">cbind</span>(x1,x2,x1x2))</span>
<span id="cb403-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-8" aria-hidden="true" tabindex="-1"></a><span class="do">##          x1     x2   x1x2</span></span>
<span id="cb403-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-9" aria-hidden="true" tabindex="-1"></a><span class="do">## x1   1.0000 1.0000 0.9897</span></span>
<span id="cb403-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-10" aria-hidden="true" tabindex="-1"></a><span class="do">## x2   1.0000 1.0000 0.9897</span></span>
<span id="cb403-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb403-11" aria-hidden="true" tabindex="-1"></a><span class="do">## x1x2 0.9897 0.9897 1.0000</span></span></code></pre></div>
<p>The cross product of <code>x1</code> and <code>x2</code>, <code>x1x2</code>, increases in value together with both predictors, meaning it enters into a <strong>monotonic</strong> relationship with the predictors (they increase and decrease together). This results in the strong correlation between the cross product and the predictors seen above. We can help minimize this sort of correlation if we center <code>x1</code> and <code>x2</code>. When we do this, the centered values will be positive when they are above the sample mean and negative when they are below it. Under these conditions, their cross product will be positive when both variables are above or below their mean, and negative when one is above and the other is below. This breaks the monotonic relationship between the cross product and the predictors, i.e., the cross product does not always increase when one of the predictors increases.</p>
<p>We re-do the example above with ‘centered’ data, assuming that the mean had been 2. We can see that the correlation between the cross product and the predictors is now zero, though the correlation between the predictors themselves is still one.</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>) </span>
<span id="cb404-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>) </span>
<span id="cb404-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-3" aria-hidden="true" tabindex="-1"></a>x1x2 <span class="ot">=</span> x1 <span class="sc">*</span> x2 </span>
<span id="cb404-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-4" aria-hidden="true" tabindex="-1"></a>x1x2</span>
<span id="cb404-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-5" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1 0 1</span></span>
<span id="cb404-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb404-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-7" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span> (<span class="fu">cbind</span>(x1,x2,x1x2))</span>
<span id="cb404-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-8" aria-hidden="true" tabindex="-1"></a><span class="do">##      x1 x2 x1x2</span></span>
<span id="cb404-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-9" aria-hidden="true" tabindex="-1"></a><span class="do">## x1    1  1    0</span></span>
<span id="cb404-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-10" aria-hidden="true" tabindex="-1"></a><span class="do">## x2    1  1    0</span></span>
<span id="cb404-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb404-11" aria-hidden="true" tabindex="-1"></a><span class="do">## x1x2  0  0    1</span></span></code></pre></div>
<p>We include a less controlled example of this below. We generate two samples of 100 random Gaussian variables (<code>x1, x2</code>) with a mean of 500 and a standard deviation of 1. These variables are not strongly correlated (-0.06), and yet their cross product (<code>x1x2</code>) is strongly correlated with both variables (0.67, and 0.70).</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-1" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">=</span> <span class="fu">rnorm</span> (<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1</span>)</span>
<span id="cb405-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-2" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">=</span> <span class="fu">rnorm</span> (<span class="dv">100</span>,<span class="dv">500</span>,<span class="dv">1</span>)</span>
<span id="cb405-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-3" aria-hidden="true" tabindex="-1"></a>x1x2 <span class="ot">=</span> x1<span class="sc">*</span>x2</span>
<span id="cb405-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb405-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span> (<span class="fu">cbind</span>(x1,x2,x1x2))</span>
<span id="cb405-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-6" aria-hidden="true" tabindex="-1"></a><span class="do">##            x1       x2   x1x2</span></span>
<span id="cb405-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-7" aria-hidden="true" tabindex="-1"></a><span class="do">## x1    1.00000 -0.05803 0.6747</span></span>
<span id="cb405-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-8" aria-hidden="true" tabindex="-1"></a><span class="do">## x2   -0.05803  1.00000 0.6977</span></span>
<span id="cb405-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb405-9" aria-hidden="true" tabindex="-1"></a><span class="do">## x1x2  0.67472  0.69768 1.0000</span></span></code></pre></div>
<p>We re-do the code above, this time after centering <code>x1</code> and <code>x2</code>. We can see that centering can dramatically reduce the correlation between the quantitative predictors and the interaction between them.</p>
<div class="sourceCode" id="cb406"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb406-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-1" aria-hidden="true" tabindex="-1"></a>x1_c <span class="ot">=</span> x1 <span class="sc">-</span> <span class="fu">mean</span> (x1)</span>
<span id="cb406-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-2" aria-hidden="true" tabindex="-1"></a>x2_c <span class="ot">=</span> x2 <span class="sc">-</span> <span class="fu">mean</span> (x2)</span>
<span id="cb406-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-3" aria-hidden="true" tabindex="-1"></a>x1x2_c <span class="ot">=</span> x1_c <span class="sc">*</span> x2_c</span>
<span id="cb406-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb406-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span> (<span class="fu">cbind</span>(x1_c,x2_c,x1x2_c))</span>
<span id="cb406-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-6" aria-hidden="true" tabindex="-1"></a><span class="do">##            x1_c     x2_c   x1x2_c</span></span>
<span id="cb406-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-7" aria-hidden="true" tabindex="-1"></a><span class="do">## x1_c    1.00000 -0.05803 -0.05193</span></span>
<span id="cb406-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-8" aria-hidden="true" tabindex="-1"></a><span class="do">## x2_c   -0.05803  1.00000  0.12431</span></span>
<span id="cb406-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb406-9" aria-hidden="true" tabindex="-1"></a><span class="do">## x1x2_c -0.05193  0.12431  1.00000</span></span></code></pre></div>
<p>In terms of the interpretability of your coefficients, it’s very important to keep in mind that in the presence of an interaction, the ‘main effect’ slope along a dimension is only the actual slope <em>when all other predictors involved in the interaction are equal to zero</em>. For example, consider a model including quantitative predictors <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, and the interaction between them. As shown in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-3">(11.3)</a>, the effective slope for <span class="math inline">\(x_1\)</span> in the presence of an interaction between <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> varies as a function of the value of <span class="math inline">\(x_2\)</span>. However, when <span class="math inline">\(x_2\)</span> is equal to zero its influence on the slope of <span class="math inline">\(x_1\)</span> is erased, and the slope of <span class="math inline">\(x_1\)</span> reported by your model applies. If you don’t center, <span class="math inline">\(x_2\)</span> = 0 may not occur in your data, meaning that the slope reported by your model is not actually expected to occur for your data. In contrast, if you center your predictors the slope for <span class="math inline">\(x_1\)</span> reported by your model represents the slope along this dimension when <span class="math inline">\(x_2\)</span> is at its mean.</p>
<p>Because of these advantages, you should consider centering quantitative predictors routinely whenever you plan to include interactions between these in your models, in the absence of a compelling reason not to (e.g., that 0 is a meaningful value for your predictors). Actually, as discussed in section <a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-centering">9.3.2</a>, you may find it useful to center quantitative predictors even if you are <em>not</em> including interactions between them.</p>
</div>
<div id="data-and-research-questions-7" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Data and research questions<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-7" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The models we fit in chapter 9 and 10 were missing an obvious and important predictor: The fundamental frequency (f0) of the speaker’s voice. The fundamental frequency of a sound is the main acoustic correlate of perceived pitch. We know from previous studies that, in general, speakers with lower speaking f0s tend to be identified as taller (see chapter 13 for a discussion of this). In this section, we’re going to fit a model that tries to predict apparent height from VTL, f0, and the interaction of the two.</p>
<p>Below we load our packages and data, and center our quantitative predictors. We also scale f0 so that it has a reasonably similar between-group difference as the VTL predictor. Specifically, the average difference in VTL between adult females and males is about 2 cm, and the difference in f0 between the groups is about 100 Hz. This means that if we divide f0 by 100 the difference between men and women is about 1 unit, comparable to the 2 unit difference between these groups in VTL. The reason we don’t divide by 50 to make them even more similar is that dividing by 100 results in frequencies being represented in hectohertz (1 hectohertz = 100 Hertz), which is easier to interpret than 50 Hz units.</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (brms)</span>
<span id="cb407-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (bmmb)</span>
<span id="cb407-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&#39;contr.sum&#39;</span>,<span class="st">&#39;contr.sum&#39;</span>))</span>
<span id="cb407-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span> (exp_data)</span>
<span id="cb407-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-7" aria-hidden="true" tabindex="-1"></a><span class="co"># center VTL</span></span>
<span id="cb407-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-8" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>vtl_original <span class="ot">=</span> exp_data<span class="sc">$</span>vtl</span>
<span id="cb407-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-9" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>vtl <span class="ot">=</span> exp_data<span class="sc">$</span>vtl <span class="sc">-</span> <span class="fu">mean</span> (exp_data<span class="sc">$</span>vtl)</span>
<span id="cb407-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb407-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-11" aria-hidden="true" tabindex="-1"></a><span class="co"># center and scale f0</span></span>
<span id="cb407-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-12" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0_original <span class="ot">=</span> exp_data<span class="sc">$</span>f0 </span>
<span id="cb407-13"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-13" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0 <span class="ot">=</span> exp_data<span class="sc">$</span>f0 <span class="sc">-</span> <span class="fu">mean</span>(exp_data<span class="sc">$</span>f0)</span>
<span id="cb407-14"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb407-14" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0 <span class="ot">=</span> exp_data<span class="sc">$</span>f0 <span class="sc">/</span> <span class="dv">100</span></span></code></pre></div>
<p>We’re not going to have well-defined research questions this time. Instead, we have a more ‘meta’ question that we will try to deal with:</p>
<p>(Q1) What do we do with all these parameters? How do we know what to focus on, and where to begin?</p>
</div>
<div id="c11-description-1" class="section level3 hasAnchor" number="11.3.3">
<h3><span class="header-section-number">11.3.3</span> Description of the model<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-description-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’re going to begin with a model that includes all possible interactions between our predictors, and also includes listener-dependent versions of all of our ‘fixed’ effects parameters. Models of this sort are sometimes referred to as <strong>maximal</strong> models because they include the maximal (i.e. most complicated) random effects structure ‘supported’ by the data (see section <a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-identifiability">8.8</a>). This means that we include corresponding ‘random’ listener effects for each of our ‘fixed’ effects predictors. However, notice that we don’t include any speaker-dependent predictors in our model (other than intercepts). This is because each speaker had a single f0 and VTL, and many were only identified as either male or female, or only as either adults or children. As a result, estimating interactions between these predictors and speaker is not <em>supported</em> by our data. Our model formula is:</p>
<p><code>height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S)</code></p>
<p>We’re going to use the same priors we used for our regression models in chapter 9. We won’t present the full model description as this is too long at this point, and all of the required elements have already been presented and discussed at this point. However, we can talk about all our model coefficients and what they mean for our model. Below is an ‘expanded’ version of our model formula that spells out all of the fixed effect parameters implied by the formula above.</p>
<pre><code>height ~ Intercept + vtl + f0 + A + G + 
         A:G1 + vtl:f0 + vtl:A + vtl:G + f0:A + f0:G + 
         vtl:f0:A + vtl:f0:G + vtl:A:G + f0:A:G + vtl:f0:A:G</code></pre>
<p>We can group these parameters together based on the way they affect the surfaces they represent: Intercept parameters (<code>a</code>), VTL slope parameters (<code>b</code>), f0 parameters (<code>c</code>), and VTL:f0 interaction parameters (<code>d</code>).</p>
<pre><code>a = Intercept + A        + G        + A:G 
b = vtl       + vtl:A    + vtl:G    + vtl:A:G
c = f0        + f0:A     + f0:G     + f0:A:G
d = vtl:f0    + vtl:f0:A + vtl:f0:G + vtl:f0:A:G</code></pre>
<p>Notice that there is a symmetry to the parameters for each ‘dimension’ in our model. Each one contains a ‘main effect’ term (<code>Intercept, vtl, f0, vtl:f0</code>), an interaction with apparent age (<code>A, vtl:A, f0:A, vtl:f0:A</code>), an interaction with apparent gender (<code>G, vtl:G, f0:G, vtl:f0:G</code>), and an interaction with apparent age <em>and</em> gender (<code>A:G, vtl:A:G, f0:A:G, vtl:f0:A:G</code>). This means that our models have intercepts, slopes (along two dimensions), and a saddle component (<code>d</code>), that can each vary as a function of apparent gender, age, and the interaction of the two. This is a complicated model, which is why it has so many parameters. In fact, it actually has many more parameters than this. For example, to calculate the listener dependent <code>a,b,c</code> and <code>d</code> parameters, which we can call <code>a_L, b_L, c_L</code> and <code>d_L</code>, we would need to add the following (hypothetical) parameters (implied by this <code>(vtl*f0*A*G|L)</code>) to our calculations.</p>
<pre><code>a_L = a + Intercept:L + A:L        + G:L        + A:G:L 
b_L = b + vtl:L       + vtl:A:L    + vtl:G:L    + vtl:A:G:L
c_L = c + f0:L        + f0:A:L     + f0:G:L     + f0:A:G:L
d_L = d + vtl:f0:L    + vtl:f0:A:L + vtl:f0:G:L + vtl:f0:A:G:L</code></pre>
<p>As a result, the calculation of the intercept alone would actually be:</p>
<p><code>a = Intercept + A + G + A:G + Intercept:L + A:L + G:L + A:G:L</code></p>
<p>Which can be rearranged to show that it is simply the sum of each corresponding ‘fixed’ effect and the corresponding listener-dependent effect.</p>
<p><code>a = (Intercept + Intercept:L) + (A + A:L) + (G + G:L) + (A:G + A:G:L)</code></p>
<p>This relatively complex model has been built up out of parts: We discussed the decomposition of intercepts into multiple factors, as in <span class="math inline">\(a\)</span> in chapter 7. We discussed the inclusion of quantitative predictors and the decomposition of variation in these, as in <span class="math inline">\(b\)</span> and <span class="math inline">\(c\)</span> in chapter 9. Now, we discuss the addition of more quantitative predictors (<span class="math inline">\(c\)</span>) and the interactions between these (<span class="math inline">\(d\)</span>). Effectively, we have been incrementally adding complexity to our models and, from here on, increasing complexity mostly consists of sticking together larger numbers of these basic components in different ways.</p>
<p>We said we weren’t going to provide a formal definition of this model, but if we had, the first few lines might have looked something like this:</p>
<p><span class="math display" id="eq:11-8">\[
\begin{equation}
\begin{split}
\mathrm{height}_{[i]} \sim \mathrm{t}(\nu, \mu_{[i]},\sigma) \\
\mu_{[i]} = a_{[i]} +  (b_{[i]} \cdot \mathrm{vtl}_{[i]}) + (c_{[i]} \cdot \mathrm{f0}_{[i]}) + (d_{[i]} \cdot \mathrm{f0}_{[i]} \cdot \mathrm{vtl}_{[i]}) \\
\ldots
\end{split}
\tag{11.8}
\end{equation}
\]</span></p>
<p>And the following lines would have described <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, <span class="math inline">\(c\)</span>, and <span class="math inline">\(d\)</span> as the sum of the appropriate model parameters as we did above (for <code>a</code> and <code>a_L</code>). Below, we provide an abbreviated plain English description corresponding to this formula:</p>
<p><code>height ~ vtl*f0*A*G + (vtl*f0*A*G|L) + (1|S)</code>.</p>
<blockquote>
<p>Apparent speaker height is predicted based on two quantitative variables, speaker f0 and VTL, and two categorical variables, apparent gender and apparent age. Our model includes all possible interactions between these predictors, resulting in 16 ‘fixed’ effects predictors (see above). Our model also included listener dependent effects for all fixed effects, which were drawn from a 16-dimensional normal distribution whose standard deviations and covariance matrix were estimated from the data. Our model included speaker dependent intercepts drawn from a normal distribution with a mean of zero and a standard deviation estimated from the data. All remaining parameters were given prior distributions appropriate for their expected range of values.</p>
</blockquote>
</div>
<div id="fitting-the-model-2" class="section level3 hasAnchor" number="11.3.4">
<h3><span class="header-section-number">11.3.4</span> Fitting the model<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-the-model-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We fit our model using the code below:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb411-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-2" aria-hidden="true" tabindex="-1"></a>priors <span class="ot">=</span> <span class="fu">c</span>(brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb411-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-3" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb411-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-4" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb411-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-5" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;lkj_corr_cholesky (2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;cor&quot;</span>), </span>
<span id="cb411-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-6" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;gamma(2, 0.1)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;nu&quot;</span>),</span>
<span id="cb411-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-7" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>))</span>
<span id="cb411-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-9" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0 <span class="ot">=</span>  </span>
<span id="cb411-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-10" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">brm</span> (height <span class="sc">~</span> vtl<span class="sc">*</span>f0<span class="sc">*</span>A<span class="sc">*</span>G <span class="sc">+</span> (vtl<span class="sc">*</span>f0<span class="sc">*</span>A<span class="sc">*</span>G<span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data =</span> exp_data, </span>
<span id="cb411-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">5000</span>, <span class="at">thin =</span> <span class="dv">4</span>, </span>
<span id="cb411-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb411-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">prior =</span> priors, <span class="at">family =</span> <span class="st">&quot;student&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb412-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb412-2" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0 <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;11_model_height_vtl_f0.RDS&#39;</span>)</span></code></pre></div>
<p>Normally this is where we would discuss and interpret the characteristics of our model. We’re going to leave this for chapter 13, where we present a model very similar to this in a format more similar to what you might see in an academic journal. Instead, we will discuss some advantages of working with Bayesian models over some more ‘traditional’ (although still modern) approaches.</p>
</div>
<div id="advantages-of-bayesian-multilevel-models-for-large-models" class="section level3 hasAnchor" number="11.3.5">
<h3><span class="header-section-number">11.3.5</span> Advantages of Bayesian multilevel models for large models<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#advantages-of-bayesian-multilevel-models-for-large-models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>At this point we have learned enough components to build very large and complicated models, like the one we fit above. Traditionally, models with many predictors have presented researchers with some combination of the three general problems outlined at the beginning of this chapter. In this section we’re going to discuss how working with multilevel Bayesian models can help us with problems (1) and (2) above. In the following section we’ll discuss an approach to solving problem (3) as well.</p>
<p>The Bayesian models fit by <code>brms</code> have two properties that help minimize the first two problems above. First, the use of prior probabilities and shrinkage, when properly applied, tend to ‘pull’ weakly-supported parameter values closer to the group mean (or to zero). This can help reduce many of the problems associated with models with large numbers of parameters (Gelman et al. 2012). Second, the fact that credible intervals are provided for all parameters helps distinguish random variation from variation that is unlikely to be small or zero.</p>
<p>To this point, we have not discussed the <code>lmer</code> function (from the <code>lme4</code> package) very much apart from in ‘Traditionalist corner’ at the end of some chapters. The <code>lmer</code> function (linear mixed-effects regression) is an extremely popular and extremely useful function. In general, <code>lmer</code> and an equivalent model specified in <code>brms</code> should result in very similar results when fit to the same data. However, there are some important differences between the two approaches. First, rather than provide a distribution of samples for each parameter, <code>lmer</code> returns <em>point estimates</em> representing the <em>best</em> values of parameters, in addition to estimated intervals around some (but not all) parameters. A second difference between <code>lmer</code> and our Bayesian multilevel models is that <code>lmer</code> doesn’t use prior probabilities to estimate most of its parameters. This can cause some problems when estimating large numbers of parameters without large amounts of data.</p>
<p>We’re going to compare the output of <code>lmer</code> and <code>brms</code> for the model we fit above. Just to be clear, our intention in comparing <code>lmer</code> and <code>brms</code> is not to compare different statistical <em>philosophies</em> or epistemological systems. Our aim is much, much more modest than that. We simply wish to compare <code>brms</code>, an approach that 1) uses priors, and 2) provides intervals for all parameters, to a broadly similar approach that does not (<code>lmer</code>). Below we fit a model equivalent to <code>model_height_vtl_f0</code> using <code>lmer</code>.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb413-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb413-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb413-2" aria-hidden="true" tabindex="-1"></a>lme_model_height_vtl_f0 <span class="ot">=</span></span>
<span id="cb413-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb413-3" aria-hidden="true" tabindex="-1"></a>  lme4<span class="sc">::</span><span class="fu">lmer</span> (height <span class="sc">~</span> vtl<span class="sc">*</span>f0<span class="sc">*</span>A<span class="sc">*</span>G <span class="sc">+</span> (vtl<span class="sc">*</span>f0<span class="sc">*</span>A<span class="sc">*</span>G<span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), </span>
<span id="cb413-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb413-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>exp_data,<span class="at">verbose =</span> <span class="cn">TRUE</span>,</span>
<span id="cb413-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb413-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">control=</span>lme4<span class="sc">::</span><span class="fu">lmerControl</span>(<span class="at">optCtrl=</span><span class="fu">list</span>(<span class="at">maxfun=</span><span class="dv">20000</span>),<span class="at">optimizer=</span><span class="st">&quot;bobyqa&quot;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb414-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb414-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb414-2" aria-hidden="true" tabindex="-1"></a>lme_model_height_vtl_f0 <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;11_lme_model_height_vtl_f0.RDS&#39;</span>)</span></code></pre></div>
<p>We won’t show the model print statements as they are both quite large, but we compare the estimates of our fixed effects in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-4">11.4</a>. Clearly, the two approaches provide very similar estimates for the model fixed effects. That’s reassuring because if results differed dramatically for approximately the same model based on the software used, we would need to think very carefully about the causes and possible meaning of these differences.</p>
<div class="figure"><span style="display:block;" id="fig:F11-4"></span>
<img src="_main_files/figure-html/F11-4-1.jpeg" alt="A comparison of fixed effect estimates provided by the brms (red) and lmer (black) models. The brms intervals are the 95% credible intervals, those for lmer are twice the standard error of the parameter estimate. Filled points have 95% credible intervals that exceed 0.5 cm." width="4800" />
<p class="caption">
Figure 11.4: A comparison of fixed effect estimates provided by the brms (red) and lmer (black) models. The brms intervals are the 95% credible intervals, those for lmer are twice the standard error of the parameter estimate. Filled points have 95% credible intervals that exceed 0.5 cm.
</p>
</div>
<p>Since our model has a large number of parameters we’re going to focus on interpreting those that seem likely to result in ‘meaningful’ differences in apparent height, about 1 cm (as discussed in Section <a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-answering">7.7</a>). We will discuss the Bayesian model fixed effects, which you can see by running <code>fixef(model_height_vtl_f0)</code>. Our model suggests non-zero slopes for our plane along the VTL (mean = 3.12, s.d. = 0.64, 95% C.I = [1.85, 4.4]) and f0 dimensions (mean = -3.52, s.d. = 1.45, 95% C.I = [-6.32, -0.63]). However, there is not much evidence that the cross-product term (<code>vtl:f0</code>) has a meaningful non-zero value (mean = -1.28, s.d. = 1.05, 95% C.I = [-3.32, 0.81]). This means that our responses can be predicted by a flat plane along f0 and VTL without curving the plane into a saddle shape. The <code>vtl:A1</code> interaction suggests a differing use of VTL based on apparent adultness (mean = -2.02, s.d. = 0.51, 95% C.I = [-3.03, -1.02]), but there do not appear to be any other meaningful interactions between VTL, f0 and the other predictors.</p>
<p>In terms of intercept terms (i.e. those not interacting with quantitative predictors), there is a large effect for apparent age (mean = 7.04, s.d. = 1.18, 95% C.I = [4.69, 9.35]) but no main effect for apparent gender (mean = -0.17, s.d. = 0.75, 95% C.I = [-1.63, 1.36]). However, the interaction between apparent age and apparent gender (<code>A1:G1</code>) had a 95% credible interval that did not overlap with zero and had a posterior mean value of -1.72 cm (s.d. = 0.61, 95% C.I = [-2.9, -0.5]). This indicates that although apparent gender had an average effect of about 0 cm on apparent height it may have had meaningful, but opposite, effects based on the apparent age of the speaker.</p>
<p>In order to interpret our predictors in the presence of interactions, we need to consider the simple effects. For example, in order to consider the <code>vtl:A1</code> interaction we need to find the simple effect of VTL for apparent children, and then for apparent adults. This is done in the manner outlined in chapter 9 for quantitative predictors, independently for each dimension (predictor or cross-product). We’re not going to go over the interpretation of the coefficients and the reconstruction of the simple effects here, as this will be carried out in chapter 13.</p>
<p>Whereas figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-4">11.4</a> focused on the similarity of our <code>lmer</code> and <code>brm</code> models, figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> presents some ways that these models differ. In the top row we see a comparison of the ‘random effects’ standard deviation estimates, and the error terms (i.e., <code>sigma</code> or <span class="math inline">\(\sigma\)</span>), estimated by our two models. For example, the standard deviation of the listener f0 ‘random effect’ (<code>f0:L</code>, <span class="math inline">\(\sigma_{F0 \colon L}\)</span>) represents the amount of variation between the listener-specific effects for f0 in each model. As we can see, the models provide reasonably similar standard deviation estimates for many, if not most, parameters. However, note that the <code>brm</code> model provides intervals for all parameters, while the <code>lmer</code> model only provides point estimates for these.</p>
<div class="figure"><span style="display:block;" id="fig:F11-5"></span>
<img src="_main_files/figure-html/F11-5-1.jpeg" alt="Points and intervals represent means and 95% credible intervals for brms parameter estimates for `model_height_vtl_f0`. Crosses indicate point estimates provided in `lme_model_height_vtl_f0`. (top) Estimates of random effect standard deviations. (middle) Estimates for the listener dependent effects of apparent age. (bottom) Estimates of correlations between listener random effects." width="4800" />
<p class="caption">
Figure 11.5: Points and intervals represent means and 95% credible intervals for brms parameter estimates for <code>model_height_vtl_f0</code>. Crosses indicate point estimates provided in <code>lme_model_height_vtl_f0</code>. (top) Estimates of random effect standard deviations. (middle) Estimates for the listener dependent effects of apparent age. (bottom) Estimates of correlations between listener random effects.
</p>
</div>
<p>The lack of intervals on parameter estimates makes it difficult to ‘rule out’ variance parameters since they will <em>never</em> equal exactly zero. So, we will always have non-zero estimates for these parameters, and ‘secretly’ some of these are zero or nearly zero. Notice that it is difficult to predict which standard deviation parameters are distinguishable from zero based on their magnitude alone. For example, consider <code>G1:L</code> and <code>vtl:f0:G1:L</code> in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a>. Our <code>lmer</code> model provides estimates of about the same magnitude for these two components, but our <code>brms</code> model credible intervals suggest that one of these is likely to be larger than the other. So, we can use our credible intervals to figure out which variance components are unlikely to matter: Variance components whose credible intervals are concentrated near zero. There are several such components in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a>. For example, consider the listener-dependent interaction between VTL and apparent gender <code>vtl:G1:L</code>. If this variation is non zero, in the <em>best case</em>, this component reflects a tiny amount of systematic variation in our outcomes and so is unlikely to matter much.</p>
<p>Variance components very close to zero can sometimes cause problems when estimating models. For example, fitting our <code>lmer</code> model resulted in the following error:</p>
<p><code>boundary (singular) fit: see help('isSingular')</code></p>
<p>Which warns us that some of the variance components we are trying to estimate are quite small. However, the estimation of small variance components is not generally problematic for models fit using <code>brms</code> (and <em>Stan</em>).</p>
<p>In the middle plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> we see a comparison of the listener-dependent <code>A1</code> ‘random effects’ (i.e. <code>A1:L</code>) estimated using <code>brms</code> and <code>lmer</code>. Just as with the estimates of the fixed effects in the middle plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-4">11.4</a>, we see a close alignment between the two approaches. However, just as for our standard deviation terms, we see that a lack of intervals around our <code>lmer</code> estimates makes it difficult to compare our parameter estimates to specific values (such as zero).</p>
<p>Finally, in the bottom plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> we compare the correlations for the listener random effects across the two models. Since there were 16 listener-dependent parameters, we needed to estimate 120 unique correlations between these parameters. As with our standard deviation parameters, <code>brms</code> gives us intervals while <code>lmer</code> returns point estimates. In addition, for the first time we see a substantial difference between the estimates provided by <code>lmer</code> and those provided by <code>brms</code>. This is likely a result of the fact that <code>lmer</code> does not use adaptive pooling, or shrinkage, to estimate correlations. As a result, we see that the <code>lmer</code> estimates vary substantially around 0 while the <code>brms</code> estimates are mostly close to zero and have intervals that include zero. We see that in this case our Bayesian model protects us by: 1) Providing credible intervals for all parameters, letting us accept values of zero as likely, and 2) the LKJ prior we used for our random effect correlation matrices pulls weakly-supported correlations to zero, thereby protecting against spurious results.</p>
<p>The fact that most of our correlation estimates are nearly zero not only lets us rule many out as not interesting, but also focuses our attention on those correlations that <em>do</em> deviate from this pattern. For example, the third correlation from the left in the bottom plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> represents the correlation between the listener-dependent intercepts and effects for apparent age. Although its 95% credible interval includes some very small values (mean = -0.38, s.d. = 0.17, 95% C.I = [-0.69, -0.01]), it seems reasonable that this correlation may in fact be negative and non-zero. In fact, we found this correlation in a previous model and also discussed why we think this correlation ‘makes sense’ (in section <a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-answering">6.5</a>).</p>
</div>
</div>
<div id="c11-BANOVA" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Bayesian Analysis of Variance<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-BANOVA" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The information we presented in the previous section can be used to consider which predictors, or groups of predictors, are important for understanding variation in the dependent variable. This approach becomes more and more useful as our models increase in complexity and we end up with dozens or hundreds of parameters that we then need to interpret. The framework to be presented here is outlined by by Gelman and colleagues in Gelman (2005), Gelman and Hill (2006, chapter 22), and Gelman et al. (2013, chapter 15).</p>
<p>The <strong>analysis of variance</strong> (<strong>ANOVA</strong>) is a set of modeling techniques meant to help understand the components of variation in a dependent variable. A ‘traditional’ ANOVA tries to <strong>decompose</strong> variation in the dependent variable into independent components. It then carries out different statistical tests by relating the different variance components as ratios and comparing values to a reference distribution. If those statements make no sense to you, that’s because that approach is fundamentally different to the sorts of things we’ve been doing with our multilevel Bayesian models. We’re not going to talk about a ‘traditional’ ANOVA in any detail here as that would involve the introduction of a <em>parallel universe</em> of statistical concepts and jargon that has not been discussed in this book. In addition, there are many excellent treatments on the subject including Myers et al. (2013), Pedhazur and Schmelkin (2013), and Wickens and Keppel (2004). That being said, we can discuss how ANOVA features concepts that are very useful for Bayesian multilevel models.</p>
<p>At its core ANOVA consists of thinking of variation in the dependent variable as the sum of a set of <strong>components of variation</strong> related to the predictors in our model. For example, consider the formula for <code>model_four_groups</code> we fit in chapter 7:</p>
<p><code>height ~ C + (C|L) + (1|S)</code></p>
<p>This formula implies a model with a relatively large number of parameters. These parameters can be thought of as ‘batches’ of thematically related coefficients. For example, we can think of the following batches of parameters:</p>
<ul>
<li>3 parameters representing the fixed effects for apparent speaker category <code>C</code>: <code>C1, C2, C3</code>.</li>
<li>15 parameters representing the listener-dependent intercepts.</li>
<li>45 (15 <span class="math inline">\(\cdot\)</span> 3) parameters representing the listener-dependent effects for parameters <code>C1</code>, <code>C2</code>, and <code>C3</code>.<br />
</li>
<li>139 parameters representing the speaker-dependent intercepts.</li>
</ul>
<p>Each of these batches has a thematic or semantic link; these are not just parameters grouped at random. When we break up variation into thematically-grouped parameters, we are doing an <strong>ANOVA-like decomposition</strong> of variation of the dependent variable. We introduced this approach in chapter 7 without directly referring to ANOVA and have generally been using this approach to understand variation in our predictors throughout the book. Here’s what Gelman and Hill (2006) have to say about the analysis of variance in the context of multilevel models:</p>
<blockquote>
<p>“When moving to multilevel modeling, the key idea we want to take from the analysis of variance is the estimation of the importance of different batches of predictors (“components of variation” in ANOVA terminology). As usual, we focus on estimation rather than testing: instead of testing the null hypothesis that a variance component is zero, we estimate the standard deviation of the corresponding batch of coefficients. If this standard deviation is estimated to be small, then the source of variation is minor—we do not worry about whether it is exactly zero. In the social science and public health examples that we focus on, it can be a useful research goal to identify important sources of variation, but it is rare that anything is truly zero.” (p. 490)</p>
</blockquote>
<p>Batches of parameters that vary a lot from each other reflect large differences in our dependent variable across the parameters. Batches of parameters that vary a lot from each other will have large standard deviations, i.e., they will be dispersed around the mean for that batch. In contrast, parameters that do not vary much from each other will be represented by small standard deviations, and will generally be close to their mean. These parameters do not have a large effect on our data (since they do not vary much).</p>
<p>For example, in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> we see that the standard deviation of listener-dependent intercepts (<code>Intercept:L</code>, <span class="math inline">\(\sigma_L\)</span>) is much larger than the listener-dependent interaction between VTL and apparent gender (<code>vtl:G1:L</code>, <span class="math inline">\(\sigma_{VTL \colon G \colon L}\)</span>). We can see that this directly relates to the variation of each batch of ‘random effects’ around zero, as shown in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-6">11.6</a>. Whether or not <span class="math inline">\(\sigma_{VTL \colon G \colon L}\)</span> is <em>exactly</em> zero, we can look at figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-6">11.6</a> and see that this predictor does not predict much variation in our dependent variable. As a result of this, by inspecting the standard deviations in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> we can see that although there are a large number of predictors, only a couple are having any meaningful effect on apparent height judgments.</p>
<div class="figure"><span style="display:block;" id="fig:F11-6"></span>
<img src="_main_files/figure-html/F11-6-1.jpeg" alt="Listener-dependent intercepts (Intercept:L) and vtl:G1 interactions (VTL:G1:L)." width="4800" />
<p class="caption">
Figure 11.6: Listener-dependent intercepts (Intercept:L) and vtl:G1 interactions (VTL:G1:L).
</p>
</div>
<p>Gelman and Hill (2006) distinguish two types of standard deviations for a ‘random’ effect with J levels (p. 459) (emphasis ours):</p>
<blockquote>
<p>“The <strong>superpopulation</strong> standard deviation, which represents the variation among the modeled probability distribution from which they were drawn, is relevant for determining the uncertainty about the value of a new group not in the original set of J.”</p>
</blockquote>
<blockquote>
<p>“The <strong>finite-population</strong> standard deviation of the particular J values of [some coefficient] describes variation within the existing data.”</p>
</blockquote>
<p>So, the <em>finite-population</em> standard deviation terms reflect the variation we observe in our actual model parameters. This concept can be applied to batches of ‘random’ effects estimated with adaptive partial pooling and to ‘fixed’ effects estimated with fixed priors. For example, if your estimated parameters are -1, 0, and 1, your finite-population estimate would be directly based on these values. In contrast, the <em>superpopulation</em> standard deviation estimates correspond to the specific <span class="math inline">\(\sigma_{\beta}\)</span> term estimated by our model for some batch <span class="math inline">\(\beta\)</span> of ‘random’ effects. No analogue exists for our ‘fixed’ effects, and so we can only get superpopulation standard deviations for batches of parameters fit with adaptive partial pooling (i.e. ‘random’ effects). Gelman and colleagues suggest the following general process, that can be referred to as a <strong>Bayesian analysis of variance</strong>, or <strong>BANOVA</strong>:</p>
<ol style="list-style-type: decimal">
<li>Fit the model with the structure you think is required to capture the variation in the data and answer your research questions.</li>
<li>Calculate the finite-population (and/or superpopulation) standard deviations for predictors or batches of predictors.</li>
<li>Make a plot comparing the magnitudes of different batches of predictors, and of the uncertainty in the estimates. The authors refer to this as an <strong>ANOVA plot</strong>.</li>
<li>Use the ANOVA plot to make inferences about the relative importance of your predictors, and to guide your analysis.</li>
</ol>
<p>We could potentially add a fifth step: 5) Re-fit a reduced model if some components show little to no meaningful variation, and if you have some compelling reason to do so. This step is not strictly necessary, and may even be a bad idea sometimes, but we will consider it as a possibility.</p>
<div id="getting-the-standard-deviations-from-our-models-manually" class="section level3 hasAnchor" number="11.4.1">
<h3><span class="header-section-number">11.4.1</span> Getting the standard deviations from our models ‘manually’<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#getting-the-standard-deviations-from-our-models-manually" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The superpopulation standard deviation is our model’s estimate of the standard deviation of a batch of parameters. We can extract the superpopulation standard deviations using the <code>VarCorr</code> function. This function returns all sorts of information about the variance and correlation parameters estimated by our model. In the second line below we specify that we only want information related to the standard deviation (<code>"sd"</code>) of our listener effects (<code>"L"</code>). We’re not goint to go into detail about the information provided by this function, but you can probably figure most of it out by inspecting the output carefully.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb415-1" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">VarCorr</span>(model_height_vtl_f0)</span>
<span id="cb415-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb415-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb415-3" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">VarCorr</span>(model_height_vtl_f0)[[<span class="st">&quot;L&quot;</span>]][[<span class="st">&quot;sd&quot;</span>]]</span></code></pre></div>
<p>We can also get information regarding our error (<span class="math inline">\(\sigma\)</span>, <code>sigma</code>) using <code>Varcorr</code> as seen below:</p>
<div class="sourceCode" id="cb416"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb416-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb416-1" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">VarCorr</span>(model_height_vtl_f0)<span class="sc">$</span>residual<span class="sc">$</span>sd</span>
<span id="cb416-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb416-2" aria-hidden="true" tabindex="-1"></a><span class="do">##  Estimate Est.Error  Q2.5 Q97.5</span></span>
<span id="cb416-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb416-3" aria-hidden="true" tabindex="-1"></a><span class="do">##     4.819    0.1576 4.515 5.137</span></span></code></pre></div>
<p>The <code>bmmb</code> package contains a function called <code>get_sds</code> that collects estimates of all standard deviations estimated by the model, including the error. We show the first five lines of the output of this function below.</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-1" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">get_sds</span> (model_height_vtl_f0)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb417-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-2" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error   Q2.5 Q97.5 group</span></span>
<span id="cb417-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Int.L    4.083    0.8450 2.7530 6.047     L</span></span>
<span id="cb417-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-4" aria-hidden="true" tabindex="-1"></a><span class="do">## vtl      1.767    0.5420 0.8613 3.020     L</span></span>
<span id="cb417-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-5" aria-hidden="true" tabindex="-1"></a><span class="do">## f0       1.868    1.0913 0.1007 4.281     L</span></span>
<span id="cb417-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-6" aria-hidden="true" tabindex="-1"></a><span class="do">## A1       4.009    0.8597 2.6786 6.047     L</span></span>
<span id="cb417-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb417-7" aria-hidden="true" tabindex="-1"></a><span class="do">## G1       1.970    0.5739 1.0015 3.307     L</span></span></code></pre></div>
<p>Getting the finite-sample standard deviations is a bit trickier. First, we should note that although they are called standard deviations, they are actually calculated by finding the root-mean squared error. The <strong>root-mean-squared</strong> (RMS) error for each batch of coefficients is exactly what it sounds like, it’s the (square) root of the mean square. In other words, as seen in equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-9">(11.9)</a>, you square a bunch of values, find the average of these, and then find the square root of this value.</p>
<p><span class="math display" id="eq:11-9">\[
\begin{equation}
RMS_x = \sqrt {\sum_{i=1}^{n} x_{[i]}^2 / n}
\tag{11.9}
\end{equation}
\]</span></p>
<p>Note that this is just like the formula to calculate the sample variance (equation <a href="probabilities-likelihood-and-inference.html#eq:2-4">(2.5)</a>) if we assume that the sample mean is equal to zero. In fact, when we use sum coding we <em>do</em> assume a mean of 0 for each batch of parameters and our parameters already reflect deviations from the mean. Further, remember that in all our model specifications each batch of random effects is assumed to have a mean of zero (i.e. the prior for <span class="math inline">\(L\)</span> is <span class="math inline">\(\mathrm{N}(0,\sigma_L)\)</span>). In addition, it’s possible that the sample mean of any given batch of random effects will actually <em>not</em> be zero. This is because there is no guarantee that the sample mean will equal the population mean (which we know to be zero), and this applies to our ‘random effects’ as it does to variables in general. As a result, we should use the RMS function when calculating the standard deviation for our batches of parameters.</p>
<p>To calculate the standard deviations of different batches of parameters you need to calculate the root-mean squared deviation for each batch, <em>for each sample</em>. This means you end up with an estimate of the finite-sample standard deviation for each set of posterior samples. For example, equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-10">(11.10)</a> has been updated to show the calculation of the RMS of the listener-dependent intercept terms (<span class="math inline">\(L\)</span>) across <span class="math inline">\(J\)</span> listeners. The little <span class="math inline">\(^s\)</span> superscript indicates that each calculation is made for an individual posterior sample (<span class="math inline">\(s\)</span>). As a result, the measure below will produce 4000 estimates of the RMS for <span class="math inline">\(L\)</span> given 4000 posterior samples.</p>
<p><span class="math display" id="eq:11-10">\[
\begin{equation}
RMS^s_L = \sqrt {\sum_{j=1}^{J} (L^s_{[j]})^2 / \,J}
\tag{11.10}
\end{equation}
\]</span></p>
<p>The code below shows how to calculate the finite-population standard deviations for listener based on the random effects parameter estimates.</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-1" aria-hidden="true" tabindex="-1"></a><span class="co"># extract matrix representing listener random intercepts from our model</span></span>
<span id="cb418-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-2" aria-hidden="true" tabindex="-1"></a>listener_intercepts <span class="ot">=</span> </span>
<span id="cb418-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>(model_height_vtl_f0, <span class="at">summary =</span> <span class="cn">FALSE</span>)[[<span class="st">&quot;L&quot;</span>]][,,<span class="st">&quot;Intercept&quot;</span>]</span>
<span id="cb418-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-5" aria-hidden="true" tabindex="-1"></a><span class="co"># the output is a 2d matrix. dimensions </span></span>
<span id="cb418-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-6" aria-hidden="true" tabindex="-1"></a><span class="co"># are: (rows) samples, (columns) parameters</span></span>
<span id="cb418-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-7" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (listener_intercepts)</span>
<span id="cb418-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-8" aria-hidden="true" tabindex="-1"></a><span class="do">##  num [1:4000, 1:15] 6.1 3.62 7.43 7.5 7.62 ...</span></span>
<span id="cb418-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  - attr(*, &quot;dimnames&quot;)=List of 2</span></span>
<span id="cb418-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-10" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : NULL</span></span>
<span id="cb418-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-11" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : chr [1:15] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</span></span>
<span id="cb418-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-13"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-13" aria-hidden="true" tabindex="-1"></a><span class="co"># we find the RMS error across each row in the matrix</span></span>
<span id="cb418-14"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-14" aria-hidden="true" tabindex="-1"></a>listener_intercepts_finite <span class="ot">=</span> <span class="fu">apply</span> (listener_intercepts,<span class="dv">1</span>,bmmb<span class="sc">::</span>rms)</span>
<span id="cb418-15"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-16"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-16" aria-hidden="true" tabindex="-1"></a><span class="co"># we summarize the output </span></span>
<span id="cb418-17"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-17" aria-hidden="true" tabindex="-1"></a>listener_intercepts_finite <span class="ot">=</span> </span>
<span id="cb418-18"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">posterior_summary</span> (listener_intercepts_finite)</span>
<span id="cb418-19"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb418-20"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-20" aria-hidden="true" tabindex="-1"></a>listener_intercepts_finite</span>
<span id="cb418-21"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-21" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate Est.Error  Q2.5 Q97.5</span></span>
<span id="cb418-22"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb418-22" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,]    3.926      0.39 3.243 4.772</span></span></code></pre></div>
<p>For the fixed effects, we can use the absolute value of the parameters when these are each a single ‘degree of freedom’ (i.e. a single parameter). The code below shows how to get the fixed effects standard deviation estimates assuming that all parameters are unrelated.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb419-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get individual parameter samples</span></span>
<span id="cb419-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb419-2" aria-hidden="true" tabindex="-1"></a>fixefs_finite <span class="ot">=</span> <span class="fu">fixef</span>(model_height_vtl_f0, <span class="at">summary =</span> <span class="cn">FALSE</span>)</span>
<span id="cb419-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb419-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb419-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb419-4" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize absolute value</span></span>
<span id="cb419-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb419-5" aria-hidden="true" tabindex="-1"></a>fixefs_finite <span class="ot">=</span> <span class="fu">posterior_summary</span> (<span class="fu">abs</span> (fixefs_finite))</span></code></pre></div>
<p>Finally, we can estimate the finite-sample error by getting the model residuals, and then calculating the standard deviation of the residuals for each set of samples as shown below.</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get residuals</span></span>
<span id="cb420-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-2" aria-hidden="true" tabindex="-1"></a>sigma_finite <span class="ot">=</span> <span class="fu">residuals</span> (model_height_vtl_f0, <span class="at">summary =</span> <span class="cn">FALSE</span>)</span>
<span id="cb420-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-4" aria-hidden="true" tabindex="-1"></a><span class="co"># find standard deviation for each set of samples</span></span>
<span id="cb420-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-5" aria-hidden="true" tabindex="-1"></a>sigma_finite <span class="ot">=</span> <span class="fu">apply</span> (sigma_finite, <span class="dv">1</span>, sd)</span>
<span id="cb420-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-7" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize</span></span>
<span id="cb420-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-8" aria-hidden="true" tabindex="-1"></a>sigma_finite <span class="ot">=</span> <span class="fu">posterior_summary</span> (sigma_finite)</span>
<span id="cb420-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb420-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-10" aria-hidden="true" tabindex="-1"></a><span class="co"># name row, because it has no name by default</span></span>
<span id="cb420-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb420-11" aria-hidden="true" tabindex="-1"></a><span class="fu">row.names</span>(sigma_finite) <span class="ot">=</span> <span class="st">&#39;sigma&#39;</span></span></code></pre></div>
<p>In the examples above, we treated each fixed effect predictor, and the interaction of each of these with listener, as independent. This is actually appropriate for this model because all our predictors <em>are</em> conceptually distinct so that we don’t really have batches of fixed effects. However, the process Gelman proposes is potentially more complicated than what we’ve done above. For example, imagine if we had included <code>C</code> as a predictor in our model and calculated the listener-dependent effects of <code>C</code>. This would result in the fixed effects <code>C1</code>, <code>C2</code>, and <code>C3</code>, 15 <code>C1:L</code> random effects, 15 <code>C2:L</code> random effects, and 15 <code>C3:L</code> random effects. The process described here would treat each of the 3 fixed effects as independent, and also treat each batch of 15 random effects as independent. In contrast, Gelman and colleagues recommend treating the 3 category-related fixed effects as a single batch, and the 45 category-related random effects as a single batch.</p>
<p>The main reason to do it the way we’ve shown above is because it can be done easily for all models, and you still get very useful information from the analysis. However, it is undeniable that, for example, treating the 45 <code>C:L</code> terms in our example above as related may be desirable in some cases. If you do want to investigate the variation associated with entire clusters of multiple predictors at a time, the code provided above can be modified to do this as necessary, and you should also probably see the readings referred to at the top of section <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-BANOVA">11.4</a>.</p>
</div>
<div id="using-the-banova-function" class="section level3 hasAnchor" number="11.4.2">
<h3><span class="header-section-number">11.4.2</span> Using the <code>banova</code> function<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#using-the-banova-function" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The <code>bmmb</code> package contains a function called <code>banova</code> that can get the finite-sample or superpopulation standard deviations for you. This function will only calculate standard deviations the ‘simple’ way outlined in the previous section, treating each fixed effect and the random effects for each individual parameter as an independent batch. The output of the <code>banova</code> function is a single data frame that contains a summary of the standard deviations for fixed and random effects, and the error term if the model contains one. Below we use the function to get both kinds of standard deviations compared in the previous section.</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb421-1" aria-hidden="true" tabindex="-1"></a>banova_height_vtl_f0_finite <span class="ot">=</span> </span>
<span id="cb421-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb421-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">banova</span> (model_height_vtl_f0, <span class="at">superpopulation =</span> <span class="cn">FALSE</span>)</span>
<span id="cb421-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb421-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb421-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb421-4" aria-hidden="true" tabindex="-1"></a>banova_height_vtl_f0_super <span class="ot">=</span> </span>
<span id="cb421-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb421-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">banova</span> (model_height_vtl_f0, <span class="at">superpopulation =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>The output of the <code>banova</code> function can be used to make a Bayesian ANOVA plot of our model using the <code>banovaplot</code> function in the <code>bmmb</code> package. An example of a Bayesian ANOVA plot is shown in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-7">11.7</a>. These plots compare the (absolute) values of your fixed effects, the standard deviation of different batches of random effects, and you residual error (<span class="math inline">\(\sigma\)</span>) if applicable. This is effectively the same information shown in the top row of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-5">11.5</a> save for the inclusion of the ‘fixed’ effects in the figure. If we make a BANOVA plot right after fitting our model, we would have a pretty good idea of which of our predictors are associated with meaningful variation in our dependent variable and which don’t seem to matter much.</p>
<div class="figure"><span style="display:block;" id="fig:F11-7"></span>
<img src="_main_files/figure-html/F11-7-1.jpeg" alt="(top) Finite sample BANOVA plot for `model_height_vtl_f0` showing the model error, fixed effects, listener random effects, and speaker random effects. (bottom) The superpopulation BANOVA plot for the same model." width="4800" />
<p class="caption">
Figure 11.7: (top) Finite sample BANOVA plot for <code>model_height_vtl_f0</code> showing the model error, fixed effects, listener random effects, and speaker random effects. (bottom) The superpopulation BANOVA plot for the same model.
</p>
</div>
</div>
<div id="fitting-and-comparing-the-reduced-model" class="section level3 hasAnchor" number="11.4.3">
<h3><span class="header-section-number">11.4.3</span> Fitting and comparing the reduced model<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-comparing-the-reduced-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our initial model formula was:</p>
<p><code>height ~ f0*vtl*A*G + (f0*vtl*A*G|L) + (f0*vtl*A*G|S)</code></p>
<p>Because we include all possible interactions between ‘fixed’ effects and listener ‘random effects’ for each predictor and interaction, we’re basically saying that we think its possible for every predictor to affect every other predictor, and for all of this to vary in a listener-dependent manner. We might instead consider the following model formula which includes only those effects we (arbitrarily) deemed ‘large enough’ based on our inspection of the Bayesian ANOVA above.</p>
<p><code>height ~ f0 + vtl + A*G + vtl:A1 + (f0 + vtl + A*G + vtl:A1|L) + (1|S)</code></p>
<p>In some situations we may be justified in fitting a ‘final’ model that includes only the important components. We fit the reduced model below:</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb422-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-2" aria-hidden="true" tabindex="-1"></a>priors <span class="ot">=</span> <span class="fu">c</span>(brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,160, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb422-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-3" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb422-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-4" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb422-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-5" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;lkj_corr_cholesky (2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;cor&quot;</span>), </span>
<span id="cb422-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-6" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;gamma(2, 0.1)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;nu&quot;</span>),</span>
<span id="cb422-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-7" aria-hidden="true" tabindex="-1"></a>           brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3,0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>))</span>
<span id="cb422-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb422-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-9" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0_reduced <span class="ot">=</span>  </span>
<span id="cb422-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-10" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">brm</span> (height <span class="sc">~</span> f0<span class="sc">+</span>vtl<span class="sc">+</span>A<span class="sc">*</span>G<span class="sc">+</span>vtl<span class="sc">:</span>A <span class="sc">+</span> (f0<span class="sc">+</span>vtl<span class="sc">+</span>A<span class="sc">*</span>G<span class="sc">+</span>vtl<span class="sc">:</span>A<span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S),</span>
<span id="cb422-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> exp_data, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, </span>
<span id="cb422-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb422-12" aria-hidden="true" tabindex="-1"></a>             <span class="at">iter =</span> <span class="dv">5000</span>, <span class="at">thin =</span> <span class="dv">4</span>, <span class="at">prior =</span> priors, <span class="at">family =</span> <span class="st">&quot;student&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb423-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb423-2" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0_reduced <span class="ot">=</span> </span>
<span id="cb423-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb423-3" aria-hidden="true" tabindex="-1"></a>  bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;11_model_height_vtl_f0_reduced.RDS&#39;</span>)</span></code></pre></div>
<p>We can see that the fixed effects shared in common are very similar, as are the estimates of the superpopulation random effects for the listener-dependent parameters (although intervals are wider for the full model).</p>
<div class="figure"><span style="display:block;" id="fig:F11-8"></span>
<img src="_main_files/figure-html/F11-8-1.jpeg" alt="(left) A comparison of the means and 95% credible intervals for shared fixed effects parameters in our full and reduced models. (right) A comparison of the means and 95% credible intervals for shared superpopulation standard deviations in our full and reduced models." width="4800" />
<p class="caption">
Figure 11.8: (left) A comparison of the means and 95% credible intervals for shared fixed effects parameters in our full and reduced models. (right) A comparison of the means and 95% credible intervals for shared superpopulation standard deviations in our full and reduced models.
</p>
</div>
<p>We can use cross-validation to compare the expected model out-of-sample prediction:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb424-1" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0 <span class="ot">=</span> </span>
<span id="cb424-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb424-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_criterion</span> (model_height_vtl_f0, <span class="st">&quot;loo&quot;</span>)</span>
<span id="cb424-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb424-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb424-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb424-4" aria-hidden="true" tabindex="-1"></a>model_height_vtl_f0_reduced <span class="ot">=</span> </span>
<span id="cb424-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb424-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">add_criterion</span> (model_height_vtl_f0_reduced, <span class="st">&quot;loo&quot;</span>)</span></code></pre></div>
<p>And see that the reduced model has a lower <span class="math inline">\(\mathrm{elpd}\)</span>, but that the difference is only about 1 standard error, making it not at all reliable.</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb425-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loo_compare</span> (model_height_vtl_f0,model_height_vtl_f0_reduced) </span>
<span id="cb425-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb425-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                             elpd_diff se_diff</span></span>
<span id="cb425-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb425-3" aria-hidden="true" tabindex="-1"></a><span class="do">## model_height_vtl_f0           0.0       0.0  </span></span>
<span id="cb425-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb425-4" aria-hidden="true" tabindex="-1"></a><span class="do">## model_height_vtl_f0_reduced -10.8      11.7</span></span></code></pre></div>
<p>We can also consider the variance explained (<span class="math inline">\(R^2\)</span>) by each model:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R2 for full model</span></span>
<span id="cb426-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-2" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">r2_bayes</span>(model_height_vtl_f0)</span>
<span id="cb426-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-3" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate Est.Error   Q2.5  Q97.5</span></span>
<span id="cb426-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,]   0.8064  0.004273 0.7975 0.8142</span></span>
<span id="cb426-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb426-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-6" aria-hidden="true" tabindex="-1"></a><span class="co"># R2 for reduced model</span></span>
<span id="cb426-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-7" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">r2_bayes</span>(model_height_vtl_f0_reduced)</span>
<span id="cb426-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-8" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate Est.Error   Q2.5  Q97.5</span></span>
<span id="cb426-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb426-9" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,]   0.7997  0.004404 0.7906 0.8077</span></span></code></pre></div>
<p>And see that all of the extra complexity included in our full model gains us less than 1% additional variance explained. All of this suggests that a researcher would be justified in fitting and interpreting the reduced model for their research, especially if there is a compelling reason to do so. However, being able to say “these parameters are near zero/show no meaningful variation” is potentially useful, and we lose that ability when we base our analysis on the reduced model. Of course, we could say something like “we fit a larger model that showed all these effects are zero but we are not presenting it here, please take our word for it”. If we <em>do</em> want to say something like this it may make sense to present the full model to the reader so that they can reach the same conclusions you did (or not).</p>
</div>
</div>
<div id="a-logistic-regression-model-with-multiple-quantitative-predictors" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> A logistic regression model with multiple quantitative predictors<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#a-logistic-regression-model-with-multiple-quantitative-predictors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’re going to fit a logistic regression model with two quantitative predictors and an interaction between them. We’re also going to inspect the model using the principles of Bayesian ANOVA (henceforth <strong>BANOVA</strong>) outlined in the previous section. Before continuing we want to talk briefly about the geometry of the models we’ll be fitting.</p>
<p>A logistic regression model with two quantitative predictors specifies planes (top row, figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-9">11.9</a>) along a third dimension (z) representing the logit of the probability of observing a ‘success’ (a value of 1 for the dependent variable). We will refer to these surfaces as <strong>response surfaces</strong> because they specify the expected value of the response variable based on the value of our quantitative predictors. When the value on the response surface is negative, the model predicts a response of 0 at this location of the predictor space (i.e. the space defined by the quantitative predictors). When the value of the plane is positive the model predicts a 1. When we want to know the probability expected for any given x and y axis location, we can transform the value of the response surface using the inverse logit function (equation <a href="logistic-regression-and-signal-detection-theory-models.html#eq:10-9">(10.9)</a>). When the predicted logits are transformed to probabilities, our model defines a curved surface (bottom row of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-9">11.9</a>) rather than a flat plane.</p>
<div class="figure"><span style="display:block;" id="fig:F11-9"></span>
<img src="_main_files/figure-html/F11-9-1.jpeg" alt="(top) Three perspectives on a plane that specifies logits along its z axis. (bottom) The same plane after undergoing the inverse logit transform, now expressing probabilities along the z axis." width="4800" />
<p class="caption">
Figure 11.9: (top) Three perspectives on a plane that specifies logits along its z axis. (bottom) The same plane after undergoing the inverse logit transform, now expressing probabilities along the z axis.
</p>
</div>
<p>When our models include interactions between quantitative predictors (i.e. the cross-product), our predicted logits will no longer vary along planes. Instead, the surface will resemble a saddle shape based on the sign of the parameter and its magnitude relative to the slopes of the relevant quantitative predictors in the model (top row, figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>). When we convert these saddle shapes to probabilities using the inverse logit function, the resulting shape can be strange. For example, in the bottom row in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>, we see that saddle shapes can result in non-contiguous regions associated with successes, with a canyon in the middle associated with failures.</p>
<div class="figure"><span style="display:block;" id="fig:F11-10"></span>
<img src="_main_files/figure-html/F11-10-1.jpeg" alt="(top) Three perspectives on a saddle shape that specifies logits along its z axis. (bottom) The same saddle shape after undergoing the inverse logit transform, now expressing probabilities along the z axis." width="4800" />
<p class="caption">
Figure 11.10: (top) Three perspectives on a saddle shape that specifies logits along its z axis. (bottom) The same saddle shape after undergoing the inverse logit transform, now expressing probabilities along the z axis.
</p>
</div>
<div id="data-and-research-questions-8" class="section level3 hasAnchor" number="11.5.1">
<h3><span class="header-section-number">11.5.1</span> Data and research questions<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-8" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the code below we load our packages, set our contrasts, and load our experimental data. We also add our dependent variable, <code>Female</code>, to our data frame. This variable equals 1 when the listener indicated hearing a female speaker and 0 when the listener indicated hearing a male speaker. As with our previous model we center our quantitative variables and divide f0 by 100 to make the expected regression coefficients for VTL and f0 more similar in magnitude.</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (brms)</span>
<span id="cb427-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (bmmb)</span>
<span id="cb427-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-3" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&#39;contr.sum&#39;</span>,<span class="st">&#39;contr.sum&#39;</span>))</span>
<span id="cb427-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span> (exp_data)</span>
<span id="cb427-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-7" aria-hidden="true" tabindex="-1"></a><span class="co"># create our dependent variable</span></span>
<span id="cb427-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-8" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>Female <span class="ot">=</span> <span class="fu">ifelse</span>(exp_data<span class="sc">$</span>G <span class="sc">==</span> <span class="st">&#39;f&#39;</span>, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb427-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-10" aria-hidden="true" tabindex="-1"></a><span class="co"># center vtl</span></span>
<span id="cb427-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-11" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>vtl_original <span class="ot">=</span> exp_data<span class="sc">$</span>vtl</span>
<span id="cb427-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-12" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>vtl <span class="ot">=</span> exp_data<span class="sc">$</span>vtl <span class="sc">-</span> <span class="fu">mean</span> (exp_data<span class="sc">$</span>vtl)</span>
<span id="cb427-13"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb427-14"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-14" aria-hidden="true" tabindex="-1"></a><span class="co"># center and scale f0</span></span>
<span id="cb427-15"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-15" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0_original <span class="ot">=</span> exp_data<span class="sc">$</span>f0 </span>
<span id="cb427-16"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-16" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0 <span class="ot">=</span> exp_data<span class="sc">$</span>f0 <span class="sc">-</span> <span class="fu">mean</span>(exp_data<span class="sc">$</span>f0)</span>
<span id="cb427-17"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb427-17" aria-hidden="true" tabindex="-1"></a>exp_data<span class="sc">$</span>f0 <span class="ot">=</span> exp_data<span class="sc">$</span>f0 <span class="sc">/</span> <span class="dv">100</span></span></code></pre></div>
<p>As with our height model, we’ll leave more detailed research questions for chapter 13. For now we are only interested in two general questions:</p>
<p>(Q1) Can we use what we’ve learned so far to fit and evaluate a logistic regression model with two quantitative predictors?</p>
<p>(Q2) Can we extend the concepts from chapter 10 to classify speakers along two stimulus dimensions (f0 and VTL) using our logistic models?</p>
</div>
<div id="description-of-the-model-10" class="section level3 hasAnchor" number="11.5.2">
<h3><span class="header-section-number">11.5.2</span> Description of the model<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#description-of-the-model-10" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our model formula is very much like the one we used to investigate the perception of femaleness in the last chapter, save for the addition of f0 and its interaction with the other predictors. Our formula will be:</p>
<p><code>Female ~ vtl * f0 * A + (vtl * f0 * A|L) + (1|S)</code></p>
<p>We’ll use the same priors we used for our logistic models last chapter. Since we scaled f0 so that a change of 1 corresponds to 100 Hz, a 1 unit change in f0 represents about the average difference in f0 between adult males and females. As a result, we think it’s reasonable to use a prior of the same magnitude as we used for our VTL parameter.</p>
<p>We will omit our model specification since it is quite large and very similar to the one presented in chapter 10 for <code>model_gender_vtl</code>. However we can say what it’s doing in general. We are predicting the perception of femaleness using planes, or potentially saddle shapes, that vary as a function of speaker VTL and f0, and the apparent age of the speaker. These shapes can vary arbitrarily, in their slopes along each dimension, degree of curvature, and intercepts, as a function of apparent age. <em>All</em> of the aforementioned characteristics can vary in a listener dependent way, and intercepts can vary in a speaker dependent way. If the preceding sentences make no sense to you, you should review the description of the linear model in section <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-description-1">11.3.3</a>. All we’ve done here is briefly say the same thing we said in more detail in that section.</p>
</div>
<div id="fitting-and-the-model-and-applying-a-bayesian-anova" class="section level3 hasAnchor" number="11.5.3">
<h3><span class="header-section-number">11.5.3</span> Fitting and the model and applying a Bayesian ANOVA<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-the-model-and-applying-a-bayesian-anova" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We fit our model with the code below:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb428-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-2" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0 <span class="ot">=</span></span>
<span id="cb428-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (Female <span class="sc">~</span> vtl<span class="sc">*</span>f0<span class="sc">*</span>A <span class="sc">+</span> (vtl<span class="sc">*</span>f0<span class="sc">*</span>A<span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data=</span>exp_data, </span>
<span id="cb428-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">chains=</span><span class="dv">4</span>, <span class="at">cores=</span><span class="dv">4</span>, <span class="at">family=</span><span class="st">&quot;bernoulli&quot;</span>, </span>
<span id="cb428-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">5000</span>, <span class="at">thin =</span> <span class="dv">4</span>,  </span>
<span id="cb428-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb428-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-7" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb428-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-8" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb428-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb428-9" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;lkj_corr_cholesky (2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;cor&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb429-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb429-2" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0 <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;11_model_gender_vtl_f0.RDS&#39;</span>)</span></code></pre></div>
<p>We can inspect the model fixed effects using <code>brmplot</code> in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-11">11.11</a>. Beside that we make a BANOVA plot comparing the model fixed effects and the finite-sample standard deviations for ‘batches’ of our random effects parameters.</p>
<div class="figure"><span style="display:block;" id="fig:F11-11"></span>
<img src="_main_files/figure-html/F11-11-1.jpeg" alt="(left) A plot showing fixed effects estimates and 95% credible intervals for `model_gender_vtl_f0`. (right) A BANOVA plot of the same model, showing posterior means and 95% credible intervals for the finite sample standard deviation estimates." width="4800" />
<p class="caption">
Figure 11.11: (left) A plot showing fixed effects estimates and 95% credible intervals for <code>model_gender_vtl_f0</code>. (right) A BANOVA plot of the same model, showing posterior means and 95% credible intervals for the finite sample standard deviation estimates.
</p>
</div>
<p>In figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-11">11.11</a> we see a relatively complex model, with an important role for f0 and VTL. We also see that unlike for our model predicting apparent height above, this model features a prominent f0 by VTL interaction (<code>vtl:f0</code>), and an interaction between this and apparent age (<code>vtl:f0:A1</code>). Just as with our height model above, we will leave interpretation of this model for chapter 13. Instead, we’re going to focus on using our models to understand the classification of speakers into apparent females and apparent males based on their VTL and f0, and on whether we actually <em>like</em> this model or not.</p>
</div>
<div id="c12-2d-categorization" class="section level3 hasAnchor" number="11.5.4">
<h3><span class="header-section-number">11.5.4</span> Categorization in two dimensions<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c12-2d-categorization" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Imagine a horizontal plane such that z=0 for all values of x and y in figures <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-9">11.9</a> and <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>. If the z (vertical) axis represents logits, this plane would represent an expected probability of 0.5, meaning it is the boundary between successes (1) and failures (0) along the z axis. Our response surface will intersect with the horizontal z=0 plane, forming a curve at this intersection. These curves represent the division of the response surface into sections with values greater than 0 (expected response 1) and sections with values less than 0 (expected response 0). Thus, the curves formed by the intersection of our response surface and the z=0 plane represent the <em>category boundary</em> along the predictor space, as defined by our model.</p>
<p>We will begin by discussing the case where the response surface is a plane, i.e., there is no cross product term in our model. The intersection of two planes forms a straight line. Although the surfaces in the bottom row of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-9">11.9</a> are not planes, the intersection of these surfaces with planes still form straight lines. Thus, their intersection with the plane at p=0.5 (i.e. the plane where logit(p) = 0) will still form straight lines. To find the intersection of our response surfaces and the plane at z=0, we can use some basic algebra. We take the equation defining the shape of our response and set z to zero:</p>
<p><span class="math display" id="eq:11-11">\[
\begin{equation}
\begin{split}
z =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y) \\
0 =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y)
\end{split}
\tag{11.11}
\end{equation}
\]</span></p>
<p>We will arbitrarily decide to draw a line that treats y as the ‘dependent’ variable. To find the equation for this line we need to solve for y (i.e. isolate it on one side of the equal sign), as shown in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-12">(11.12)</a>.</p>
<p><span class="math display" id="eq:11-12">\[
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y) \\
y =  -(\mathrm{b} \cdot x - \mathrm{a}) / \mathrm{c}
\end{split}
\tag{11.12}
\end{equation}
\]</span></p>
<p>We can use the above method to calculate the category boundaries implied by a model including a cross product as seen below. In the interest of full disclosure, we use online algebra solving tools to solve equations like this. There is no shame in doing so, and it minimizes on the probability of an error on your part. Of course, you need to make sure the tool you use is reliable, but you can always double (or triple) check proposed solutions across different analysis methods.</p>
<p><span class="math display" id="eq:11-13">\[
\begin{equation}
\begin{split}
0 =  \mathrm{a} + (\mathrm{b} \cdot x) + (\mathrm{c} \cdot y) + (d \cdot x \cdot y) \\
y =  (-\mathrm{b} \cdot x - \mathrm{a}) / (d \cdot x + c)
\end{split}
\tag{11.13}
\end{equation}
\]</span></p>
<p>As seen in <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-13">(11.13)</a>, the intersection between a saddle shape and the plane where z=0 will not be a straight line. Instead, it will be a <strong>hyperbola</strong> a shape that resembles a pair of parabolas that approach, but never cross an asymptote (a boundary line). Since saddle shapes can fall and then rise again, a surface of this kind may intersect with the plane at z=0 in more than one location (seen in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>). The <span class="math inline">\(a, b, c\)</span> and <span class="math inline">\(d\)</span> parameters above represent model coefficients for the intercept, VTL slope, f0 slope, and cross-product respectively. Below we get the samples for our fixed effects parameters from our model, in addition to the marginal, or ‘main effect’, estimates of these parameters.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get fixed effect parameters</span></span>
<span id="cb430-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">fixef</span> (model_gender_vtl_f0, <span class="at">summary =</span> <span class="cn">FALSE</span>)</span>
<span id="cb430-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c,d coefficients for overall surface</span></span>
<span id="cb430-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-5" aria-hidden="true" tabindex="-1"></a>a_all <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>])</span>
<span id="cb430-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-6" aria-hidden="true" tabindex="-1"></a>b_all <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>])</span>
<span id="cb430-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-7" aria-hidden="true" tabindex="-1"></a>c_all <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>])</span>
<span id="cb430-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb430-8" aria-hidden="true" tabindex="-1"></a>d_all <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl:f0&quot;</span>])</span></code></pre></div>
<p>We can also add up appropriate combinations of the fixed effects to calculate separate <span class="math inline">\(a, b, c\)</span> and <span class="math inline">\(d\)</span> parameters for apparent adults and for apparent children, as seen below. Note that in each case we combine the necessary parameters first and then find the average across the samples of the parameter. Of course, in both cases we could have used the <code>hypothesis</code> (or <code>short_hypothesis</code>) function rather than do it ‘by hand’.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c,d coefficients for adult surface</span></span>
<span id="cb431-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-2" aria-hidden="true" tabindex="-1"></a>a_adult <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;A1&quot;</span>])</span>
<span id="cb431-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-3" aria-hidden="true" tabindex="-1"></a>b_adult <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;vtl:A1&quot;</span>])</span>
<span id="cb431-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-4" aria-hidden="true" tabindex="-1"></a>c_adult <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;f0:A1&quot;</span>])</span>
<span id="cb431-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-5" aria-hidden="true" tabindex="-1"></a>d_adult <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl:f0&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;vtl:f0:A1&quot;</span>])</span>
<span id="cb431-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb431-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-7" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c,d coefficients for child surface</span></span>
<span id="cb431-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-8" aria-hidden="true" tabindex="-1"></a>a_child <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;A1&quot;</span>])</span>
<span id="cb431-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-9" aria-hidden="true" tabindex="-1"></a>b_child <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;vtl:A1&quot;</span>])</span>
<span id="cb431-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-10" aria-hidden="true" tabindex="-1"></a>c_child <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;f0:A1&quot;</span>])</span>
<span id="cb431-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb431-11" aria-hidden="true" tabindex="-1"></a>d_child <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl:f0&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;vtl:f0:A1&quot;</span>])</span></code></pre></div>
<p>We can use these parameters to generate curves representing the boundaries between expected female and expected male responses. We do this for our hyperbolic (equation <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#eq:11-13">(11.13)</a>) boundaries in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-12">11.12</a>. When we ‘zoom out’ in the middle plot of the same figure, we see that this model actually predicts male classifications in the top left corner as well as in the bottom right corner. This is a result of the fact that our hyperbolic boundaries come in pairs, resulting from the bimodal (i.e. two peaked) shape seen in the bottom row of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>.</p>
<div class="figure"><span style="display:block;" id="fig:F11-12"></span>
<img src="../wrong_plots/Figure 11.12.jpg" alt="(left) Each point represents a single speaker, labels indicate most common group classification. Curves indicate male/female boundaries for adults (green), children (orange), and overall (blue). (middle) The same as the left figure but zoomed out more. (right) Territorial maps showing expected classifications for apparent adults in different regions of the f0 by VTL stimulus space."  />
<p class="caption">
Figure 11.12: (left) Each point represents a single speaker, labels indicate most common group classification. Curves indicate male/female boundaries for adults (green), children (orange), and overall (blue). (middle) The same as the left figure but zoomed out more. (right) Territorial maps showing expected classifications for apparent adults in different regions of the f0 by VTL stimulus space.
</p>
</div>
<p>In the right plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-12">11.12</a> we present a <em>territorial map</em> of our stimulus space as defined by speaker VTL and f0, for apparent adults. This map tells us the expected classification of speakers into males and females given their voice f0 and VTL, and assuming that they are perceived as being adults (broken green lines in the left and middle plots). Unlike the territorial maps presented in the previous chapter (in figure <a href="logistic-regression-and-signal-detection-theory-models.html#fig:F10-5">10.5</a>), this map is defined along a two-dimensional stimulus space. In addition, although we only present one map in the plot, we can make three separate maps, one for apparent children, one for apparent adults, and an overall map.</p>
<p>The high-frequency male region in the top-left corner of the plot suggests that speakers with a very high f0 and a very short VTL are likely to be identified as males, even for adults. Note that we don’t have many speakers in these regions and so we can only guess how listeners might have responded to voices there. However, common sense suggests that speakers with a very short VTL and a very high f0 are not very likely to be identified as adult males. Does this matter? Yes and no. Does it matter that the earth isn’t flat but our maps mostly act like it is? If it’s <em>flat enough</em> in the area described by our map, then maybe not. If you’re trying to find the shortest flight path between two cities, it probably does.</p>
<p>This suggests we should decide what our model is for. If we only want to understand behavior in the regions where we mostly have a lot of data, then the high-frequency male region may not matter. On the other hand, if we want to understand how listeners might be using acoustic information in general, we might worry that the model predicts behavior that we think is very unlikely to be correct. In other words, we might want our model to ‘make sense’ even for data we don’t have.</p>
</div>
<div id="model-selection-and-misspecification" class="section level3 hasAnchor" number="11.5.5">
<h3><span class="header-section-number">11.5.5</span> Model selection and misspecification<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#model-selection-and-misspecification" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the hopes of finding a model that ‘makes more sense’, we’re going to drop the cross-product and related predictors. Below we fit a reduced model that is otherwise the same as our initial model, but without the interaction between f0 and VTL.</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb432-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-2" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0_reduced <span class="ot">=</span></span>
<span id="cb432-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">brm</span> (Female <span class="sc">~</span> (vtl<span class="sc">+</span>f0)<span class="sc">*</span>A <span class="sc">+</span> ((vtl<span class="sc">+</span>f0)<span class="sc">*</span>A<span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data=</span>exp_data, </span>
<span id="cb432-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-4" aria-hidden="true" tabindex="-1"></a>       <span class="at">chains=</span><span class="dv">4</span>, <span class="at">cores=</span><span class="dv">4</span>, <span class="at">family=</span><span class="st">&quot;bernoulli&quot;</span>, </span>
<span id="cb432-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-5" aria-hidden="true" tabindex="-1"></a>       <span class="at">warmup=</span><span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">5000</span>, <span class="at">thin =</span> <span class="dv">4</span>,  </span>
<span id="cb432-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb432-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-7" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb432-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-8" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 3)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb432-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb432-9" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">set_prior</span>(<span class="st">&quot;lkj_corr_cholesky (2)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;cor&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb433-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb433-2" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0_reduced <span class="ot">=</span> </span>
<span id="cb433-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb433-3" aria-hidden="true" tabindex="-1"></a>  bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;11_model_gender_vtl_f0_reduced.RDS&#39;</span>)</span></code></pre></div>
<p>We find the <span class="math inline">\(a,b\)</span> and <span class="math inline">\(c\)</span> parameters for the response plane given our model, calculating the overall (marginal) plane, a plane for apparent children, and another for apparent adults. There is no <span class="math inline">\(d\)</span> parameter this time since there is no cross-product term in this model.</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get fixed effect parameters</span></span>
<span id="cb434-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-2" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">fixef</span> (model_gender_vtl_f0_reduced, <span class="at">summary =</span> <span class="cn">FALSE</span>)</span>
<span id="cb434-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-4" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c coefficients for overall plane</span></span>
<span id="cb434-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-5" aria-hidden="true" tabindex="-1"></a>a_all_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>])</span>
<span id="cb434-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-6" aria-hidden="true" tabindex="-1"></a>b_all_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>])</span>
<span id="cb434-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-7" aria-hidden="true" tabindex="-1"></a>c_all_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>])</span>
<span id="cb434-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-9" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c coefficients for adult plane</span></span>
<span id="cb434-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-10" aria-hidden="true" tabindex="-1"></a>a_adult_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;A1&quot;</span>])</span>
<span id="cb434-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-11" aria-hidden="true" tabindex="-1"></a>b_adult_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;vtl:A1&quot;</span>])</span>
<span id="cb434-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-12" aria-hidden="true" tabindex="-1"></a>c_adult_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;f0:A1&quot;</span>])</span>
<span id="cb434-13"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-14"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-14" aria-hidden="true" tabindex="-1"></a><span class="co"># get a,b,c coefficients for child plane</span></span>
<span id="cb434-15"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-15" aria-hidden="true" tabindex="-1"></a>a_child_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;Intercept&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;A1&quot;</span>])</span>
<span id="cb434-16"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-16" aria-hidden="true" tabindex="-1"></a>b_child_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;vtl&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;vtl:A1&quot;</span>])</span>
<span id="cb434-17"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb434-17" aria-hidden="true" tabindex="-1"></a>c_child_reduced <span class="ot">=</span> <span class="fu">mean</span> (samples[,<span class="st">&quot;f0&quot;</span>] <span class="sc">-</span> samples[,<span class="st">&quot;f0:A1&quot;</span>])</span></code></pre></div>
<p>We use these parameters to plot the linear category boundaries in our stimulus space. Figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-13">11.13</a> compares the linear boundaries implied by our reduced model (middle) to those implied by our full model (left), ignoring the <span class="math inline">\(d\)</span> coefficients in the case of the full model. We can see that in the absence of the cross-product (middle), the boundaries for children (orange) and adults (green) differ noticeably in their slope. The change in slope indicates that f0 differences matter less for children than they do for adults. This is because since the male-female boundary is almost parallel to the y axis (f0), it is difficult to cross the boundary by moving along this axis. In general, when a boundary is parallel to an axis this means that variable is not strongly associated with category changes. If a boundary is perpendicular to an axis that means the predictor may be strongly associated with category changes.</p>
<div class="figure"><span style="display:block;" id="fig:F11-13"></span>
<img src="../wrong_plots/Figure 11.13.jpg" alt="(left) Each point represents a single speaker, labels indicate most common group classification. Lines indicate male/female boundaries for adults (green), children (orange), and overall (blue) implied by the full model, ignoring the cross-product term. (middle) The same as the left figure but for the reduced model. (right) Territorial maps showing expected classifications for apparent adults in different regions of the f0 by VTL stimulus space, for the reduced model."  />
<p class="caption">
Figure 11.13: (left) Each point represents a single speaker, labels indicate most common group classification. Lines indicate male/female boundaries for adults (green), children (orange), and overall (blue) implied by the full model, ignoring the cross-product term. (middle) The same as the left figure but for the reduced model. (right) Territorial maps showing expected classifications for apparent adults in different regions of the f0 by VTL stimulus space, for the reduced model.
</p>
</div>
<p>We can use cross-validation to investigate which of our two models is preferable.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb435-1" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0 <span class="ot">=</span> </span>
<span id="cb435-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb435-2" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">add_criterion</span>(model_gender_vtl_f0,<span class="st">&quot;loo&quot;</span>)</span>
<span id="cb435-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb435-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb435-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb435-4" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0_reduced <span class="ot">=</span> </span>
<span id="cb435-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb435-5" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">add_criterion</span>(model_gender_vtl_f0_reduced,<span class="st">&quot;loo&quot;</span>)</span></code></pre></div>
<p>The comparison suggests the model that includes the interaction does a better job of explaining our data. The difference between the two models is large-ish, but just under two standard errors in magnitude and so is not terribly reliable.</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb436-1" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">loo_compare</span> (model_gender_vtl_f0, model_gender_vtl_f0_reduced)</span>
<span id="cb436-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb436-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                             elpd_diff se_diff</span></span>
<span id="cb436-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb436-3" aria-hidden="true" tabindex="-1"></a><span class="do">## model_gender_vtl_f0           0.0       0.0  </span></span>
<span id="cb436-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb436-4" aria-hidden="true" tabindex="-1"></a><span class="do">## model_gender_vtl_f0_reduced -18.2       9.9</span></span></code></pre></div>
<p>When adding the <code>loo</code> criterion to our models we got error messages like this:</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Warning: Found 205 observations with a pareto_k &gt; 0.7 in model </span></span>
<span id="cb437-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb437-2" aria-hidden="true" tabindex="-1"></a><span class="do">## &#39;model_gender_vtl_f0&#39;. It is recommended to set &#39;moment_match = TRUE&#39; </span></span>
<span id="cb437-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb437-3" aria-hidden="true" tabindex="-1"></a><span class="do">## in order to perform moment matching for problematic observations.`</span></span></code></pre></div>
<p>When we add the <code>loo</code> criterion to our model, <code>brms</code> (and <em>Stan</em>) don’t actually fit a new model for every left out data point (i.e. a ‘real’ leave-one-out cross validation). Instead, there’s a way to approximate what the model <em>would</em> look like had it actually been refit without each data point. This approximation uses something called <strong>Pareto smoothed importance sampling</strong> (<strong>PSIS</strong>). The Pareto-k (<span class="math inline">\(\hat{k}\)</span>, <code>pareto_k</code>) statistic is a diagnostic for this estimation method that helps you check the assumptions underlying the leave-one-out approximation (Vehtari et al. 2017). Essentially, the <span class="math inline">\(\hat{k}\)</span> statistic is a measure of how unusual a given observation is. A very unusual observation is highly influential in your model and will have a higher value of <span class="math inline">\(\hat{k}\)</span>. If an observation is <em>too</em> unusual, then the estimate of <span class="math inline">\(\mathrm{elpd}\)</span> associated with that observation may not be reliable. The general rule of thumb is that values of <span class="math inline">\(\hat{k}\)</span> that are less than 0.5 are ‘good’, values between 0.5 and 0.7 are ‘ok’ (not so great but not bad either), values greater than 0.7 are ‘bad’ and values greater than 1.0 are ‘very bad’.</p>
<p>Vehtari (2022) outlines three general situations that cause Pareto-k statistics to be large. To understand these it might help to review the information on model comparison previously discussed in section <a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-model-comparison">6.4</a>, and <a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-out-sample-crossval">6.4.3</a> specifically. The number of estimated parameters in a model is the total actual number of parameters estimated, including all fixed effects, random effects, and ‘distributional’ parameters such as <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(\nu\)</span>. We may distinguish this from the <em>effective</em> number of parameters, <code>p_loo</code> when calculated using <code>loo</code>, which takes the flexibility of the model into account. If a model shows little variability in its random effects, its effective number of parameters may be smaller than its total number of estimated parameters. The three situations that can cause large Pareto-k statistics are:</p>
<ol style="list-style-type: decimal">
<li>p_loo is <em>smaller</em> the number of estimated parameters: If the estimated number of parameters (p) is relatively large relative to the number of observations (n), e.g. p &gt; n/5, then the model may be too flexible, or your priors may be too weak.</li>
<li>p_loo is <em>much smaller</em> than the number of estimated parameters: The model is likely to be <strong>misspecified</strong>. A misspecified model is one whose structure contains important differences compared to the processes being modeled.</li>
<li>p_loo is <em>greater than</em> the number of parameters: The model is likely to be <em>‘badly’</em> misspecified.</li>
</ol>
<p>In each case, a posterior predictive check may help understand the issues, as can inspecting the distribution of Pareto-k statistics. Below, we print the actual and effective number of parameters for our full model, as well as our number of observations.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="co"># actual number of estimated parameters</span></span>
<span id="cb438-2"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ncol</span> (bmmb<span class="sc">::</span><span class="fu">get_samples</span>(model_gender_vtl_f0))<span class="sc">-</span><span class="dv">2</span></span>
<span id="cb438-3"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 304</span></span>
<span id="cb438-4"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb438-5"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-5" aria-hidden="true" tabindex="-1"></a><span class="co"># number of observations</span></span>
<span id="cb438-6"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-6" aria-hidden="true" tabindex="-1"></a><span class="fu">nrow</span> (model_gender_vtl_f0<span class="sc">$</span>data)</span>
<span id="cb438-7"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 2085</span></span>
<span id="cb438-8"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb438-9"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-9" aria-hidden="true" tabindex="-1"></a><span class="co"># information related to loo creiterion</span></span>
<span id="cb438-10"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-10" aria-hidden="true" tabindex="-1"></a>model_gender_vtl_f0<span class="sc">$</span>criteria<span class="sc">$</span>loo<span class="sc">$</span>estimates</span>
<span id="cb438-11"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-11" aria-hidden="true" tabindex="-1"></a><span class="do">##          Estimate     SE</span></span>
<span id="cb438-12"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-12" aria-hidden="true" tabindex="-1"></a><span class="do">## elpd_loo   -541.5 23.405</span></span>
<span id="cb438-13"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-13" aria-hidden="true" tabindex="-1"></a><span class="do">## p_loo       105.8  6.637</span></span>
<span id="cb438-14"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb438-14" aria-hidden="true" tabindex="-1"></a><span class="do">## looic      1083.0 46.810</span></span></code></pre></div>
<p>Based on the information above, we believe that our model falls into the first case. Our <code>p_loo</code> is only about 30% as large as our number of parameters. Although we do have more than 5 times as many observations (2085) as estimated parameters (304), the ratio of 6.86 is not much greater than 5. In addition, we <em>do</em> think there is a possibility that the model is <em>misspecified</em> and may be too flexible. We’ve said repeatedly that no model can really ‘prove’ itself to be the ‘real’ model, and even that it’s not totally clear what it would mean for a formalism like regression to represent the ‘real’ process underlying our observations. Given this, it seems that every model is ‘misspecified’ to some extent, making a focus on the misspecification of this one model seem somewhat arbitrary.</p>
<p>Although the above may be generally true, we can focus on misspecifications that cause noticeable ‘misbehaviors’ in our models. What might ‘misbehaviors’ look like? We think an example of this is given by the hyperbolic category boundaries seen in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-12">11.12</a>. We noted above that these boundaries defied logic and were unlikely to represent listener behavior in all areas of the stimulus space. In other words, the model did not seem to correctly reflect the underlying process we are trying to understand: Listener judgments of apparent gender based on speech acoustics and apparent speaker age.</p>
<p>To investigate the issue, we can get the Pareto-k estimates for our initial model using the code below:</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb439-1" aria-hidden="true" tabindex="-1"></a>pareto_k <span class="ot">=</span> model_gender_vtl_f0<span class="sc">$</span>criteria<span class="sc">$</span>loo<span class="sc">$</span>diagnostics<span class="sc">$</span>pareto_k</span></code></pre></div>
<p>We plot these in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-14">11.14</a>, and compare them to the same values for our reduced model. When plotting these, we noted that there was a pattern such that <span class="math inline">\(\hat{k}\)</span> values were highest for adult male speakers, and that the problems largely disappear when the cross product is removed.</p>
<div class="figure"><span style="display:block;" id="fig:F11-14"></span>
<img src="_main_files/figure-html/F11-14-1.jpeg" alt="(left) Pareto k estimates for data points in `model_gender_vtl_f0`. (right) Pareto k estimates for data points in `model_gender_vtl_f0_reduced`. Point colors reflect veridical speaker category." width="4800" />
<p class="caption">
Figure 11.14: (left) Pareto k estimates for data points in <code>model_gender_vtl_f0</code>. (right) Pareto k estimates for data points in <code>model_gender_vtl_f0_reduced</code>. Point colors reflect veridical speaker category.
</p>
</div>
<p>Below we make posterior predictions for the full model, taking the average across all posterior samples:</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#cb440-1" aria-hidden="true" tabindex="-1"></a>p_preds <span class="ot">=</span> <span class="fu">predict</span> (model_gender_vtl_f0)</span></code></pre></div>
<p>Pareto-k values are plotted according to their predicted probability of a female response in the left plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-15">11.15</a>. It’s clear that the main issue seems to be with adult males who are predicted to be female nearly 0% of the time. In fact, in the data several men <em>were</em> identified as women in 0% of cases. Since a probability of 0 implies, in the limit, a logit of negative infinity, the model appears to have a hard time finding reasonable values for some parameters in these cases. We considered a boxplot of Pareto k values by speaker (not presented here), which revealed that a small number of individual men were responsible for most high k values. We found that these men tended to have the lowest f0 values from among our speakers. In the middle plot we present each speaker plotted according to their f0 and VTL, where point size reflects the average Pareto-k value for each speaker.</p>
<div class="figure"><span style="display:block;" id="fig:F11-15"></span>
<img src="_main_files/figure-html/F11-15-1.jpeg" alt="(left) Pareto k estimates for data points in `model_gender_vtl_f0` plotted against the predicted probability of a female response for each data point. Point color represents veridical speaker category. (middle) Adult male and female speakers plotted according to voice characteristics. Point size reflects Pareto k values. (right) A 'topographic map' of our predicted surface for adult speakers. The same points as in the middle figure. Black lines indicate female/male category boundaries (i.e. logit = 0). Red lines indicate 2-logit decreases in expected values, green lines indicate 2-logit increases in expected values." width="4800" />
<p class="caption">
Figure 11.15: (left) Pareto k estimates for data points in <code>model_gender_vtl_f0</code> plotted against the predicted probability of a female response for each data point. Point color represents veridical speaker category. (middle) Adult male and female speakers plotted according to voice characteristics. Point size reflects Pareto k values. (right) A ‘topographic map’ of our predicted surface for adult speakers. The same points as in the middle figure. Black lines indicate female/male category boundaries (i.e. logit = 0). Red lines indicate 2-logit decreases in expected values, green lines indicate 2-logit increases in expected values.
</p>
</div>
<p>Based on figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-15">11.15</a>, we can see that the problematic male voices are those with extreme values of VTL and, in particular f0. If we think of our saddle shapes (see figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-10">11.10</a>), they can have areas where z values (i.e., the dependent variable) can rise or fall extremely rapidly. For example, the right plot of figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-15">11.15</a> presents a sort of topographical map of the response surface for adults in our full model. In this sort of plot, lines indicate differences in ‘elevation’ and lines that are close together indicate rapid rises/falls in the height of the surface.</p>
<p>We can see that the voices with the highest Pareto-k values were in a region that includes very high values of z that also rise rapidly based on small differences in f0 and VTL. So, it appears that in this case we have some male speakers whose probability of being identified as female is very low, implying very negative logit values, in a region of our surface that is curved such that extremely negative predicted values are possible. Combining this with our relatively small number of observations (given the complexity/flexibility of our model) results in the very high Pareto-k values seen above.</p>
<p>To resolve this situation we could refit the full model with tighter priors, especially since our priors are actually relatively wide and could be quite a bit narrower without likely having much of an effect on results. However, it may be the case that our full model is simply too flexible given the amount of data we have. Independently of all of this, we are still concerned with the very basic problem that the high-frequency region associated with male responses (presented in figure <a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fig:F11-12">11.12</a>) defies common sense and is probably wrong. As a result of this, we’re not going to try to ‘fix’ the more complicated model but simply abandon it, relying instead on the reduced model that does not include the VTL by f0 interaction. We should note that our reduced model <em>also</em> had a handful of high Pareto-k values, albeit only a small number (6) and with no values near 1. We don’t think this necessarily means that our model is fundamentally misspecified, but rather that sometimes listeners do unpredictable things. It may be the case that a more ‘robust’ approach to logistic regression is justified in this case, as discussed in Kruschke (2014, chapter 21).</p>
</div>
</div>
<div id="exercises-10" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Exercises<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#exercises-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The analyses in the main body of the text all involve only the unmodified ‘actual’ resonance level (in <code>exp_data</code>). Responses for the stimuli with the simulate ‘big’ resonance are reserved for exercises throughout. You can get the ‘big’ resonance in the <code>exp_ex</code> data frame, or all data in the <code>exp_data_all</code> data frame.</p>
<p>Fit and interpret one or more of the suggested models:</p>
<ol style="list-style-type: decimal">
<li><p>Easy: Analyze the (pre-fit) model that’s exactly like <code>model_height_vtl_f0</code>, except using the data in <code>exp_ex</code> (<code>bmmb::get_model("11_model_height_vtl_f0.RDS")</code>).</p></li>
<li><p>Easy: Analyze the (pre-fit) model that’s exactly like <code>model_gender_vtl_f0_reduced</code>, except using the data in <code>exp_ex</code> (<code>bmmb::get_model("11_model_gender_vtl_f0_reduced_ex.RDS")</code>).</p></li>
<li><p>Medium: Fit a model like the ones in this chapter but include the resonance predictor, and any interactions you may be interested in.</p></li>
<li><p>Hard: Fit a model like the ones in this chapter but include the duration predictor, and any interactions you may be interested in. You may also want to predict apparent age using a logistic model.</p></li>
</ol>
<p>In any case, describe the model, present and explain the results, and include some figures.</p>
</div>
<div id="references-8" class="section level2 hasAnchor" number="11.7">
<h2><span class="header-section-number">11.7</span> References<a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#references-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Gelman, A. (2005). Analysis of variance—why it is more important than ever. The annals of statistics, 33(1), 1-53.</p>
<p>Gelman, A., &amp; Hill, J. (2006). Data analysis using regression and multilevel/hierarchical models. Cambridge university press.</p>
<p>Gelman, A., Hill, J., &amp; Yajima, M. (2012). Why we (usually) don’t have to worry about multiple comparisons. Journal of Research on Educational Effectiveness, 5(2), 189–211.</p>
<p>Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp; Rubin, D. B. (2013). Bayesian Data Analysis.</p>
<p>Kruschke, J. (2014). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan.</p>
<p>Myers, J. L., Well, A. D., &amp; Lorch, R. F. (2013). Research design and statistical analysis. Routledge.</p>
<p>Pedhazur, E. J., &amp; Schmelkin, L. P. (2013). Measurement, design, and analysis: An integrated approach. psychology press.</p>
<p>Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and computing, 27(5), 1413-1432.</p>
<p>Vehtari, A. (2022). Cross-validation FAQ.Model Selection. ttps://avehtari.github.io/modelselection/CV-FAQ.html</p>
<p>Wickens, T. D., &amp; Keppel, G. (2004). Design and analysis: A researcher’s handbook. Upper Saddle River, NJ: Pearson Prentice-Hall.</p>

<div style="page-break-after: always;"></div>
</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression-and-signal-detection-theory-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multinomial-and-ordinal-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
