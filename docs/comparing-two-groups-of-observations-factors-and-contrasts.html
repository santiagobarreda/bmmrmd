<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Comparing two groups of observations: Factors and contrasts | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</title>
  <meta name="description" content="Bayesian Models for Repeated Measures" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Comparing two groups of observations: Factors and contrasts | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Bayesian Models for Repeated Measures" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Comparing two groups of observations: Factors and contrasts | Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R" />
  
  <meta name="twitter:description" content="Bayesian Models for Repeated Measures" />
  

<meta name="author" content="Santiago Bareda and Noah Silbert" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"/>
<link rel="next" href="variation-in-parameters-random-effects-and-model-comparison.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bayesian Repeated Measures data</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#bayesian-multilevel-models-and-repeated-measures-data"><i class="fa fa-check"></i>Bayesian Multilevel models and repeated measures data</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#whats-missing-from-this-book"><i class="fa fa-check"></i>What’s missing from this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#statistics-as-procedural-knowledge"><i class="fa fa-check"></i>Statistics as Procedural knowledge</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practice-vs-brain-power"><i class="fa fa-check"></i>Practice vs brain power</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-to-use-this-book"><i class="fa fa-check"></i>How to use this book</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#supplemental-resources"><i class="fa fa-check"></i>Supplemental Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#our-target-audience"><i class="fa fa-check"></i>Our target audience</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-self-starter"><i class="fa fa-check"></i>The self-starter</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-convert"><i class="fa fa-check"></i>The convert</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-instructor"><i class="fa fa-check"></i>The instructor</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-you-need-installed-to-use-this-book"><i class="fa fa-check"></i>What you need installed to use this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-go-bayesian"><i class="fa fa-check"></i>Why go Bayesian?</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#why-brms"><i class="fa fa-check"></i>Why brms?</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#it-takes-a-village-of-books"><i class="fa fa-check"></i>It takes a village (of books)</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html"><i class="fa fa-check"></i><b>1</b> Introduction: Experiments and Variables</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#chapter-pre-cap"><i class="fa fa-check"></i><b>1.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="1.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-and-effects"><i class="fa fa-check"></i><b>1.2</b> Experiments and effects</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-and-inference"><i class="fa fa-check"></i><b>1.2.1</b> Experiments and inference</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp"><i class="fa fa-check"></i><b>1.3</b> Our experiment</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-intro"><i class="fa fa-check"></i><b>1.3.1</b> Our experiment: Introduction</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-methods"><i class="fa fa-check"></i><b>1.3.2</b> Our experimental methods</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-research-questions"><i class="fa fa-check"></i><b>1.3.3</b> Our research questions</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-exp-data"><i class="fa fa-check"></i><b>1.3.4</b> Our experimental data</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-variables"><i class="fa fa-check"></i><b>1.4</b> Variables</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-pops-and-samps"><i class="fa fa-check"></i><b>1.4.1</b> Populations and samples</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-dep-and-indep"><i class="fa fa-check"></i><b>1.4.2</b> Dependent and Independent Variables</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-categorical"><i class="fa fa-check"></i><b>1.4.3</b> Categorical variables and ‘factors’</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-quantitative"><i class="fa fa-check"></i><b>1.4.4</b> Quantitative variables</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-logical"><i class="fa fa-check"></i><b>1.4.5</b> Logical variables</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting"><i class="fa fa-check"></i><b>1.5</b> Inspecting our data</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-categorical"><i class="fa fa-check"></i><b>1.5.1</b> Inspecting categorical variables</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-quantitative"><i class="fa fa-check"></i><b>1.5.2</b> Inspecting quantitative variables</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#c1-inspecting-together"><i class="fa fa-check"></i><b>1.5.3</b> Exploring continuous and categorical variables together</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#exercises"><i class="fa fa-check"></i><b>1.6</b> Exercises</a></li>
<li class="chapter" data-level="1.7" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#references"><i class="fa fa-check"></i><b>1.7</b> References</a></li>
<li class="chapter" data-level="1.8" data-path="introduction-experiments-and-variables.html"><a href="introduction-experiments-and-variables.html#plot-code"><i class="fa fa-check"></i><b>1.8</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html"><i class="fa fa-check"></i><b>2</b> Probabilities, likelihood, and inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#chapter-pre-cap-1"><i class="fa fa-check"></i><b>2.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="2.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-data"><i class="fa fa-check"></i><b>2.2</b> Data and research questions</a></li>
<li class="chapter" data-level="2.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-empirical-prob"><i class="fa fa-check"></i><b>2.3</b> Empirical Probabilities</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-conditional"><i class="fa fa-check"></i><b>2.3.1</b> Conditional and marginal probabilities</a></li>
<li class="chapter" data-level="2.3.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-joint"><i class="fa fa-check"></i><b>2.3.2</b> Joint probabilities</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-theoretical"><i class="fa fa-check"></i><b>2.4</b> Probability distributions</a></li>
<li class="chapter" data-level="2.5" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-normal"><i class="fa fa-check"></i><b>2.5</b> The normal distribution</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-sample-mean"><i class="fa fa-check"></i><b>2.5.1</b> The sample mean</a></li>
<li class="chapter" data-level="2.5.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-sample-variance"><i class="fa fa-check"></i><b>2.5.2</b> The sample variance (or standard deviation)</a></li>
<li class="chapter" data-level="2.5.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-normal-density"><i class="fa fa-check"></i><b>2.5.3</b> The normal density</a></li>
<li class="chapter" data-level="2.5.4" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-standard-normal"><i class="fa fa-check"></i><b>2.5.4</b> The standard normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-models-and-inference"><i class="fa fa-check"></i><b>2.6</b> Models and inference</a></li>
<li class="chapter" data-level="2.7" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-likelihoods"><i class="fa fa-check"></i><b>2.7</b> Probabilities of events and likelihoods of parameters</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-chars-of-likelihoods"><i class="fa fa-check"></i><b>2.7.1</b> Characteristics of likelihoods</a></li>
<li class="chapter" data-level="2.7.2" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-logarithms"><i class="fa fa-check"></i><b>2.7.2</b> A brief aside on logarithms</a></li>
<li class="chapter" data-level="2.7.3" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-chars-of-likelihoods-2"><i class="fa fa-check"></i><b>2.7.3</b> Characteristics of likelihoods, continued</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#c2-inference-and-likelihood"><i class="fa fa-check"></i><b>2.8</b> Answering our research questions</a></li>
<li class="chapter" data-level="2.9" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#exercises-1"><i class="fa fa-check"></i><b>2.9</b> Exercises</a></li>
<li class="chapter" data-level="2.10" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#references-1"><i class="fa fa-check"></i><b>2.10</b> References</a></li>
<li class="chapter" data-level="2.11" data-path="probabilities-likelihood-and-inference.html"><a href="probabilities-likelihood-and-inference.html#plot-code-1"><i class="fa fa-check"></i><b>2.11</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html"><i class="fa fa-check"></i><b>3</b> Fitting Bayesian regression models with <em>brms</em></a>
<ul>
<li class="chapter" data-level="3.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#chapter-pre-cap-2"><i class="fa fa-check"></i><b>3.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="3.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-what-is-reg"><i class="fa fa-check"></i><b>3.2</b> What are regression models?</a></li>
<li class="chapter" data-level="3.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-whats-bayes"><i class="fa fa-check"></i><b>3.3</b> What’s ‘Bayesian’ about these models?</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-priors"><i class="fa fa-check"></i><b>3.3.1</b> Prior probabilities</a></li>
<li class="chapter" data-level="3.3.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-posterior"><i class="fa fa-check"></i><b>3.3.2</b> Posterior distributions</a></li>
<li class="chapter" data-level="3.3.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-characteristics-posteriors"><i class="fa fa-check"></i><b>3.3.3</b> Posterior distributions and shrinkage</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-sampling"><i class="fa fa-check"></i><b>3.4</b> Sampling from the posterior using <em>Stan</em> and <em>brms</em></a></li>
<li class="chapter" data-level="3.5" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-estimating"><i class="fa fa-check"></i><b>3.5</b> Estimating a single mean with the <code>brms</code> package</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-data-qs-1"><i class="fa fa-check"></i><b>3.5.1</b> Data and Research Questions</a></li>
<li class="chapter" data-level="3.5.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-description-1"><i class="fa fa-check"></i><b>3.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="3.5.3" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-errors-and-residuals"><i class="fa fa-check"></i><b>3.5.3</b> Errors and residuals</a></li>
<li class="chapter" data-level="3.5.4" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-model-formula"><i class="fa fa-check"></i><b>3.5.4</b> The model formula</a></li>
<li class="chapter" data-level="3.5.5" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-calling-brm"><i class="fa fa-check"></i><b>3.5.5</b> Fitting the model: Calling the <em>brm</em> function</a></li>
<li class="chapter" data-level="3.5.6" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-interpreting-print"><i class="fa fa-check"></i><b>3.5.6</b> Interpreting the model: The print statement</a></li>
<li class="chapter" data-level="3.5.7" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-seeing-samples"><i class="fa fa-check"></i><b>3.5.7</b> Seeing the samples</a></li>
<li class="chapter" data-level="3.5.8" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-getting-residuals"><i class="fa fa-check"></i><b>3.5.8</b> Getting the residuals</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-checking-convergence"><i class="fa fa-check"></i><b>3.6</b> Checking model convergence</a></li>
<li class="chapter" data-level="3.7" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-specifying-priors"><i class="fa fa-check"></i><b>3.7</b> Specifying prior probabilities</a></li>
<li class="chapter" data-level="3.8" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-log-posterior"><i class="fa fa-check"></i><b>3.8</b> The log prior and log posterior densities</a></li>
<li class="chapter" data-level="3.9" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-answering-qs"><i class="fa fa-check"></i><b>3.9</b> Answering our research questions</a></li>
<li class="chapter" data-level="3.10" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-frequentist"><i class="fa fa-check"></i><b>3.10</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-vs-ttest"><i class="fa fa-check"></i><b>3.10.1</b> One-sample t-test vs. intercept-only Bayesian models</a></li>
<li class="chapter" data-level="3.10.2" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#c3-vs-ols"><i class="fa fa-check"></i><b>3.10.2</b> Intercept-only ordinary-least-squares regression vs. intercept-only Bayesian models</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#exercises-2"><i class="fa fa-check"></i><b>3.11</b> Exercises</a></li>
<li class="chapter" data-level="3.12" data-path="fitting-bayesian-regression-models-with-brms.html"><a href="fitting-bayesian-regression-models-with-brms.html#plot-code-2"><i class="fa fa-check"></i><b>3.12</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><i class="fa fa-check"></i><b>4</b> Inspecting a ‘single group’ of observations using a Bayesian multilevel model</a>
<ul>
<li class="chapter" data-level="4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#chapter-pre-cap-3"><i class="fa fa-check"></i><b>4.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-multilevel"><i class="fa fa-check"></i><b>4.2</b> Repeated measures data</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-levels"><i class="fa fa-check"></i><b>4.2.1</b> Multilevel models and ‘levels’ of variation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-many-levels"><i class="fa fa-check"></i><b>4.3</b> Representing predictors with many levels</a></li>
<li class="chapter" data-level="4.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-strategies"><i class="fa fa-check"></i><b>4.4</b> Strategies for estimating factors with many levels</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-complete-pooling"><i class="fa fa-check"></i><b>4.4.1</b> Complete pooling</a></li>
<li class="chapter" data-level="4.4.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-no-pooling"><i class="fa fa-check"></i><b>4.4.2</b> No pooling</a></li>
<li class="chapter" data-level="4.4.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-partial-pooling"><i class="fa fa-check"></i><b>4.4.3</b> (Adaptive) Partial pooling</a></li>
<li class="chapter" data-level="4.4.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#hyperpriors"><i class="fa fa-check"></i><b>4.4.4</b> Hyperpriors</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-estimating1"><i class="fa fa-check"></i><b>4.5</b> Estimating a multilevel model with <code>brms</code></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-data-and-qs-1"><i class="fa fa-check"></i><b>4.5.1</b> Data and Research questions</a></li>
<li class="chapter" data-level="4.5.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#description-of-the-model"><i class="fa fa-check"></i><b>4.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="4.5.3" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-fitting-1"><i class="fa fa-check"></i><b>4.5.3</b> Fitting the model</a></li>
<li class="chapter" data-level="4.5.4" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#interpreting-the-model"><i class="fa fa-check"></i><b>4.5.4</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-random-effects"><i class="fa fa-check"></i><b>4.6</b> ‘Random’ Effects</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-inspecting-random-effects"><i class="fa fa-check"></i><b>4.6.1</b> Inspecting the random effects</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-simulating"><i class="fa fa-check"></i><b>4.7</b> Simulating data using our model parameters</a></li>
<li class="chapter" data-level="4.8" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-second-random-effect"><i class="fa fa-check"></i><b>4.8</b> Adding a second random effect</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-updating-model"><i class="fa fa-check"></i><b>4.8.1</b> Updating the model description</a></li>
<li class="chapter" data-level="4.8.2" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#fitting-and-interpreting-the-model"><i class="fa fa-check"></i><b>4.8.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-investigating-shrinkage"><i class="fa fa-check"></i><b>4.9</b> Investigating ‘shrinkage’</a></li>
<li class="chapter" data-level="4.10" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-answering-question"><i class="fa fa-check"></i><b>4.10</b> Answering our research questions</a></li>
<li class="chapter" data-level="4.11" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-frequentist"><i class="fa fa-check"></i><b>4.11</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="4.11.1" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-vs-lmer"><i class="fa fa-check"></i><b>4.11.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="4.12" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#exercises-3"><i class="fa fa-check"></i><b>4.12</b> Exercises</a></li>
<li class="chapter" data-level="4.13" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#references-2"><i class="fa fa-check"></i><b>4.13</b> References</a></li>
<li class="chapter" data-level="4.14" data-path="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html"><a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#plot-code-3"><i class="fa fa-check"></i><b>4.14</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html"><i class="fa fa-check"></i><b>5</b> Comparing two groups of observations: Factors and contrasts</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#chapter-pre-cap-4"><i class="fa fa-check"></i><b>5.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparing-two-groups"><i class="fa fa-check"></i><b>5.2</b> Comparing two groups</a></li>
<li class="chapter" data-level="5.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#distribution-of-repeated-measures-across-factor-levels"><i class="fa fa-check"></i><b>5.3</b> Distribution of repeated measures across factor levels</a></li>
<li class="chapter" data-level="5.4" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-data-and-qs"><i class="fa fa-check"></i><b>5.4</b> Data and research questions</a></li>
<li class="chapter" data-level="5.5" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-two-means"><i class="fa fa-check"></i><b>5.5</b> Estimating the difference between two means with ‘brms’</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model"><i class="fa fa-check"></i><b>5.5.1</b> Fitting the model</a></li>
<li class="chapter" data-level="5.5.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model-1"><i class="fa fa-check"></i><b>5.5.2</b> Interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-contrasts"><i class="fa fa-check"></i><b>5.6</b> Contrasts</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-treatment-coding"><i class="fa fa-check"></i><b>5.6.1</b> Treatment coding</a></li>
<li class="chapter" data-level="5.6.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-sum-coding"><i class="fa fa-check"></i><b>5.6.2</b> Sum coding</a></li>
<li class="chapter" data-level="5.6.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-comparison-sum-treatment"><i class="fa fa-check"></i><b>5.6.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-refittin-sum"><i class="fa fa-check"></i><b>5.7</b> Sum coding and the decomposition of variation</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-description-1"><i class="fa fa-check"></i><b>5.7.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.7.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-1"><i class="fa fa-check"></i><b>5.7.2</b> Fitting the model</a></li>
<li class="chapter" data-level="5.7.3" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparison-of-sum-and-treatment-coding"><i class="fa fa-check"></i><b>5.7.3</b> Comparison of sum and treatment coding</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-working-with-posteriors"><i class="fa fa-check"></i><b>5.8</b> Inspecting and manipulating the posterior samples</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-using-hypothesis"><i class="fa fa-check"></i><b>5.8.1</b> Using the <em>hypothesis</em> function</a></li>
<li class="chapter" data-level="5.8.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-manipulating-random-effects"><i class="fa fa-check"></i><b>5.8.2</b> Working with the random effects</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-robustness"><i class="fa fa-check"></i><b>5.9</b> Making our models more robust: The (non-standardized) t distribution</a></li>
<li class="chapter" data-level="5.10" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#re-fitting-with-t-distributed-errors."><i class="fa fa-check"></i><b>5.10</b> Re-fitting with t-distributed errors</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#description-of-the-model-1"><i class="fa fa-check"></i><b>5.10.1</b> Description of the model</a></li>
<li class="chapter" data-level="5.10.2" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-and-interpreting-the-model-1"><i class="fa fa-check"></i><b>5.10.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="5.11" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-simulating"><i class="fa fa-check"></i><b>5.11</b> Simulating the two-group model</a></li>
<li class="chapter" data-level="5.12" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-answering-qs"><i class="fa fa-check"></i><b>5.12</b> Answering our research questions</a></li>
<li class="chapter" data-level="5.13" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-frequentist"><i class="fa fa-check"></i><b>5.13</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="5.13.1" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#bayesian-multilevel-models-vs.-lmer"><i class="fa fa-check"></i><b>5.13.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="5.14" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#exercises-4"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
<li class="chapter" data-level="5.15" data-path="comparing-two-groups-of-observations-factors-and-contrasts.html"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#plot-code-4"><i class="fa fa-check"></i><b>5.15</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html"><i class="fa fa-check"></i><b>6</b> Variation in parameters (‘random effects’) and model comparison</a>
<ul>
<li class="chapter" data-level="6.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#chapter-pre-cap-5"><i class="fa fa-check"></i><b>6.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="6.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-data-and-qs"><i class="fa fa-check"></i><b>6.2</b> Data and research questions</a></li>
<li class="chapter" data-level="6.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-variation-sources"><i class="fa fa-check"></i><b>6.3</b> Variation in parameters across sources of data</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#description-of-our-model"><i class="fa fa-check"></i><b>6.3.1</b> Description of our model</a></li>
<li class="chapter" data-level="6.3.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-correlations"><i class="fa fa-check"></i><b>6.3.2</b> Correlations between random parameters</a></li>
<li class="chapter" data-level="6.3.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-random-and-mvn"><i class="fa fa-check"></i><b>6.3.3</b> Random effects and the multivariate normal distribution</a></li>
<li class="chapter" data-level="6.3.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-mvn-priors"><i class="fa fa-check"></i><b>6.3.4</b> Specifying priors for a multivariate normal distribution</a></li>
<li class="chapter" data-level="6.3.5" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#updating-our-model-description"><i class="fa fa-check"></i><b>6.3.5</b> Updating our model description</a></li>
<li class="chapter" data-level="6.3.6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-fitting"><i class="fa fa-check"></i><b>6.3.6</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-model-comparison"><i class="fa fa-check"></i><b>6.4</b> Model Comparison</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-in-and-out-prediction"><i class="fa fa-check"></i><b>6.4.1</b> In-sample and out-of-sample prediction</a></li>
<li class="chapter" data-level="6.4.2" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-out-sample-adjust"><i class="fa fa-check"></i><b>6.4.2</b> Out-of-sample prediction: Adjusting predictive accuracy</a></li>
<li class="chapter" data-level="6.4.3" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-out-sample-crossval"><i class="fa fa-check"></i><b>6.4.3</b> Out-of-sample prediction: Cross validation</a></li>
<li class="chapter" data-level="6.4.4" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#selecting-a-model"><i class="fa fa-check"></i><b>6.4.4</b> Selecting a model</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-answering"><i class="fa fa-check"></i><b>6.5</b> Answering our research questions</a></li>
<li class="chapter" data-level="6.6" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-frequentist"><i class="fa fa-check"></i><b>6.6</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-vs-lmer"><i class="fa fa-check"></i><b>6.6.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#exercises-5"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#references-3"><i class="fa fa-check"></i><b>6.8</b> References</a></li>
<li class="chapter" data-level="6.9" data-path="variation-in-parameters-random-effects-and-model-comparison.html"><a href="variation-in-parameters-random-effects-and-model-comparison.html#plot-code-5"><i class="fa fa-check"></i><b>6.9</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><i class="fa fa-check"></i><b>7</b> Comparing many groups, interactions, and posterior predictive checks</a>
<ul>
<li class="chapter" data-level="7.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#chapter-pre-cap-6"><i class="fa fa-check"></i><b>7.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="7.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#comparing-four-or-any-number-of-groups"><i class="fa fa-check"></i><b>7.2</b> Comparing four (or any number of) groups</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions"><i class="fa fa-check"></i><b>7.2.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.2.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-description-1"><i class="fa fa-check"></i><b>7.2.2</b> Description of our model</a></li>
<li class="chapter" data-level="7.2.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-2"><i class="fa fa-check"></i><b>7.2.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#investigating-multiple-factors-simultaneously"><i class="fa fa-check"></i><b>7.3</b> Investigating multiple factors simultaneously</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions-1"><i class="fa fa-check"></i><b>7.3.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.3.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#description-of-the-model-2"><i class="fa fa-check"></i><b>7.3.2</b> Description of the model</a></li>
<li class="chapter" data-level="7.3.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-3"><i class="fa fa-check"></i><b>7.3.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-posterior-prediction"><i class="fa fa-check"></i><b>7.4</b> Posterior prediction: Using our models to predict new data</a></li>
<li class="chapter" data-level="7.5" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-interactions-and-plots"><i class="fa fa-check"></i><b>7.5</b> Interactions and interaction plots</a></li>
<li class="chapter" data-level="7.6" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#investigating-interactions-with-a-model"><i class="fa fa-check"></i><b>7.6</b> Investigating interactions with a model</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#data-and-research-questions-2"><i class="fa fa-check"></i><b>7.6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="7.6.2" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#model-formulas"><i class="fa fa-check"></i><b>7.6.2</b> Model formulas</a></li>
<li class="chapter" data-level="7.6.3" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#description-of-our-model-1"><i class="fa fa-check"></i><b>7.6.3</b> Description of our model</a></li>
<li class="chapter" data-level="7.6.4" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#fitting-and-interpreting-the-model-4"><i class="fa fa-check"></i><b>7.6.4</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="7.6.5" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-calc-means"><i class="fa fa-check"></i><b>7.6.5</b> Caulculating group means in the presence of interactions</a></li>
<li class="chapter" data-level="7.6.6" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#calculating-simple-effects-in-the-presence-of-interactions"><i class="fa fa-check"></i><b>7.6.6</b> Calculating simple effects in the presence of interactions</a></li>
<li class="chapter" data-level="7.6.7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#assessing-model-fit-bayesian-r2"><i class="fa fa-check"></i><b>7.6.7</b> Assessing model fit: Bayesian <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-answering"><i class="fa fa-check"></i><b>7.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="7.8" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#factors-with-more-than-two-levels"><i class="fa fa-check"></i><b>7.8</b> Factors with more than two levels</a></li>
<li class="chapter" data-level="7.9" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#c7-frequentist"><i class="fa fa-check"></i><b>7.9</b> ‘Traditionalists’ corner</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#bayesian-multilevel-models-vs.-lmer-1"><i class="fa fa-check"></i><b>7.9.1</b> Bayesian multilevel models vs. lmer</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#exercises-6"><i class="fa fa-check"></i><b>7.10</b> Exercises</a></li>
<li class="chapter" data-level="7.11" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#references-4"><i class="fa fa-check"></i><b>7.11</b> References</a></li>
<li class="chapter" data-level="7.12" data-path="comparing-many-groups-interactions-and-posterior-predictive-checks.html"><a href="comparing-many-groups-interactions-and-posterior-predictive-checks.html#plot-code-6"><i class="fa fa-check"></i><b>7.12</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html"><i class="fa fa-check"></i><b>8</b> Varying variances, more about priors, and prior predictive checks</a>
<ul>
<li class="chapter" data-level="8.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#chapter-pre-cap-7"><i class="fa fa-check"></i><b>8.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="8.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#data-and-research-questions-3"><i class="fa fa-check"></i><b>8.2</b> Data and Research questions</a></li>
<li class="chapter" data-level="8.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#more-about-priors"><i class="fa fa-check"></i><b>8.3</b> More about priors</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-prior-prediction"><i class="fa fa-check"></i><b>8.3.1</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.3.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#more-specific-priors"><i class="fa fa-check"></i><b>8.3.2</b> More specific priors</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#heteroskedasticity-and-distributional-or-mixture-models"><i class="fa fa-check"></i><b>8.4</b> Heteroskedasticity and distributional (or mixture) models</a></li>
<li class="chapter" data-level="8.5" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#a-simple-model-error-varies-according-to-a-single-fixed-effect"><i class="fa fa-check"></i><b>8.5</b> A ‘simple’ model: Error varies according to a single fixed effect</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#description-of-our-model-2"><i class="fa fa-check"></i><b>8.5.1</b> Description of our model</a></li>
<li class="chapter" data-level="8.5.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#prior-predictive-checks"><i class="fa fa-check"></i><b>8.5.2</b> Prior predictive checks</a></li>
<li class="chapter" data-level="8.5.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#fitting-and-interpreting-the-model-5"><i class="fa fa-check"></i><b>8.5.3</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#a-complex-model-error-varies-according-to-fixed-and-random-effects"><i class="fa fa-check"></i><b>8.6</b> A ‘complex’ model: Error varies according to fixed and random effects</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-description-2"><i class="fa fa-check"></i><b>8.6.1</b> Description of our model</a></li>
<li class="chapter" data-level="8.6.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#fitting-and-interpreting-the-model-6"><i class="fa fa-check"></i><b>8.6.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#answering-our-research-questions"><i class="fa fa-check"></i><b>8.7</b> Answering our research questions</a></li>
<li class="chapter" data-level="8.8" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-identifiability"><i class="fa fa-check"></i><b>8.8</b> Building identifiable and supportable models</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#collinearity"><i class="fa fa-check"></i><b>8.8.1</b> Collinearity</a></li>
<li class="chapter" data-level="8.8.2" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#predictable-values-of-categorical-predictors"><i class="fa fa-check"></i><b>8.8.2</b> Predictable values of categorical predictors</a></li>
<li class="chapter" data-level="8.8.3" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#saturated-and-nearly-saturated-models"><i class="fa fa-check"></i><b>8.8.3</b> Saturated, and ‘nearly-saturated’, models</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#exercises-7"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
<li class="chapter" data-level="8.10" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#references-5"><i class="fa fa-check"></i><b>8.10</b> References</a></li>
<li class="chapter" data-level="8.11" data-path="varying-variances-more-about-priors-and-prior-predictive-checks.html"><a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#plot-code-7"><i class="fa fa-check"></i><b>8.11</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html"><i class="fa fa-check"></i><b>9</b> Quantitative predictors and their interactions with factors</a>
<ul>
<li class="chapter" data-level="9.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#chapter-pre-cap-8"><i class="fa fa-check"></i><b>9.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="9.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#data-and-research-questions-4"><i class="fa fa-check"></i><b>9.2</b> Data and research questions</a></li>
<li class="chapter" data-level="9.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#modeling-variation-along-lines"><i class="fa fa-check"></i><b>9.3</b> Modeling variation along lines</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-3"><i class="fa fa-check"></i><b>9.3.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.3.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-centering"><i class="fa fa-check"></i><b>9.3.2</b> Centering quantitative predictors</a></li>
<li class="chapter" data-level="9.3.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-an-interpreting-the-model"><i class="fa fa-check"></i><b>9.3.3</b> Fitting an interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-intercepts-but-shared-slopes"><i class="fa fa-check"></i><b>9.4</b> Models with group-dependent intercepts, but shared slopes</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-4"><i class="fa fa-check"></i><b>9.4.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.4.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-and-interpreting-the-model-7"><i class="fa fa-check"></i><b>9.4.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.4.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-shared-non-zero-slopes"><i class="fa fa-check"></i><b>9.4.3</b> Interpreting group effects in the presence of shared (non-zero) slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-group-dependent-slopes-and-intercepts"><i class="fa fa-check"></i><b>9.5</b> Models with group-dependent slopes and intercepts</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-5"><i class="fa fa-check"></i><b>9.5.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.5.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-fitting-3"><i class="fa fa-check"></i><b>9.5.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.5.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#interpreting-group-effects-in-the-presence-of-varying-slopes"><i class="fa fa-check"></i><b>9.5.3</b> Interpreting group effects in the presence of varying slopes</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#answering-our-research-questions-interim-discussion"><i class="fa fa-check"></i><b>9.6</b> Answering our research questions: Interim discussion</a></li>
<li class="chapter" data-level="9.7" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#data-and-research-questions-updated"><i class="fa fa-check"></i><b>9.7</b> Data and research questions: Updated</a></li>
<li class="chapter" data-level="9.8" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-intercepts-and-slopes-for-each-level-of-a-grouping-factor-i.e.-random-slopes"><i class="fa fa-check"></i><b>9.8</b> Models with intercepts and slopes for each level of a grouping factor (i.e. ‘random slopes’)</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-6"><i class="fa fa-check"></i><b>9.8.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.8.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#fitting-and-interpreting-the-model-8"><i class="fa fa-check"></i><b>9.8.2</b> Fitting and interpreting the model</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#models-with-multiple-predictors-for-each-level-of-a-grouping-factor"><i class="fa fa-check"></i><b>9.9</b> Models with multiple predictors for each level of a grouping factor</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#description-of-the-model-7"><i class="fa fa-check"></i><b>9.9.1</b> Description of the model</a></li>
<li class="chapter" data-level="9.9.2" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#c9-fitting-5"><i class="fa fa-check"></i><b>9.9.2</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="9.9.3" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#model-selection"><i class="fa fa-check"></i><b>9.9.3</b> Model selection</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#answering-our-research-questions-updated"><i class="fa fa-check"></i><b>9.10</b> Answering our research questions: Updated</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#a-word-on-causality"><i class="fa fa-check"></i><b>9.10.1</b> A word on causality</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#exercises-8"><i class="fa fa-check"></i><b>9.11</b> Exercises</a></li>
<li class="chapter" data-level="9.12" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#references-6"><i class="fa fa-check"></i><b>9.12</b> References</a></li>
<li class="chapter" data-level="9.13" data-path="quantitative-predictors-and-their-interactions-with-factors.html"><a href="quantitative-predictors-and-their-interactions-with-factors.html#plot-code-8"><i class="fa fa-check"></i><b>9.13</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html"><i class="fa fa-check"></i><b>10</b> Logistic regression and signal detection theory models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#chapter-pre-cap-9"><i class="fa fa-check"></i><b>10.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-dichotomous"><i class="fa fa-check"></i><b>10.2</b> Dichotomous variables and data</a></li>
<li class="chapter" data-level="10.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#generalizing-our-linear-models"><i class="fa fa-check"></i><b>10.3</b> Generalizing our linear models</a></li>
<li class="chapter" data-level="10.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logistic-regression"><i class="fa fa-check"></i><b>10.4</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logits"><i class="fa fa-check"></i><b>10.4.1</b> Logits</a></li>
<li class="chapter" data-level="10.4.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-inverse-logit"><i class="fa fa-check"></i><b>10.4.2</b> The inverse logit link function</a></li>
<li class="chapter" data-level="10.4.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#building-intuitions-about-logits-and-the-inverse-logit-function"><i class="fa fa-check"></i><b>10.4.3</b> Building intuitions about logits and the inverse logit function</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#logistic-regression-with-one-quantitative-predictor"><i class="fa fa-check"></i><b>10.5</b> Logistic regression with one quantitative predictor</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#data-and-research-questions-5"><i class="fa fa-check"></i><b>10.5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="10.5.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#description-of-the-model-8"><i class="fa fa-check"></i><b>10.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="10.5.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-fitting-0"><i class="fa fa-check"></i><b>10.5.3</b> Fitting the model</a></li>
<li class="chapter" data-level="10.5.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-fitting-1"><i class="fa fa-check"></i><b>10.5.4</b> Interpreting the model</a></li>
<li class="chapter" data-level="10.5.5" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#c10-classification"><i class="fa fa-check"></i><b>10.5.5</b> Using logistic models to understand classification</a></li>
<li class="chapter" data-level="10.5.6" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#answering-our-research-question"><i class="fa fa-check"></i><b>10.5.6</b> Answering our research question</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#measuring-sensitivity-and-bias"><i class="fa fa-check"></i><b>10.6</b> Measuring sensitivity and bias</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#data-and-research-questions-6"><i class="fa fa-check"></i><b>10.6.1</b> Data and research questions</a></li>
<li class="chapter" data-level="10.6.2" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#description-of-the-model-9"><i class="fa fa-check"></i><b>10.6.2</b> Description of the model</a></li>
<li class="chapter" data-level="10.6.3" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#fitting-and-interpreting-the-model-9"><i class="fa fa-check"></i><b>10.6.3</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="10.6.4" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#answering-our-research-questions-1"><i class="fa fa-check"></i><b>10.6.4</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#exercises-9"><i class="fa fa-check"></i><b>10.7</b> Exercises</a></li>
<li class="chapter" data-level="10.8" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#references-7"><i class="fa fa-check"></i><b>10.8</b> References</a></li>
<li class="chapter" data-level="10.9" data-path="logistic-regression-and-signal-detection-theory-models.html"><a href="logistic-regression-and-signal-detection-theory-models.html#plot-code-9"><i class="fa fa-check"></i><b>10.9</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><i class="fa fa-check"></i><b>11</b> Multiple quantitative predictors, dealing with large models, and Bayesian ANOVA</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#chapter-pre-cap-10"><i class="fa fa-check"></i><b>11.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="11.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#models-with-multiple-quantitative-predictors"><i class="fa fa-check"></i><b>11.2</b> Models with multiple quantitative predictors</a></li>
<li class="chapter" data-level="11.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#interactions-between-quantitative-predictors"><i class="fa fa-check"></i><b>11.3</b> Interactions between quantitative predictors</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#centering-quantitative-predictors-when-including-interactions"><i class="fa fa-check"></i><b>11.3.1</b> Centering quantitative predictors when including interactions</a></li>
<li class="chapter" data-level="11.3.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-7"><i class="fa fa-check"></i><b>11.3.2</b> Data and research questions</a></li>
<li class="chapter" data-level="11.3.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-description-1"><i class="fa fa-check"></i><b>11.3.3</b> Description of the model</a></li>
<li class="chapter" data-level="11.3.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-the-model-2"><i class="fa fa-check"></i><b>11.3.4</b> Fitting the model</a></li>
<li class="chapter" data-level="11.3.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#advantages-of-bayesian-multilevel-models-for-large-models"><i class="fa fa-check"></i><b>11.3.5</b> Advantages of Bayesian multilevel models for large models</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c11-BANOVA"><i class="fa fa-check"></i><b>11.4</b> Bayesian Analysis of Variance</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#getting-the-standard-deviations-from-our-models-manually"><i class="fa fa-check"></i><b>11.4.1</b> Getting the standard deviations from our models ‘manually’</a></li>
<li class="chapter" data-level="11.4.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#using-the-banova-function"><i class="fa fa-check"></i><b>11.4.2</b> Using the <code>banova</code> function</a></li>
<li class="chapter" data-level="11.4.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-comparing-the-reduced-model"><i class="fa fa-check"></i><b>11.4.3</b> Fitting and comparing the reduced model</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#a-logistic-regression-model-with-multiple-quantitative-predictors"><i class="fa fa-check"></i><b>11.5</b> A logistic regression model with multiple quantitative predictors</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#data-and-research-questions-8"><i class="fa fa-check"></i><b>11.5.1</b> Data and research questions</a></li>
<li class="chapter" data-level="11.5.2" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#description-of-the-model-10"><i class="fa fa-check"></i><b>11.5.2</b> Description of the model</a></li>
<li class="chapter" data-level="11.5.3" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#fitting-and-the-model-and-applying-a-bayesian-anova"><i class="fa fa-check"></i><b>11.5.3</b> Fitting and the model and applying a Bayesian ANOVA</a></li>
<li class="chapter" data-level="11.5.4" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#c12-2d-categorization"><i class="fa fa-check"></i><b>11.5.4</b> Categorization in two dimensions</a></li>
<li class="chapter" data-level="11.5.5" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#model-selection-and-misspecification"><i class="fa fa-check"></i><b>11.5.5</b> Model selection and misspecification</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#exercises-10"><i class="fa fa-check"></i><b>11.6</b> Exercises</a></li>
<li class="chapter" data-level="11.7" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#references-8"><i class="fa fa-check"></i><b>11.7</b> References</a></li>
<li class="chapter" data-level="11.8" data-path="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html"><a href="multiple-quantitative-predictors-dealing-with-large-models-and-bayesian-anova.html#plot-code-10"><i class="fa fa-check"></i><b>11.8</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html"><i class="fa fa-check"></i><b>12</b> Multinomial and Ordinal regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#chapter-pre-cap-11"><i class="fa fa-check"></i><b>12.1</b> Chapter pre-cap</a></li>
<li class="chapter" data-level="12.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#multinomial-logistic-regression"><i class="fa fa-check"></i><b>12.2</b> Multinomial logistic regression</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#multinomial-logits-and-the-softmax-function"><i class="fa fa-check"></i><b>12.2.1</b> Multinomial logits and the softmax function</a></li>
<li class="chapter" data-level="12.2.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#comparison-to-logistic-regression"><i class="fa fa-check"></i><b>12.2.2</b> Comparison to logistic regression</a></li>
<li class="chapter" data-level="12.2.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#data-and-research-questions-9"><i class="fa fa-check"></i><b>12.2.3</b> Data and research questions</a></li>
<li class="chapter" data-level="12.2.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#description-of-our-model-3"><i class="fa fa-check"></i><b>12.2.4</b> Description of our model</a></li>
<li class="chapter" data-level="12.2.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#fitting-the-model-3"><i class="fa fa-check"></i><b>12.2.5</b> Fitting the model</a></li>
<li class="chapter" data-level="12.2.6" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#interpreting-the-model-2"><i class="fa fa-check"></i><b>12.2.6</b> Interpreting the model</a></li>
<li class="chapter" data-level="12.2.7" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#c12-multinomial-territorial-maps"><i class="fa fa-check"></i><b>12.2.7</b> Multinomial models and territorial maps</a></li>
<li class="chapter" data-level="12.2.8" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#refitting-the-model-without-speaker-random-effects"><i class="fa fa-check"></i><b>12.2.8</b> Refitting the model without speaker random effects</a></li>
<li class="chapter" data-level="12.2.9" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#answering-our-research-questions-2"><i class="fa fa-check"></i><b>12.2.9</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>12.3</b> Ordinal (logistic) regression</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#c12-cumulative-density"><i class="fa fa-check"></i><b>12.3.1</b> Cumulative distribution functions</a></li>
<li class="chapter" data-level="12.3.2" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#data-and-research-questions-10"><i class="fa fa-check"></i><b>12.3.2</b> Data and research questions</a></li>
<li class="chapter" data-level="12.3.3" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#description-of-the-model-11"><i class="fa fa-check"></i><b>12.3.3</b> Description of the model</a></li>
<li class="chapter" data-level="12.3.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#fitting-and-interpreting-the-model-10"><i class="fa fa-check"></i><b>12.3.4</b> Fitting and interpreting the model</a></li>
<li class="chapter" data-level="12.3.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#listener-specific-discrimination-terms"><i class="fa fa-check"></i><b>12.3.5</b> Listener-specific discrimination terms</a></li>
<li class="chapter" data-level="12.3.6" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#answering-our-research-questions-3"><i class="fa fa-check"></i><b>12.3.6</b> Answering our research questions</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#exercises-11"><i class="fa fa-check"></i><b>12.4</b> Exercises</a></li>
<li class="chapter" data-level="12.5" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#references-9"><i class="fa fa-check"></i><b>12.5</b> References</a></li>
<li class="chapter" data-level="12.6" data-path="multinomial-and-ordinal-regression.html"><a href="multinomial-and-ordinal-regression.html#plot-code-11"><i class="fa fa-check"></i><b>12.6</b> Plot Code</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><i class="fa fa-check"></i><b>13</b> Writing up experiments: An investigation of the perception of apparent speaker characteristics from speech acoustics</a>
<ul>
<li class="chapter" data-level="13.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#introduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#fundamental-frequency-and-voice-pitch"><i class="fa fa-check"></i><b>13.1.1</b> Fundamental frequency and voice pitch</a></li>
<li class="chapter" data-level="13.1.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#variation-in-fundamental-frequency-between-speakers"><i class="fa fa-check"></i><b>13.1.2</b> Variation in fundamental frequency between speakers</a></li>
<li class="chapter" data-level="13.1.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#voice-resonance-and-vocal-tract-length"><i class="fa fa-check"></i><b>13.1.3</b> Voice resonance and vocal-tract length</a></li>
<li class="chapter" data-level="13.1.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-estimating-vtl"><i class="fa fa-check"></i><b>13.1.4</b> Estimating vocal-tracts length from speech</a></li>
<li class="chapter" data-level="13.1.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#variation-in-vocal-tract-length-between-speakers"><i class="fa fa-check"></i><b>13.1.5</b> Variation in vocal-tract length between speakers</a></li>
<li class="chapter" data-level="13.1.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-perception-of-chars"><i class="fa fa-check"></i><b>13.1.6</b> Perception of age, gender and size</a></li>
<li class="chapter" data-level="13.1.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#category-dependent-behavior"><i class="fa fa-check"></i><b>13.1.7</b> Category-dependent behavior</a></li>
<li class="chapter" data-level="13.1.8" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#the-current-experiment"><i class="fa fa-check"></i><b>13.1.8</b> The current experiment</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#methods"><i class="fa fa-check"></i><b>13.2</b> Methods</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#participants"><i class="fa fa-check"></i><b>13.2.1</b> Participants</a></li>
<li class="chapter" data-level="13.2.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#c13-stimuli"><i class="fa fa-check"></i><b>13.2.2</b> Stimuli</a></li>
<li class="chapter" data-level="13.2.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#procedure"><i class="fa fa-check"></i><b>13.2.3</b> Procedure</a></li>
<li class="chapter" data-level="13.2.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#data-screening"><i class="fa fa-check"></i><b>13.2.4</b> Data screening</a></li>
<li class="chapter" data-level="13.2.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#loading-the-data-and-packages"><i class="fa fa-check"></i><b>13.2.5</b> Loading the data and packages</a></li>
<li class="chapter" data-level="13.2.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#statistical-analysis-apparent-height"><i class="fa fa-check"></i><b>13.2.6</b> Statistical Analysis: Apparent height</a></li>
<li class="chapter" data-level="13.2.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#statistical-analysis-apparent-gender"><i class="fa fa-check"></i><b>13.2.7</b> Statistical Analysis: Apparent gender</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#results-apparent-height-judgments"><i class="fa fa-check"></i><b>13.3</b> Results: Apparent height judgments</a></li>
<li class="chapter" data-level="13.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#discussion-apparent-height"><i class="fa fa-check"></i><b>13.4</b> Discussion: Apparent height</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#age-dependent-use-of-vtl-cues-on-apparent-height"><i class="fa fa-check"></i><b>13.4.1</b> Age-dependent use of VTL cues on apparent height</a></li>
<li class="chapter" data-level="13.4.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#the-effect-for-apparent-gender-on-apparent-height"><i class="fa fa-check"></i><b>13.4.2</b> The effect for apparent gender on apparent height</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#conclusion-apparent-height-judgments"><i class="fa fa-check"></i><b>13.5</b> Conclusion: Apparent height judgments</a></li>
<li class="chapter" data-level="13.6" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#results-apparent-gender-judgments"><i class="fa fa-check"></i><b>13.6</b> Results: Apparent gender judgments</a></li>
<li class="chapter" data-level="13.7" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#discussion-apparent-gender-judgments"><i class="fa fa-check"></i><b>13.7</b> Discussion: Apparent gender judgments</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#effect-of-apparent-age-on-the-perception-of-femaleness"><i class="fa fa-check"></i><b>13.7.1</b> Effect of apparent age on the perception of femaleness</a></li>
<li class="chapter" data-level="13.7.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#between-listener-variation-in-gender-perception"><i class="fa fa-check"></i><b>13.7.2</b> Between-listener variation in gender perception</a></li>
<li class="chapter" data-level="13.7.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#beyond-gross-acoustic-cues-in-gender-perception"><i class="fa fa-check"></i><b>13.7.3</b> Beyond gross acoustic cues in gender perception</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#conclusion-apparent-gender"><i class="fa fa-check"></i><b>13.8</b> Conclusion: Apparent gender</a></li>
<li class="chapter" data-level="13.9" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#next-steps"><i class="fa fa-check"></i><b>13.9</b> Next steps</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#research-design-variable-selection-etc."><i class="fa fa-check"></i><b>13.9.1</b> Research design, variable selection, etc.</a></li>
<li class="chapter" data-level="13.9.2" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#non-linear-models"><i class="fa fa-check"></i><b>13.9.2</b> Non-linear models</a></li>
<li class="chapter" data-level="13.9.3" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#other-data-distributions"><i class="fa fa-check"></i><b>13.9.3</b> Other data distributions</a></li>
<li class="chapter" data-level="13.9.4" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#multivariate-analyses"><i class="fa fa-check"></i><b>13.9.4</b> Multivariate analyses</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#references-10"><i class="fa fa-check"></i><b>13.10</b> References</a></li>
<li class="chapter" data-level="13.11" data-path="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html"><a href="writing-up-experiments-an-investigation-of-the-perception-of-apparent-speaker-characteristics-from-speech-acoustics.html#plot-code-12"><i class="fa fa-check"></i><b>13.11</b> Plot Code</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/santiagobarreda/bmmrmd" target="blank">Book GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Bayesian multilevel models for repeated-measures data: A conceptual and practical introduction in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="comparing-two-groups-of-observations-factors-and-contrasts" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Comparing two groups of observations: Factors and contrasts<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparing-two-groups-of-observations-factors-and-contrasts" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The models discussed in this chapter can be used for data that compares observations across two groups. In this chapter we will ask: Are two averages different or are they the same? Comparing two groups basically means estimating a single <em>effect</em>, a single difference between groups. We do not discuss the comparison of multiple groups, i.e. the estimation of multiple fixed effects, until chapter 7.</p>
<p>Research questions comparing two groups come up often in scientific research. For example, a psycholinguist may ask: Does visual information speed up speech perception or not (are two sets of reaction times the same)? A phonetician may ask: Do men and women produce vowels that are about the same duration (are two sets of speech durations the same)? A doctor may ask: Is the blood pressure of people who take some medicine the same as that of those who don’t (are two sets of blood pressure measurements the same)?</p>
<div id="chapter-pre-cap-4" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Chapter pre-cap<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#chapter-pre-cap-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter, we discuss models comparing two groups, and introduce the concept of between and within-subjects factors. Factor coding is presented, and treatment and sum coding are compared. We then discuss the decomposition of variation in the dependent variable into effects associated with independent variables, and the difficulty of establishing causal relationships using statistical models. We fit a sum coded model comparing two groups, and compare this to a treatment coded model fit to the same data. We present a discussion on retrieving and manipulating the model posterior samples, including the importance of combining parameters before summarizing them. The <code>hypothesis</code> function is introduced, and the retrieval and combination of ‘random effect’ parameters is explained. Finally, there is a discussion of outliers and robustness, and the t distribution is presented. We fit a model with t distributed errors, and compare this to our model assuming normal errors.</p>
</div>
<div id="comparing-two-groups" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Comparing two groups<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparing-two-groups" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We introduce the comparison of two groups in terms of our hypothetical experiment regarding coffee and reading times (discussed in chapter 1) where we investigate whether coffee makes people read faster. Subjects are asked to drink either a cup of decaf or a cup of regular coffee. After a 30-minute wait they are asked to read a passage aloud and the duration of the reading time is measured. In this case, we might call the factor “drink” and have two levels “decaf”, and “coffee”. However, we might have named them “A1” and “A2”: The factor and factor levels are named arbitrarily by the researcher and have no real effect on the outcome of an analysis.</p>
<p>Every observation in our data can be assigned to a ‘group’ based on the value of the coffee group predictor for that observation (i.e., whether it indicates that the observation is associated with decaf, or regular coffee). The values associated with each group can be thought of as realizations of two random variables: “the amount of time it takes people to read this passage of text after drinking decaf”, and “the amount of time it takes people to read this passage of text after drinking regular coffee”. These variables have some unknown mean parameters we can call <span class="math inline">\(\mu_{\mathrm{decaf}}\)</span> and <span class="math inline">\(\mu_{\mathrm{coffee}}\)</span> respectively.</p>
<p>Usually, researchers don’t ask if two distributions of observations are identical in absolutely all respects across the two groups, and instead mostly focus on whether <span class="math inline">\(\mu_{\mathrm{decaf}}=\mu_{\mathrm{coffee}}\)</span> or not. So, when we design an experiment to test for differences between groups, what we are often really asking is: Is the mean of the distribution of these two variables the same? In other words, is “the mean of the distribution of the amount of time it takes people to read this passage of text after drinking decaf” the same as “the mean of the distribution of the amount of time it takes people to read this passage of text after drinking coffee”?</p>
</div>
<div id="distribution-of-repeated-measures-across-factor-levels" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Distribution of repeated measures across factor levels<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#distribution-of-repeated-measures-across-factor-levels" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Since we are discussing repeated measures data, we necessarily have repeated observations of measurements for different sources of data (e.g. listener). The way that these repeated measurements are distributed across levels of a grouping factor affects the structure of your regression model and the efficiency of your analysis, so it is useful to be familiar with these characteristics. We will consider a situation where you have several subjects (<span class="math inline">\(S\)</span>) distributed among levels of a predictor factor (<span class="math inline">\(A\)</span>) with two levels. Figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-1">5.1</a> is a visual representation of three ways that the comparison of two groups can be structured: Between-subjects, within-subjects, and an unnamed but possible configuration.</p>
<div class="figure"><span style="display:block;" id="fig:F5-1"></span>
<img src="../_main_files/figure-html/Figure 5.1.jpg" alt="Three ways that subjects (S) can vary across levels of the factor A, making two groups." width="100%" />
<p class="caption">
Figure 5.1: Three ways that subjects (S) can vary across levels of the factor A, making two groups.
</p>
</div>
<p>We can consider the organizations in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-1">5.1</a> in terms of our hypothetical experiment regarding coffee and reading times described above. In the first example, factor <span class="math inline">\(A\)</span> is a <em>within-subjects</em> factor. This is because each subject appears at both levels of <span class="math inline">\(A\)</span> so that the grouping factor (<span class="math inline">\(A\)</span>) varies <em>within</em> subjects. This would occur if we measured all subjects at both levels, i.e., we first ask people to read the passage after drinking decaf, then, we ask them to do the same after drinking regular coffee. Within-subject factors can usually be estimated more reliably because their effect can be measured for each person, letting you ‘average out’ random differences between people. For example, what if you put an extremely fast reader in the coffee group. You may think the caffeine had a huge effect but they actually just naturally read fast. If you had also observed them in the decaf group you would know that.</p>
<p>Although having factors vary within-subjects has many benefits, this is not always possible or practical. For example, speakers cannot usually exist at multiple levels of first language since most have only one first language. Sometimes, practical considerations cause problems. For example, for our hypothetical experiment we can’t give people coffee first and then decaf in the same session because the caffeine would still have an effect on their performance. To solve this problem a researcher may always ask subjects to perform the decaf round first. However, this may make the second reading faster due to rehearsal effects, making the second (caffeinated) reading seem artificially faster. Sometimes, there is no perfect solution to a problem and a researcher will need to select the best experimental structure given the limitations of the situation.</p>
<p>In the second example <span class="math inline">\(A\)</span> is a <em>between-subjects</em> factor. This is because the factor varies <em>between</em> subjects since each subject appears at only one level of <span class="math inline">\(A\)</span>. This would occur if we only measured subjects in either the decaf condition or the coffee condition, but not both. A design like this avoids the possible problems with within-subjects designs mentioned above. However, since different random people are in each group, finding stable differences between groups is a bit harder. As a result, the estimation of between-subjects factors will tend to be noisier than for within-subjects factors, all other things being equal.</p>
<p>Finally, we have a design that doesn’t really have a name (labelled ?). This would arise if you tested some people in both conditions, and other people in only one condition. This is not really a ‘proper’ design, to the extent that it cannot be analyzed with some more ‘traditional’ approaches to statistical inference. Although there is no particular reason that you should design an experiment like this, this sort of data can arise incidentally out of experiments or observational studies.</p>
<p>For example in our experiment we asked people to judge the height, age, and gender of all speakers. Imagine we’re interested in the effect of apparent age on apparent height, we wonder, “do people sound shorter when listeners think they are children?”. To investigate this question we would make two groups, one containing all rows where listeners indicated hearing a child, and another with all rows where listeners indicated hearing an adult. If <em>all</em> listeners identify at least some speakers as adults and others as children, then apparent age is a <em>within-subject</em> factor. This is because in this case, all listeners would exist in both the “I think the speaker is an adult” and “I think the speaker is a child” groups (though the number of observations at each of these levels would likely vary across listeners). If all listeners identified <em>all</em> speakers as <em>either</em> children <em>or</em> adults, then apparent age would be a <em>between-subjects</em> factor. This is because there would be no speakers in <em>both</em> the “I think the speaker is an adult” and the “I think the speaker is a child group”.</p>
<p>However, it may occur that <em>some</em> speakers report both adult and child speakers, others report only adult speakers and others report only child speakers. If this were to occur, we could end up with the unnamed organization unintentionally due to the behavior of the listeners in the experiment. Note that in all of these cases, drawing inferences is additionally complicated by the fact that we can’t randomly allocate listeners to either the “I think the speaker is an adult” or the “I think the speaker is a child” group, though we can (probably) shift the probability that a listener perceives particular speech stimuli as adult or childlike. Hence, these groups are more like groups defined by listeners’ first languages than they are like decaf and coffee groups (i.e., there is a lack of <em>control</em> in their creation).</p>
</div>
<div id="c5-data-and-qs" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Data and research questions<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-data-and-qs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the last chapter we focused on the apparent height of adult male speakers. The reason for this is that, because of the very low voice pitch of many adult male speakers, adult males represent the least confusable category of speakers from among women, men, boys and girls. For example we can compare veridical (i.e. actual, <code>C_v</code>) to perceived (<code>C</code>) speaker category in what is called a <strong>confusion matrix</strong> below. A confusion matrix organizes responses to a classification problem in a way that makes correct classifications and confusions (i.e., errors) comparable across categories. In the matrix below, rows indicate actual speaker category and columns indicate apparent speaker category. We see that boys were identified as boys 234 times in total, and as girls and adult females 133 and 32 times respectively. So, boys were misidentified at a relatively high rate. In contrast, men were correctly identified in 626 cases and only misidentified in 49 cases, meaning their category was correctly identified in 93% of cases (<span class="math inline">\(626/(626+49)\)</span>).</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span> ( <span class="sc">~</span> bmmb<span class="sc">::</span>exp_data<span class="sc">$</span>C_v <span class="sc">+</span> bmmb<span class="sc">::</span>exp_data<span class="sc">$</span>C)</span>
<span id="cb124-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="do">##                   bmmb::exp_data$C</span></span>
<span id="cb124-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-3" aria-hidden="true" tabindex="-1"></a><span class="do">## bmmb::exp_data$C_v   b   g   m   w</span></span>
<span id="cb124-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="do">##                  b 234 133   6  32</span></span>
<span id="cb124-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-5" aria-hidden="true" tabindex="-1"></a><span class="do">##                  g  79 184   0  22</span></span>
<span id="cb124-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-6" aria-hidden="true" tabindex="-1"></a><span class="do">##                  m  31   0 626  18</span></span>
<span id="cb124-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb124-7" aria-hidden="true" tabindex="-1"></a><span class="do">##                  w  97 109   3 511</span></span></code></pre></div>
<p>In this chapter we’re going to focus on <em>confusable</em> voices, so we’re going to exclude adult males from our data. Below we load our packages and experimental data, and create a new data frame called <code>notmen</code> that excludes all data associated with adult male speakers. This excludes both speech produced by adult males, and stimuli identified as being produced by adult males. We also exclude the ‘big’ resonance level by using the <code>exp_data</code> data frame, focusing only on the unmodified speech.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="co"># load packages and data</span></span>
<span id="cb125-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (bmmb)</span>
<span id="cb125-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (brms)</span>
<span id="cb125-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span> (exp_data)</span>
<span id="cb125-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-6" aria-hidden="true" tabindex="-1"></a><span class="co"># exclude actual men and apparent men</span></span>
<span id="cb125-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb125-7" aria-hidden="true" tabindex="-1"></a>notmen <span class="ot">=</span> exp_data[exp_data<span class="sc">$</span>C_v<span class="sc">!=</span><span class="st">&#39;m&#39;</span> <span class="sc">&amp;</span> exp_data<span class="sc">$</span>C<span class="sc">!=</span><span class="st">&#39;m&#39;</span>,]</span></code></pre></div>
<p>We create a new confusion matrix that compares <code>A_v</code> (veridical age group, with levels <code>a</code> adults, and <code>c</code> children) and <code>C</code> (apparent speaker category) to see to what extent listeners confused the adult women in our sample with younger speakers (since all adults were women). We can see that although a majority of stimuli were classified correctly, there are plenty of misidentifications in the data.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span> (<span class="sc">~</span> notmen<span class="sc">$</span>A_v <span class="sc">+</span> notmen<span class="sc">$</span>C)</span>
<span id="cb126-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="do">##           notmen$C</span></span>
<span id="cb126-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="do">## notmen$A_v   b   g   w</span></span>
<span id="cb126-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="do">##          a  97 109 511</span></span>
<span id="cb126-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="do">##          c 313 317  54</span></span></code></pre></div>
<p>Our height responses could potentially be modeled on the basis of either apparent age group or veridical age group. Neither of these approaches would be <em>wrong</em> or <em>right</em> in any general, absolute sense. Rather, each can provide different information regarding our response variable, and so answer different research questions. The boxplot in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-2">5.2</a> presents a comparison of height judgments for our confusable speakers, organized according to perceived and veridical age. Based on this plot we see that the apparent age of a speaker dominates their apparent height.</p>
<div class="figure"><span style="display:block;" id="fig:F5-2"></span>
<img src="_main_files/figure-html/F5-2-1.jpeg" alt="Distribution of apparent height judgments organized by apparent and veridical age. Apparent height varies a lot across levels of apparent age, but not much across levels of veridical age." width="4800" />
<p class="caption">
Figure 5.2: Distribution of apparent height judgments organized by apparent and veridical age. Apparent height varies a lot across levels of apparent age, but not much across levels of veridical age.
</p>
</div>
<p>For example, the first two boxes from the top indicate that speakers ‘sounded’ shorter when they were identified as children, regardless of whether they were adults or not. Conversely, the bottom two boxes indicate that speakers ‘sounded’ taller when they were identified as adults, even if they were children. So, we see that what seems to determine apparent height is apparent speaker age, rather than veridical speaker age. This makes sense to some extent, since listeners don’t <em>know</em> how old speakers are, they just know how old they <em>think</em> speakers are. For this reason, the analysis in this chapter will focus on understanding the role of <em>apparent age</em> on the perception of speaker height.</p>
<p>By focusing on apparent age, we are effectively asking how apparent height is affected by whether the listener <em>thinks</em> the speaker is an adult or not. As a result, this experiment focuses on how our expectations and ‘real world knowledge’ can influence how we perceive the world. This may seem unusual but it is actually a very common thing. For example think of an image of a box of an unknown size. Your estimate of how heavy this is, or how hard it is to move, will depend on how large you think the box is and on what you think is inside of it. Historically, research on the perception of speaker size from speech has taken a very mathematical approach, assuming humans are using acoustic information in an optimal and dispassionate manner. More recent work highlights the role of ‘real world knowledge’, and stereotypes about different kinds of speakers, in the determination (or reporting) of apparent speaker height (see chapter 13 for more information on this topic).</p>
<p>One potential problem with using apparent age as a predictor is that this is not necessarily balanced across listeners. To investigate the distribution of levels of <span class="math inline">\(A\)</span> across listeners, we can cross-tabulate age classifications by listener as seen below. Since each listener has observations at both levels of the <code>A</code> factor (i.e. across each column), we know that apparent age is a within-subjects factor. If <em>all</em> of the columns contained one zero and one non-zero value, this would be a <em>between-subjects</em> factor. Finally, if <em>some</em> of the columns featured one zero and others featured no zeros apparent age would vary across listeners in a manner resembling the nameless (?) design.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span> (<span class="sc">~</span> notmen<span class="sc">$</span>A <span class="sc">+</span> notmen<span class="sc">$</span>L)</span>
<span id="cb127-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="do">##         notmen$L</span></span>
<span id="cb127-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="do">## notmen$A  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15</span></span>
<span id="cb127-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb127-4" aria-hidden="true" tabindex="-1"></a><span class="do">##        a 42 35 42 20 34 37 30 48 42 46 42 44 31 36 36</span></span>
<span id="cb127-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb127-5" aria-hidden="true" tabindex="-1"></a><span class="do">##        c 52 59 50 74 58 55 64 46 49 48 52 50 63 58 58</span></span></code></pre></div>
<p>We can see an example of our ‘undesirable’ organization when we inspect the distribution of apparent age across speakers, a subset of which is shown below. Some speakers are <em>never</em> identified as adults, some are <em>always</em> identified as adults, and some are <em>sometimes</em> identified as adults.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span> (<span class="sc">~</span> notmen<span class="sc">$</span>A <span class="sc">+</span> notmen<span class="sc">$</span>S)[,<span class="dv">40</span><span class="sc">:</span><span class="dv">50</span>]</span>
<span id="cb128-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="do">##         notmen$S</span></span>
<span id="cb128-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="do">## notmen$A 40 41 42 43 44 45 46 92 93 94 95</span></span>
<span id="cb128-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb128-4" aria-hidden="true" tabindex="-1"></a><span class="do">##        a 11  0  0  0  0  0  0 11  7 15 14</span></span>
<span id="cb128-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb128-5" aria-hidden="true" tabindex="-1"></a><span class="do">##        c  4 15 15 15 15 15 15  4  8  0  1</span></span></code></pre></div>
<p>To analyze data from two groups, we need to have it in a data frame with one row for each observation. One column should contain the dependent variable, the variable whose variation you’re trying to predict. Another column should contain information about which group each observation belongs to. Finally, since we have repeated measures data, we also need a column that indicates which source (speaker/listener/participant) provided the data point. The variables from our <code>exp_data</code> data frame that we will be using are:</p>
<ul>
<li><code>L</code>: An integer from 1-15 indicating which <em>listener</em> responded to the trial.</li>
<li><code>height</code>: A floating-point number representing the <em>height</em> (in centimeters) reported for the speaker on each trial.</li>
<li><code>S</code>: An integer from 1-139 indicating which <em>speaker</em> produced the trial stimulus.</li>
<li><code>A</code>: The <em>apparent age</em> of the speaker indicated by the listener, <code>a</code> (adult) or <code>c</code> (child).</li>
</ul>
<p>In this chapter we will build models that help us answer the following questions, among others:</p>
<p>(Q1) How tall do speakers perceived as adult females sound?</p>
<p>(Q2) How tall do speakers perceived as children sound?</p>
<p>(Q3) What is the difference in apparent height associated with the perception of adultness?</p>
<p>Figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-3">5.3</a> presents between-speaker and within-speaker variation in apparent height, according to apparent age. The answer to (Q1) above will depend on the distribution illustrated by the left boxplot of the left plot of the figure. The answer to (Q2) will depend on the distribution illustrated by the right boxplot of the left plot of the figure. The answer to (Q3) will depend on the difference between these distributions. Of course, we see that this is not the full story since there is substantial between-listener variation in the locations of these distributions, and in the differences between them, as illustrated by the pairs of boxes in the right plot. However, we will leave discussion of between-listener variation in effects for the next chapter.</p>
<div class="figure"><span style="display:block;" id="fig:F5-3"></span>
<img src="_main_files/figure-html/F5-3-1.jpeg" alt="(left) Distribution of apparent heights according to apparent age group, across all listeners. (right) Same as left plot but presented individually for each listener. In each case, the first box of each color (the higher box) represents responses for apparent adults." width="4800" />
<p class="caption">
Figure 5.3: (left) Distribution of apparent heights according to apparent age group, across all listeners. (right) Same as left plot but presented individually for each listener. In each case, the first box of each color (the higher box) represents responses for apparent adults.
</p>
</div>
</div>
<div id="c5-two-means" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Estimating the difference between two means with ‘brms’<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-two-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In Chapter 4 we fit a model with the simplest possible fixed-effect structure, basically an ‘intercept only’ random effects model. To estimate a difference between two group means, we need to include a ‘real’ predictor in our model, a variable indicating apparent age for each observation. Remember that formulas look like <code>y ~ predictor(s)</code>. Previously, our formula had no (fixed effect) predictors and so it looked like <code>height ~ 1 + (1|L) + (1|S)</code>, where the <code>1</code> indicates that this is an intercept-only model. To predict apparent height based on whether the talker was perceived as an adult or not, our model formula would now look like this:</p>
<p><code>height ~ 1 + A + (1|L) + (1|S)</code></p>
<p>This assumes that we have a column in our data frame (<code>A</code>) that indicates whether the listener thought a data point was produced by an adult or not. This model formula basically says “we expect height to vary around the intercept based on whether the speaker was judged to be an adult, in addition to listener and speaker-specific adjustments to the intercept’. When you have at least one non-intercept predictor in your model then you don’t need to include a <code>1</code> in your formula, since the intercept is included in the model by default. So, your model formula can look like:</p>
<p><code>height ~ A + (1|L) + (1|S)</code>.</p>
<p>Since the intercept is included by default, if you want to <em>suppress</em> (omit) an intercept from your model you need to specifically indicate this in your formula. You can do this by placing a <code>0</code> in front of your model formula like this <code>height ~ 0 + A + (1|L) + (1|S)</code>.</p>
<p>To fit our model comparing two groups, we need to specify prior probabilities for our age predictor. We should also rethink our priors since our data has changed substantially (from <em>only</em> men to <em>no</em> men). We can do this using the information provided in <code>height_data</code>, which tells us that adult females are about 162 cm tall on average, and 11 year old children are around 150 cm tall (our boys and girls were 10-12 years old). Based on this we can set the intercept to 156 cm, halfway between each average. We set the standard deviations for all priors to the difference between group means, 12 cm. This means that we expect that variation in the data, whether it be between groups (the <span class="math inline">\(A\)</span> predictor) or within-listener error (<code>sigma</code>, <span class="math inline">\(\sigma\)</span>), will be roughly on the order of the empirical group differences.</p>
<p>Usually, we would discuss the structure of this model now, <em>before</em> fitting. However, this time we’re going to put this off for a little bit because an explanation involves some of the less intuitive concepts relating to regression. So, this time we’re going to fit the model first and then get to the details of the model later in the chapter.</p>
<div id="fitting-the-model" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Fitting the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Our model now includes a non-intercept term, apparent age (<code>A</code>), and so we need to specify a prior for class <code>b</code> in addition to the priors we set in chapter 4. This is the class for all fixed-effect predictors (those fit without adaptive pooling) other than the intercept. Below we see a summary of the classes of predictors we have set priors for so far.</p>
<ul>
<li><code>Intercept</code>: this is a unique class, only for intercepts.</li>
<li><code>b</code>: This class includes all fixed-effect predictors <em>apart</em> from the intercept.</li>
<li><code>sd</code>: This is for standard deviation parameters related to ‘batches’ of parameters, e.g. <code>sd(Intercept)</code> for <code>L</code> (<span class="math inline">\(\sigma_{L}\)</span>).</li>
<li><code>sigma</code>: the error term.</li>
</ul>
<p>Below we fit the model, using the formula discussed above.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb129-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">brm</span> (</span>
<span id="cb129-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-3" aria-hidden="true" tabindex="-1"></a>  height <span class="sc">~</span> A <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data =</span> notmen, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb129-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">3500</span>, <span class="at">thin =</span> <span class="dv">2</span>,</span>
<span id="cb129-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(156, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb129-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-6" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb129-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-7" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb129-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb129-8" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb130-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb130-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;5_model.RDS&#39;</span>)</span></code></pre></div>
</div>
<div id="interpreting-the-model-1" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Interpreting the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#interpreting-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can inspect the model print statement, which is mostly familiar by now.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect model</span></span>
<span id="cb131-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-2" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">short_summary</span> (model)</span>
<span id="cb131-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Formula:  height ~ A + (1 | L) + (1 | S)</span></span>
<span id="cb131-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb131-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Group-Level Effects:</span></span>
<span id="cb131-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-6" aria-hidden="true" tabindex="-1"></a><span class="do">## ~L (Number of levels: 15)</span></span>
<span id="cb131-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-7" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb131-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-8" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     5.24      1.11     3.54     7.85</span></span>
<span id="cb131-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb131-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-10" aria-hidden="true" tabindex="-1"></a><span class="do">## ~S (Number of levels: 94)</span></span>
<span id="cb131-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-11" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb131-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-12" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     3.59      0.43      2.8     4.51</span></span>
<span id="cb131-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-13" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb131-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects:</span></span>
<span id="cb131-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-15" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb131-16"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-16" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept   163.92      1.46   160.97   166.72</span></span>
<span id="cb131-17"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-17" aria-hidden="true" tabindex="-1"></a><span class="do">## Ac          -17.37      0.74   -18.81   -15.89</span></span>
<span id="cb131-18"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-18" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb131-19"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Family Specific Parameters:</span></span>
<span id="cb131-20"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-20" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb131-21"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb131-21" aria-hidden="true" tabindex="-1"></a><span class="do">## sigma     8.58      0.17     8.25     8.92</span></span></code></pre></div>
<p>There’s a new predictor in the section on <code>Population-Level Effects</code> (i.e. the ‘fixed’ effects). In addition to the <code>Intercept</code> term, we now get estimates for a term called <code>Ac</code>. Admittedly, this is a strange name, but it’s how R handles predictors that are words (called <em>factors</em> in R). R names predictors like this <code>factornameFactorlevel</code>. For example, a factor called <code>colors</code> with levels <code>red</code>, <code>green</code> and <code>blue</code> would have the levels <code>colorsred</code>, <code>colorsgreen</code>, and <code>colorsblue</code>. So, the <code>Ac</code> name tells us this is the estimate for the <code>c</code> (child) level of the <code>A</code> (apparent age) factor. The <code>Ac</code> term in our model reflects something about the average apparent height of speakers identified as children. But what about this value does it reflect? Note that the ‘Intercept’ term in the model above corresponds to the mean apparent height for speakers perceived as adult females:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate mean apparent height based on apparent adultness</span></span>
<span id="cb132-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb132-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tapply</span> (notmen<span class="sc">$</span>height, notmen<span class="sc">$</span>A, mean)</span>
<span id="cb132-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="do">##     a     c </span></span>
<span id="cb132-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 165.5 145.4</span></span></code></pre></div>
<p>What does the value of <code>Ac</code> reflect about the apparent height of speakers identified as children? It tells us the difference between the group means, which is 20.1 cm when calculating simple group means, and 17.4 cm as estimated in the model. Well, our model coefficient is actually -17.4, but since it reflects a distance we can express it as an absolute value. Ideally, it seems like our model would have three <code>population level</code> predictors, the intercept, a predictor associated with the adult response mean (i.e. <code>Aa</code>), and a predictor associated with child response mean (<code>Ac</code>). To understand why this can’t happen, we need to talk about contrasts.</p>
</div>
</div>
<div id="c5-contrasts" class="section level2 hasAnchor" number="5.6">
<h2><span class="header-section-number">5.6</span> Contrasts<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-contrasts" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Factors are variables like ‘adult’ vs. ‘child’ that are not inherently numerical. <strong>Contrasts</strong> are the numerical implementation of factors in your model. The general problem is, in many cases, that coefficients for every level of a factor cannot all be estimated. For example, if you have two groups then you can’t <em>independently</em> calculate all of the following:</p>
<ol style="list-style-type: decimal">
<li>The group 1 mean.</li>
<li>The group 2 mean.</li>
<li>The grand mean (the Intercept).</li>
</ol>
<p>Why not? Because once you know any 2 of these quantities, you also know the 3rd. In section <a href="probabilities-likelihood-and-inference.html#c2-sample-mean">2.5.1</a> we mentioned that the sum of the differences between observations and the sample mean calculated from those observations will always equal zero. When we estimate the intercept based on the group 1 and group 2 means, the intercept is analogous to a sample mean, and each group average can be thought of as an ‘observation’. As a result, the deviations of the group means around the intercept (i.e. the effects) are constrained to sum to zero. Since the sum of the effect of group 1 and the effect of group 2 must equal zero, that means that the group 1 effect <em>must</em> equal the opposite of the group 2 effect. For example, if the group 1 mean is 5 and the overall mean is 6, the group 2 mean <em>must</em> be 7. This is because if the group 1 mean is 1 below the overall mean (an effect of -1), then the other group <em>must</em> be 1 above the mean (an effect of +1) in order to balance out.</p>
<p>The situation described above means that when we estimate the mean of the means (i.e. the intercept) based on two group means, one of the three values is always perfectly predictable based on the other two. When things are entirely predictable in this way we say they are <strong>linearly dependent</strong>, and regression models don’t like this (for more information on linear dependence, see section <a href="varying-variances-more-about-priors-and-prior-predictive-checks.html#c8-identifiability">8.8</a>). For example, imagine you were trying to predict a person’s weight from their height. You want to include height in centimeters <em>and</em> height in meters in your model, and you want to <em>independently</em> estimate effects for both predictors. Since height in centimeters = height in meters <span class="math inline">\(\times\)</span> 100, that is not going to be possible. The effect of one <em>must</em> be 100 times the effect of the other. Clearly, one value is not independent of another if it always exactly 100 times the other. This means that we can’t independently estimate these two values. Even though it may be less transparent, this is the same reason why we can’t estimate all the group means <em>and</em> the overall mean.</p>
<p>There are many different contrast coding schemes, and these reflect different ways of representing group differences, and decisions regarding which effects to estimate (and which to ignore). Here we will discuss two approaches: Treatment coding and sum coding.</p>
<div id="c5-treatment-coding" class="section level3 hasAnchor" number="5.6.1">
<h3><span class="header-section-number">5.6.1</span> Treatment coding<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-treatment-coding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The coding scheme you use determines how your model represents the differences it encodes. In the model above we used <strong>treatment coding</strong> (the default in R). In treatment coding, a ‘reference’ level is chosen to be the intercept, and all group effects reflect the difference between the mean for that group, and the value of the Intercept (i.e., the mean for the reference level). By default, R chooses the alphabetically-lowest level to be the reference level. In our model above, the <code>a</code> (adult) level was chosen as the reference level, and so the intercept represents the mean for this group. The effect for ‘child’ (<code>Ac</code>) represents the <em>difference</em> between the child mean and the adult mean. This means that our credible intervals also represent the difference in the means and not the means themselves. So, based on our treatment coded model we expect the <em>difference</em> in the apparent heights of adults and children to be about 17.4 cm, and we think there is a 95% chance that the <em>difference</em> between the means is between 15.9 and 18.8 cm in magnitude.</p>
<p>To interpret treatment coded coefficients in a regression model:</p>
<ul>
<li><p>The reference category mean is the ‘Intercept’ in the model.</p></li>
<li><p>The value of the coefficients of any non-intercept group are equal to <code>group mean - Intercept (reference group mean)</code>.</p></li>
<li><p>To recover the mean estimate for any non-intercept group, we add <code>group effect + Intercept (reference group mean)</code>.</p></li>
</ul>
<p>Notice that under treatment coding you estimate a group mean and the differences between the group means, but you do not estimate an overall <strong>grand mean</strong>. Although there is potentially some variation in terminology, we will use <em>grand mean</em>, to refer to the mean of the group means. Keep in mind that this may have a different value from the overall mean of all of the observations with no group structure included in the calculations.</p>
</div>
<div id="c5-sum-coding" class="section level3 hasAnchor" number="5.6.2">
<h3><span class="header-section-number">5.6.2</span> Sum coding<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-sum-coding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are multiple options for coding schemes, and the best one for you depends on what you want to get out of your model. Changing the coding scheme may substantially change the value of your coefficients and the way they should be interpreted. However, this will not change the fundamental relationships encoded in your model. Think of it this way, you can tell someone that the library is five miles west of your house or that your house is five miles east of the library. This sounds different because you are changing the reference point (the ‘intercept’), but it represents the same relationship. As a result, the selection of a coding scheme best suited for a model depends on which one results in the simplest interpretation of the model given the purpose of the research.</p>
<p>That being said, going forward we will focus exclusively on what is known as <strong>sum coding</strong>. The focus on a single coding scheme is meant to save space and minimize confusion. The reason for selecting sum coding specifically is because it has some desirable mathematical properties and it allows models to be interpreted in a style reminiscent of a traditional analysis of variance (to be discussed in chapter 11), which many researchers may find useful.</p>
<p>In sum coding, there is no reference level. Instead, the intercept represents the mean of the group means. The effect for each individual group is then represented as a deviation from the intercept, and all of these effects are constrained to sum to zero. Just like for treatment coding, you can’t estimate all of your group effects <em>and</em> the overall grand mean. Since we are estimating the grand mean, that means we will not be able to estimate <em>one</em> of our group effects. When using sum coding, R selects the <em>alphabetically last</em> level of your factor, and does not estimate it. The value of the missing effect is easy to recover algebraically. Since the sum of the coefficients must equal zero, the missing factor level will always be equal to the <em>negative sum</em> of the other factors. This means that if you add up the values of the levels that <em>are</em> present and flip the sign, the outcome is the value of your missing level. If you think about it, it must be this way. This is because the final missing value must cancel out the sum of the others if the sum of all the values is to equal zero.</p>
<p>As discussed earlier, with only two groups if you know the grand mean and the distance between one group to the grand mean, you also know the distance of the other group to the grand mean. This can be seen quite clearly below where the difference between each group to the overall mean has a magnitude of 10.07. So, if our sum-coded model tells us that the intercept is 155.4 cm and the adult mean is 10.1 cm above this, then the child mean <em>must</em> be 10.07 cm below it.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="co"># calculate group means</span></span>
<span id="cb133-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-2" aria-hidden="true" tabindex="-1"></a>means <span class="ot">=</span> <span class="fu">tapply</span> (notmen<span class="sc">$</span>height, notmen<span class="sc">$</span>A, mean)</span>
<span id="cb133-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span> (means)</span>
<span id="cb133-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 155.5</span></span>
<span id="cb133-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb133-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-6" aria-hidden="true" tabindex="-1"></a><span class="co"># find the distances to the mean of the means</span></span>
<span id="cb133-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-7" aria-hidden="true" tabindex="-1"></a>means <span class="sc">-</span> <span class="fu">mean</span> (means)</span>
<span id="cb133-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-8" aria-hidden="true" tabindex="-1"></a><span class="do">##      a      c </span></span>
<span id="cb133-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb133-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  10.07 -10.07</span></span></code></pre></div>
<p>To interpret sum coded coefficients in regression models:</p>
<ul>
<li><p>The mean of all your group means (the grand mean) is the ‘Intercept’ in the model.</p></li>
<li><p>The value of the coefficients of any other group mean will be equal to <code>group mean - Intercept (grand mean)</code>.</p></li>
<li><p>To recover the mean estimate for any other group, we add <code>group effect + Intercept (grand mean)</code>.</p></li>
</ul>
<p>Before continuing, we want to mention two things with respect to sum coding. First, in chapter 4 we noted that random effects are coded as deviations from the mean. Now we can be more specific and say that <code>brms</code> will use sum coding to specify all of your random effects (i.e. all terms estimated with adaptive pooling). Second, you may have noted that last chapter we did, in fact, estimate all of the levels of the listener random effects. We have 15 listeners in our data and we clearly saw 15 ‘random effects’ for listeners at several points in the chapter. The reason for this is that unlike for fixed effects, random effects are not constrained to sum to zero, and the value of the <span class="math inline">\(J^{th}\)</span> factor level is not necessarily predictable given knowledge of the value of the other <span class="math inline">\(J-1\)</span> levels. As a result, in many cases all levels of a random effect <em>can</em> be estimated.</p>
</div>
<div id="c5-comparison-sum-treatment" class="section level3 hasAnchor" number="5.6.3">
<h3><span class="header-section-number">5.6.3</span> Comparison of sum and treatment coding<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-comparison-sum-treatment" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-4">5.4</a> presents a comparison of the way the two coding schemes represent the group means in a two-group model. In each case they estimate one intercept and one effect, letting you recreate one other effect (i.e., they each omit one parameter). In treatment coding the omitted value is the overall mean, which in the two-group case will always be <code>Intercept + estimatedEffect/2</code>. In the case of sum coding the omitted value is the effect for the second group, which will always be the same magnitude but have the opposite sign as the effect for the first group (i.e., <code>-estimatedEffect</code> in a two-group model).</p>
<div class="figure"><span style="display:block;" id="fig:F5-4"></span>
<img src="../_main_files/figure-html/Figure 5.4.jpg" alt="Artist's rendition of contrast and treatment coding differences for our model." width="100%" />
<p class="caption">
Figure 5.4: Artist’s rendition of contrast and treatment coding differences for our model.
</p>
</div>
</div>
</div>
<div id="c5-refittin-sum" class="section level2 hasAnchor" number="5.7">
<h2><span class="header-section-number">5.7</span> Sum coding and the decomposition of variation<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-refittin-sum" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Regression models try to break up the value of the dependent variable into different components. This is why effects are expressed in terms of differences to some reference value. For example, imagine we say that a speaker’s apparent height is 160 cm, and under some other condition their apparent height is also 160 cm. If this were the case, we might be inclined to say that the change in these conditions has no <em>effect</em> on their apparent height. On the other hand something that <em>is</em> associated with a difference in apparent height <em>can</em> be said to have an effect on that variable. As a result, we can express the <em>effect</em> of something in terms of the difference it is associated with. For example, we can say that under so and so condition a person will tend to sound 17.5 cm shorter, relative to some reference value. More generally, we can think of any variable as the sum of a bunch of independent <em>effects</em>.</p>
<p>As discussed in section <a href="introduction-experiments-and-variables.html#c1-exp-and-effects">1.2</a>, the term <em>effect</em> is meant to indicate that variation in the independent variable is associated with variation in the dependent variable. This term is not meant to imply that any causal relationship exists, and certainly not that such a relationship is <em>proven</em> by the model.</p>
<p>For example, since age and height are so strongly related between the ages of 2 and 18 (see figure <a href="introduction-experiments-and-variables.html#fig:F1-1">1.1</a>), you can predict the veridical height of a person between the ages of 2 and 18 from their age with good accuracy. If you build a model that predicts the height of a child based on their age you might say that in your model “age has an effect on height”. A statement like this does not mean that age variation <em>causes</em> height variation in real life. Age (i.e. <em>time</em>) is a useful way to measure the progress of biological processes during childhood that themselves cause growth in body length, but age does not itself <em>cause</em> growth. Instead, a statement regarding the effect of one variable on another means that within the context of the universe you have constructed using your model, variation in body length is predictable (to some extent) based on variation in age.</p>
<p>The above is not to say that effects in your model will <em>never</em> reflect causal relationships, just that establishing this requires substantially more than simply finding statistical associations between variables. The decomposition of variables into a sum of effects, and the view of effects as representing predictable (maybe not causal) variation is just a way to <em>think</em> about variables, to break up observed values into their component parts. It should not be confused with the <em>reality</em> of these values and the process that underlies them (whatever that is!).</p>
<p>So far we’ve covered the fact that after picking a value to use as a reference point (the model intercept), our models:</p>
<ul>
<li><p>Represent group means as deviations from the intercept.</p></li>
<li><p>Represent the listener and speaker-specific deviations from the intercept (<span class="math inline">\(L_{[\bullet]}, S_{[\bullet]}\)</span>) as being centered at 0, with standard deviations of <span class="math inline">\(\sigma_{L}\)</span> and <span class="math inline">\(\sigma_{S}\)</span>.</p></li>
<li><p>Represent the random error (<span class="math inline">\(\varepsilon\)</span>) as having a mean of 0 and a standard deviation of <span class="math inline">\(\sigma\)</span>.</p></li>
</ul>
<p>In each case, these model coefficients reflect <em>deviations</em> from some reference point. As a result, when the parameters associated with these predictors equal 0, this means that no effect is present.</p>
<ul>
<li><p>When a group coefficient is 0 the group lies exactly at the intercept. In sum coding this is the grand mean (the mean of the means) indicating that the group is basically average.</p></li>
<li><p>When a listener or speaker-effect is 0 this listener/speaker is exactly average with respect to their group. This means there is nothing about this speaker’s average that is unpredictable given knowledge of their group.</p></li>
<li><p>When an error is 0 this production is exactly as expected for a given listener/speaker in a given group. This means that an observation contains no error since it was <em>exactly</em> predictable.</p></li>
</ul>
<p>If we think of our predictors as representing deviations from some reference value, we can ‘break up’ any observed value into its component parts. For example, suppose that:</p>
<ul>
<li>The overall mean is 157 cm.</li>
<li>The adult female mean is 165 cm (+8 over the intercept).</li>
<li>A particular speaker has a mean apparent height of 170 cm (+5 over the adult female mean).</li>
</ul>
<p>If we observe an apparent height judgment of 173 cm for this speaker, that suggests the following decomposition:</p>
<p>173 = 157 (Intercept) + 8 (adult female effect) + 5 (speaker effect) + 3 (error)</p>
<p>This reflects the following considerations:</p>
<ul>
<li>The average apparent height across the groups is 157 cm.</li>
<li>The average for adult females is 8 cm above the overall mean (157 + 8 = 165).</li>
<li>This speaker’s average apparent height is 5 cm above the average for adult females (157 + 8 + 5 = 170).</li>
<li>This particular production is 3 cm higher than expected for this particular speaker (157 + 8 + 5 + 3 = 173).</li>
</ul>
<p>Another observation from this same talker might be:</p>
<p>164 = 157 (Intercept) + 8 (adult female effect) + 5 (speaker effect) - 6 (error)</p>
<p>In this case, the error is -6 since the production is now 6 cm <em>below</em> the speaker average. However, no other part of the equation has changed since this is the same speaker in the same group. Regression models basically carry out these decompositions for us, and provide estimates of these components using their model parameters.</p>
<div id="c5-description-1" class="section level3 hasAnchor" number="5.7.1">
<h3><span class="header-section-number">5.7.1</span> Description of the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-description-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We’re going to re-fit our treatment coded model using sum coding, and see what effect this has on the estimated coefficients. The full model specification, including prior probabilities, is presented in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-1">(5.1)</a> below. Our model includes a new coefficient called <span class="math inline">\(A\)</span> reflecting the effect for apparent age, but is otherwise very similar to the model described in section <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-updating-model">4.8.1</a>.</p>
<p><span class="math display" id="eq:5-1">\[
\begin{equation}
\begin{split}
height_{[i]} \sim \mathrm{N}(\mu_{[i]},\sigma) \\
\mu_{[i]} = \mathrm{Intercept} + A  + L_{[\mathsf{L}_{[i]}]} + S_{[\mathsf{S}_{[i]}]} \\ \\
\mathrm{Priors:} \\
L_{[\bullet]} \sim \mathrm{N}(0,\sigma_L) \\
S_{[\bullet]} \sim \mathrm{N}(0,\sigma_S) \\
\\
\mathrm{Intercept} \sim \mathrm{N}(156,12) \\
A \sim \mathrm{N}(0,12) \\
\sigma \sim \mathrm{N}(0,12) \\
\sigma_L \sim \mathrm{N}(0,12) \\
\sigma_S \sim \mathrm{N}(0,12)
\end{split}
\tag{5.1}
\end{equation}
\]</span></p>
<p>We need to talk about why there is only a single <span class="math inline">\(A\)</span> coefficient despite there being two different age groups, and why this parameter does not get a subscript. Recall that regression models work by multiplying predictor variables with model parameters/coefficients, and adding these products together to arrive at an expected value (e.g. <span class="math inline">\(\mu = x_1 \cdot \alpha_2+x_2 \cdot \alpha_2+...\)</span>). This means that every parameter needs to be multiplied by some number in our prediction equation. When we introduced the intercept in section <a href="fitting-bayesian-regression-models-with-brms.html#c3-description-1">3.5.2</a>, we noted that the intercept is ‘secretly’ multiplied by a predictor equal to 1 for each observation. In order to meet this requirement, R adds a column of ones to your data to represent the intercept in your predictors.</p>
<p>In the case of factors with two levels (under sum coding), R adds a predictor to our data that equals 1 when <span class="math inline">\(A\)</span> equals its first value (adult) and -1 when it has its second value (child). In this way, the single <span class="math inline">\(A\)</span> coefficient can represent the effects for both groups, i.e. the distance between each group and the intercept. These ‘hidden’ predictors are how contrasts are handled mathematically. Coding schemes differ in the ways they use combinations of 1, -1, 0, and in some cases fractions, in order to mathematically represent the relations between groups. Here’s how you would read the model description in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-1">(5.1)</a> aloud in plain English:</p>
<blockquote>
<p>“Apparent speaker height is expected to vary according to a normal distribution with some unknown mean (<span class="math inline">\(\mu\)</span>) and standard deviation (<span class="math inline">\(\sigma\)</span>). Means are expected to vary based on whether the listener identified the speaker as an adult or a child (<span class="math inline">\(A\)</span>), and listener and speaker-dependent deviations from the mean (<span class="math inline">\(L, S\)</span>). The listener and speaker effects were modeled as coming from a normal distribution with means of 0 and unknown standard deviations (<span class="math inline">\(\sigma_L, \sigma_S\)</span>). The intercept was given a normal prior with a mean of 156 and a standard deviation of 12, and the remaining parameters were given normal priors centered at 0 with standard deviations of 12.”</p>
</blockquote>
</div>
<div id="fitting-the-model-1" class="section level3 hasAnchor" number="5.7.2">
<h3><span class="header-section-number">5.7.2</span> Fitting the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To fit a model with sum coding, we need to change the global contrast options in R. These options will be in effect until we restart R or change the contrasts to something else. If you fit a model with this coding, be sure to set this option every time you start R and want to work with this model. If there is a mismatch between your contrast settings and what the <code>brms</code> helper functions expect for your model, you may encounter problems and inscrutable error messages.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="co"># to change to sum coding</span></span>
<span id="cb134-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&#39;contr.sum&#39;</span>,<span class="st">&#39;contr.sum&#39;</span>))</span>
<span id="cb134-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb134-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co"># to change back to treatment coding</span></span>
<span id="cb134-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb134-5" aria-hidden="true" tabindex="-1"></a><span class="co"># options (contrasts = c(&#39;contr.treatment&#39;,&#39;contr.treatment&#39;))</span></span></code></pre></div>
<p>Since the options (and our coding) have changed, but nothing else has, we can fit our sum coded model with the same code we used above.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb135-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-2" aria-hidden="true" tabindex="-1"></a>model_sum_coding <span class="ot">=</span>  brms<span class="sc">::</span><span class="fu">brm</span> (</span>
<span id="cb135-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-3" aria-hidden="true" tabindex="-1"></a>  height <span class="sc">~</span> A <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data =</span> notmen, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">4</span>,</span>
<span id="cb135-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">3500</span>, <span class="at">thin =</span> <span class="dv">2</span>,</span>
<span id="cb135-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(156, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb135-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-6" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb135-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-7" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb135-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb135-8" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;normal(0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb136-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb136-2" aria-hidden="true" tabindex="-1"></a>model_sum_coding <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;5_model_sum_coding.RDS&#39;</span>)</span></code></pre></div>
<p>We’re going to use the <code>fixef</code> (i.e. ‘fixed effects’) function in <code>brms</code> to inspect only the <code>Population-Level Effects</code> in our model. The <code>Population-Level Effects</code> are also sometimes called <em>fixed</em> effects in part because they are ‘fixed’ across the population. For example, the effect for ‘child’ doesn’t apply only to little Susie or little Johnny in particular, but to speakers perceived as <em>children</em> more generally.</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb137-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect model fixed effects</span></span>
<span id="cb137-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb137-2" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (model_sum_coding)</span>
<span id="cb137-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb137-3" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error    Q2.5   Q97.5</span></span>
<span id="cb137-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb137-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  155.218    1.4050 152.434 157.965</span></span>
<span id="cb137-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb137-5" aria-hidden="true" tabindex="-1"></a><span class="do">## A1           8.711    0.3602   8.003   9.416</span></span></code></pre></div>
<p>An inspection of the fixed effects shows that, as expected, the <code>Intercept</code> now reflects the mean of the group means (i.e. the grand mean) and the single estimated parameter (<code>A1</code>) reflects the distance between the adult mean and the grand mean. The name of our <code>A1</code> parameter is based on how <code>brm</code> handles factors with sum coding. Predictors representing factors will be named <code>factornameN</code>, where <code>factorname</code> is the predictor name and <code>N</code> is the level number. Levels are ordered, and numbered, alphabetically starting at one, and the alphabetically-last level will not be estimated. You can predict how your factor levels will be ordered by doing something like this:</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span> (<span class="fu">unique</span> (notmen<span class="sc">$</span>A))</span>
<span id="cb138-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb138-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] &quot;a&quot; &quot;c&quot;</span></span></code></pre></div>
<p>So, <code>A1</code> in our model corresponds to the “adult” level of our predictor, and <code>A2</code> <em>would</em> be the coefficient reflecting the effect for “child”. However, this is not separately estimated by our sum-coded model since <code>A2 = -A1</code>.</p>
</div>
<div id="comparison-of-sum-and-treatment-coding" class="section level3 hasAnchor" number="5.7.3">
<h3><span class="header-section-number">5.7.3</span> Comparison of sum and treatment coding<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#comparison-of-sum-and-treatment-coding" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If you compare the output of the treatment and sum coding models:</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb139-1" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">short_summary</span> (model)</span>
<span id="cb139-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb139-2" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">short_summary</span> (model_sum_coding)</span></code></pre></div>
<p>The main differences are in the population-level effects, seen below:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="co"># treatment coding</span></span>
<span id="cb140-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-2" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (model)</span>
<span id="cb140-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-3" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error   Q2.5  Q97.5</span></span>
<span id="cb140-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-4" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept   163.92    1.4580 160.97 166.72</span></span>
<span id="cb140-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Ac          -17.37    0.7391 -18.81 -15.89</span></span>
<span id="cb140-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb140-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-7" aria-hidden="true" tabindex="-1"></a><span class="co"># sum coding</span></span>
<span id="cb140-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-8" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (model_sum_coding)</span>
<span id="cb140-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-9" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error    Q2.5   Q97.5</span></span>
<span id="cb140-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-10" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  155.218    1.4050 152.434 157.965</span></span>
<span id="cb140-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb140-11" aria-hidden="true" tabindex="-1"></a><span class="do">## A1           8.711    0.3602   8.003   9.416</span></span></code></pre></div>
<p>In the treatment-coded model, the intercept represents the adult mean and the <code>Ac</code> effect reflects the difference between the intercept and the child mean. In the sum-coded model the intercept is the overall grand mean and the <code>A1</code> effect represents the difference between the adult mean and the intercept. We can see that the information contained in the models is equivalent, just represented differently. First, we can divide the <code>Ac</code> effect by two to find half the distance between the groups, which we know must be the distance between the grand mean and the child group. This is the same magnitude as the <code>A1</code> effect in the sum-coded model (since it represents the same distance).</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fl">17.4</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb141-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb141-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 8.7</span></span></code></pre></div>
<p>If we subtract this value from the adult mean, we recover the intercept of the sum coded model.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb142-1" aria-hidden="true" tabindex="-1"></a><span class="fl">163.9</span> <span class="sc">-</span> (<span class="fl">17.4</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb142-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb142-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 155.2</span></span></code></pre></div>
<p>We can take the opposite approach and add the <code>A1</code> effect to the intercept of the sum-coded model. This allows us to recreate the intercept of the treatment-coded model.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fl">155.2</span> <span class="sc">+</span> <span class="fl">8.7</span></span>
<span id="cb143-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb143-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 163.9</span></span></code></pre></div>
<p>Just as half the <code>Ac</code> effect equaled the magnitude of the <code>A1</code> effect, we can take the opposite approach below. Since <code>A1</code> reflects the difference between groups and the grand mean, twice this value must equal the distance between the group means themselves.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb144-1" aria-hidden="true" tabindex="-1"></a><span class="fl">8.7</span><span class="sc">*</span><span class="dv">2</span></span>
<span id="cb144-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb144-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 17.4</span></span></code></pre></div>
</div>
</div>
<div id="c5-working-with-posteriors" class="section level2 hasAnchor" number="5.8">
<h2><span class="header-section-number">5.8</span> Inspecting and manipulating the posterior samples<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-working-with-posteriors" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the examples above, we added the posterior means of our model coefficients together. What we mean by this is that we took the <code>Estimate</code> in the model print statement, and used that to recreate our parameters (e.g., <code>156.7 + 8.77</code>). This approach is fine if we intend to quickly estimate simple combinations of our parameters as we did in the section above. However, this does not allow us to estimate the intervals around parameters in a reliable way. The main issue is that this approach does not adequately reflect the shared variation in the parameters we are combining, and this is a problem when estimating their credible intervals.</p>
<p>It’s important to remember that our models are actually a series of samples from the posterior distributions of our model parameters. Each of these posterior distributions reflects a different random variable, each with its own mean and variance. When one adds or subtracts two random variables, the variance of the outcome is defined as in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-1a">(5.2)</a>. The top line in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-1a">(5.2)</a> says: “The variance of the sum of the random variables <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> is equal to the sum of their individual variances (<span class="math inline">\(\sigma^2_x,\sigma^2_y\)</span>), plus two times the product of the correlation between the variables (<span class="math inline">\(\rho\)</span>), and their individual standard deviations (<span class="math inline">\(\sigma_x, \sigma_y\)</span>).</p>
<p><span class="math display" id="eq:5-1a">\[
\begin{equation}
\begin{split}
\sigma^2_{x + y} = \sigma^2_x + \sigma^2_y + 2 \rho \sigma_x \sigma_y \\
\sigma^2_{x - y} = \sigma^2_x - \sigma^2_y - 2 \rho \sigma_x \sigma_y
\end{split}
\tag{5.2}
\end{equation}
\]</span></p>
<p>We haven’t talked about <em>correlation</em> yet (we will in section <a href="variation-in-parameters-random-effects-and-model-comparison.html#c6-correlations">6.3.2</a>). Basically, the correlation is the strength of the relationship between variables, and it can greatly affect the outcome of the equations above. Consider a situation where <span class="math inline">\(x\)</span> is very positive when <span class="math inline">\(y\)</span> is very negative, and vice versa. We show this in the code below where we make <span class="math inline">\(y\)</span> equal the negative of <span class="math inline">\(x\)</span>, plus a small amount of random variation. In this example <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> exhibit a <em>negative</em> correlation, a negative association between the variables. If you were to plot these variables (<code>plot(x,y</code>) you would see a line sloping down left to right.</p>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb145-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span> (<span class="dv">1</span>)</span>
<span id="cb145-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb145-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">=</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span></span>
<span id="cb145-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb145-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="sc">-</span>x <span class="sc">+</span> <span class="fu">rnorm</span> (<span class="dv">10</span>)</span></code></pre></div>
<p>As seen in the code below, each of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> has a variance of about 9. However, since <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> tend to have opposite values, the sum of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> will be near zero, meaning the variance of this sum will be near zero. On the other hand, since they have opposite signs their <em>difference</em> will be large, meaning the variance of their difference may also be very large.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;marginal&#39; variance of x</span></span>
<span id="cb146-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span> (x)</span>
<span id="cb146-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 9.167</span></span>
<span id="cb146-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-5" aria-hidden="true" tabindex="-1"></a><span class="co"># &#39;marginal&#39; variance of y</span></span>
<span id="cb146-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-6" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span> (y)</span>
<span id="cb146-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-7" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 8.773</span></span>
<span id="cb146-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-9" aria-hidden="true" tabindex="-1"></a><span class="co"># variance of sum of x and y</span></span>
<span id="cb146-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-10" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span> (x<span class="sc">+</span>y)</span>
<span id="cb146-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-11" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 0.6093</span></span>
<span id="cb146-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-13" aria-hidden="true" tabindex="-1"></a><span class="co"># variance of difference of x and y</span></span>
<span id="cb146-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-14" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span> (x<span class="sc">-</span>y)</span>
<span id="cb146-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb146-15" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 35.27</span></span></code></pre></div>
<p>This example shows that the sum/difference of two variables may vary substantially based on the correlation between the variables. However, this will be unpredictable if one does not take the correlation into account. Why do we care about this? Well, clearly the credible intervals describing our posterior distributions reflect the variance of these distributions; wider intervals correspond to larger variances. So, as a practical matter the only way to ensure that we get the correct variance, and credible interval, for the combination of the intercept and the apparent age predictors (i.e., <span class="math inline">\(\sigma^2_{\mathrm{Intercept}+A}\)</span>) is to take the correlation of the predictors into account. When we summarize parameters, and then combine them, we lose all information about the correlations between the parameters, making an accurate estimation of <span class="math inline">\(\sigma^2_{\mathrm{Intercept}+A}\)</span> impossible.</p>
<p>On the other hand, if we add our parameters together, or find the differences between, them <em>before</em> summarizing, we don’t need to worry about the correlations between them. This is because this information is directly present in the posterior samples and is preserved when we work with these directly. In our simple example above, we didn’t actually calculate the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> to find the correct variance of their sum, we simply found the sum and then calculated the variance. This is why when combining parameters, you should <em>always</em> do so with the original samples, and <em>then</em> summarize the combined samples.</p>
<p>We can see the individual samples for our population-level (i.e. fixed effects) parameters by calling the <code>fixef</code> function and setting <code>summary</code> to <code>FALSE</code>. Below, we see the first 6 posterior samples for each parameter.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-1" aria-hidden="true" tabindex="-1"></a>samples <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">fixef</span> (model_sum_coding, <span class="at">summary =</span> <span class="cn">FALSE</span>)</span>
<span id="cb147-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb147-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span> (samples)</span>
<span id="cb147-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-4" aria-hidden="true" tabindex="-1"></a><span class="do">##     variable</span></span>
<span id="cb147-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-5" aria-hidden="true" tabindex="-1"></a><span class="do">## draw Intercept    A1</span></span>
<span id="cb147-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-6" aria-hidden="true" tabindex="-1"></a><span class="do">##    1     153.2 9.040</span></span>
<span id="cb147-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-7" aria-hidden="true" tabindex="-1"></a><span class="do">##    2     154.7 8.365</span></span>
<span id="cb147-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-8" aria-hidden="true" tabindex="-1"></a><span class="do">##    3     152.2 8.835</span></span>
<span id="cb147-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-9" aria-hidden="true" tabindex="-1"></a><span class="do">##    4     156.0 9.003</span></span>
<span id="cb147-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-10" aria-hidden="true" tabindex="-1"></a><span class="do">##    5     154.7 8.196</span></span>
<span id="cb147-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb147-11" aria-hidden="true" tabindex="-1"></a><span class="do">##    6     155.9 8.305</span></span></code></pre></div>
<p>If we find the mean of the samples across both columns, these exactly correspond to the estimates of these parameters provided by the <code>fixef</code> function above. In fact the <code>fixef</code> function is only doing some convenient summarizing of the samples for us, and presents this to us in a nice, interpretable way.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span> (samples)</span>
<span id="cb148-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept        A1 </span></span>
<span id="cb148-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb148-3" aria-hidden="true" tabindex="-1"></a><span class="do">##   155.218     8.711</span></span></code></pre></div>
<p>When we fit the models above, we made certain choices regarding what information was directly represented in the model, and what was not. In other words, we made a decision regarding how to <strong>parameterize</strong> our model, including the selection of a coding scheme. However, the information that is not directly represented in the model can still often be recovered by combining parameter estimates in appropriate ways. For example, we know that our adult mean is equal to the sum of the intercept and the <code>A1</code> parameter. If we want to know what the value of <code>Intercept+A1</code> is according to our model, all we need to do is add the values of <code>A1</code> and <code>Intercept</code>, individually for each sample, and then consider the distribution of the sum. This means we add the elements of each row together, resulting in a single vector as long as the two vectors being summed. Combining the intercept and <code>A1</code> parameters in our model is as easy as seen below, we simply add the two vectors together:</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb149-1" aria-hidden="true" tabindex="-1"></a>adult_mean <span class="ot">=</span> samples[,<span class="st">&quot;Intercept&quot;</span>] <span class="sc">+</span> samples[,<span class="st">&quot;A1&quot;</span>]</span></code></pre></div>
<p>In figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-5">5.5</a> we plot histograms and the individual posterior samples for the <code>Intercept</code> (the overall mean) and the <code>A1</code> parameter (the effect for adults). We also show how the intercept and the <code>A1</code> parameter can be combined to find the posterior estimates of our child and adult means.</p>
<div class="figure"><span style="display:block;" id="fig:F5-5"></span>
<img src="_main_files/figure-html/F5-5-1.jpeg" alt="Comparison of histograms (top row) and trace plots (bottom row) of the posterior samples of selected parameters, and their combinations." width="4800" />
<p class="caption">
Figure 5.5: Comparison of histograms (top row) and trace plots (bottom row) of the posterior samples of selected parameters, and their combinations.
</p>
</div>
<p>We can summarize our combinations of parameters using the <code>posterior_summary</code> function from the <code>brms</code> package. This function takes in a matrix or vector and calculates the mean, standard deviation, and 95% credible interval (by default) for each column in the data. Below, we use this strategy to get information about posterior means and credible intervals for our adult and child means. Whereas the credible interval for the <code>A1</code> effect reflected uncertainty in the <em>difference</em> between the adult female mean and the Intercept, the values below provide information about the adult and child group means directly.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-1" aria-hidden="true" tabindex="-1"></a>new_parameters <span class="ot">=</span> <span class="fu">cbind</span>(<span class="at">adult_mean =</span> samples[,<span class="st">&#39;Intercept&#39;</span>] <span class="sc">+</span> samples[,<span class="st">&#39;A1&#39;</span>],</span>
<span id="cb150-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">child_mean =</span> samples[,<span class="st">&#39;Intercept&#39;</span>] <span class="sc">-</span> samples[,<span class="st">&#39;A1&#39;</span>])</span>
<span id="cb150-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb150-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-4" aria-hidden="true" tabindex="-1"></a><span class="co"># report mean and spread of samples</span></span>
<span id="cb150-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-5" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">posterior_summary</span> (new_parameters)</span>
<span id="cb150-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-6" aria-hidden="true" tabindex="-1"></a><span class="do">##            Estimate Est.Error  Q2.5 Q97.5</span></span>
<span id="cb150-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-7" aria-hidden="true" tabindex="-1"></a><span class="do">## adult_mean    163.9     1.465 161.1 166.8</span></span>
<span id="cb150-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb150-8" aria-hidden="true" tabindex="-1"></a><span class="do">## child_mean    146.5     1.435 143.7 149.3</span></span></code></pre></div>
<p>We can also compare the intervals above to those of our intercept and effect for apparent age:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb151-1" aria-hidden="true" tabindex="-1"></a>brms<span class="sc">::</span><span class="fu">fixef</span> (model_sum_coding)</span>
<span id="cb151-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb151-2" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error    Q2.5   Q97.5</span></span>
<span id="cb151-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb151-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  155.218    1.4050 152.434 157.965</span></span>
<span id="cb151-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb151-4" aria-hidden="true" tabindex="-1"></a><span class="do">## A1           8.711    0.3602   8.003   9.416</span></span></code></pre></div>
<p>We see that the 95% credible interval for our intercept spans about 5.5 cm and our 95% credible interval for the apparent age effect (<code>A1</code>) spans about 1.4 cm. However, the 95% credible intervals for the adult and child means span only about 5.7 cm each, indicating that <span class="math inline">\(\sigma^2_{\mathrm{Intercept}+A} &lt; \; \sigma^2_{\mathrm{Intercept}} + \sigma^2_{A}\)</span>. In other words, the variance of the sum of the intercept and the apparent age effect is smaller than the sum of their individual variances. We know that this likely reflects a negative correlation between the posterior samples of the intercept and <code>A1</code> parameter, however, this is not so obvious if we only look at the summaries immediately above.</p>
<div id="c5-using-hypothesis" class="section level3 hasAnchor" number="5.8.1">
<h3><span class="header-section-number">5.8.1</span> Using the <em>hypothesis</em> function<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-using-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Working directly with the posterior samples is simple, but often not strictly necessary. The <code>brms</code> package contains a very useful function called <code>hypothesis</code> that helps us combine and manipulate parameters very easily without having to do any of the steps outlined in the previous section. The <code>hypothesis</code> function provides a lot of extra information and formatting which may be useful in ‘real life’ but is cumbersome for this book. As a result, we will be relying on the <code>short_hypothesis</code> function provided in the book R package (<code>bmmb</code>). This function is simply a wrapper for the <code>hypothesis</code> function that provides a more compact output while still maintaining most of the information we need. To be clear, any functionality we credit to <code>short_hypothesis</code> is actually a property of <code>hypothesis</code> and all the credit goes to the <code>brms</code> package.</p>
<p>You can ask <code>short_hypothesis</code> to add terms in your model (spelled just as they are in the print statement), and to compare the result to some number. If you compare the result to 0, it just tells you about the result of the terms you added. However, you can compare your parameters to any value, or to each other. For example, the line below says “test my hypothesis that the Intercept plus the A1 parameter is equal to zero”. This is a slightly convoluted way of saying “tell me what the value of the adult mean is so I can see if it is different from zero”. We want to be clear, however, that we’re not suggesting that <code>short_hypothesis</code> is used to test binary true/false hypotheses with respect to the ‘real’ value of the parameter in question. Instead, we are simply using the <code>short_hypothesis</code> function as an easy way to calculate combinations of parameter values.</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb152-1" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">short_hypothesis</span>(model_sum_coding, <span class="st">&quot;Intercept + A1 = 0&quot;</span>)</span>
<span id="cb152-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb152-2" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error  Q2.5 Q97.5         hypothesis</span></span>
<span id="cb152-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb152-3" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    163.9     1.465 161.1 166.8 (Intercept+A1) = 0</span></span></code></pre></div>
<p>You will notice that the mean, error and credible intervals <em>exactly</em> correspond to the values obtained by calculating our <code>new_parameters</code> above. We can also check several parameter combinations simultaneously. Below we use the information provided in section <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-contrasts">5.6</a> to recreate all our mean estimates of interest, first for the sum coding model:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="fu">short_hypothesis</span>(model_sum_coding, </span>
<span id="cb153-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-2" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">c</span>(<span class="st">&quot;Intercept = 0&quot;</span>,        <span class="co"># overall mean</span></span>
<span id="cb153-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;Intercept + A1 = 0&quot;</span>,   <span class="co"># adult mean</span></span>
<span id="cb153-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;Intercept - A1 = 0&quot;</span>))  <span class="co"># child mean</span></span>
<span id="cb153-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-5" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error  Q2.5 Q97.5         hypothesis</span></span>
<span id="cb153-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-6" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    155.2     1.405 152.4 158.0    (Intercept) = 0</span></span>
<span id="cb153-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-7" aria-hidden="true" tabindex="-1"></a><span class="do">## H2    163.9     1.465 161.1 166.8 (Intercept+A1) = 0</span></span>
<span id="cb153-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb153-8" aria-hidden="true" tabindex="-1"></a><span class="do">## H3    146.5     1.435 143.7 149.3 (Intercept-A1) = 0</span></span></code></pre></div>
<p>And then for the treatment coding model:</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">short_hypothesis</span>(model, </span>
<span id="cb154-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-2" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">c</span>(<span class="st">&quot;Intercept + Ac/2 = 0&quot;</span>,   <span class="co"># overall mean</span></span>
<span id="cb154-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-3" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;Intercept = 0&quot;</span>,          <span class="co"># adult mean</span></span>
<span id="cb154-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-4" aria-hidden="true" tabindex="-1"></a>                   <span class="st">&quot;Intercept + Ac = 0&quot;</span>))    <span class="co"># child mean</span></span>
<span id="cb154-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-5" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error  Q2.5 Q97.5           hypothesis</span></span>
<span id="cb154-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-6" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    155.2     1.399 152.4 157.9 (Intercept+Ac/2) = 0</span></span>
<span id="cb154-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-7" aria-hidden="true" tabindex="-1"></a><span class="do">## H2    163.9     1.458 161.0 166.7      (Intercept) = 0</span></span>
<span id="cb154-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb154-8" aria-hidden="true" tabindex="-1"></a><span class="do">## H3    146.5     1.436 143.7 149.4   (Intercept+Ac) = 0</span></span></code></pre></div>
<p>As noted earlier, these models clearly contain the same information, just represented in different ways.</p>
</div>
<div id="c5-manipulating-random-effects" class="section level3 hasAnchor" number="5.8.2">
<h3><span class="header-section-number">5.8.2</span> Working with the random effects<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-manipulating-random-effects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Both ways of adding fixed effects presented above will also work for combining and manipulating our random effects. For example, we can get our listener random intercept using the <code>ranef</code> function (as discussed in section <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-inspecting-random-effects">4.6.1</a>) using the code below:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-1" aria-hidden="true" tabindex="-1"></a>listener_effects_hat <span class="ot">=</span> </span>
<span id="cb155-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>(model_sum_coding, <span class="at">summary =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>L[,,<span class="st">&quot;Intercept&quot;</span>]</span>
<span id="cb155-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb155-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (listener_effects_hat)</span>
<span id="cb155-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-5" aria-hidden="true" tabindex="-1"></a><span class="do">##  num [1:5000, 1:15] 13.17 9.58 12.68 9.24 9.55 ...</span></span>
<span id="cb155-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-6" aria-hidden="true" tabindex="-1"></a><span class="do">##  - attr(*, &quot;dimnames&quot;)=List of 2</span></span>
<span id="cb155-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-7" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : NULL</span></span>
<span id="cb155-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb155-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   ..$ : chr [1:15] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</span></span></code></pre></div>
<p>The <code>_hat</code> suffix represents the ‘hat’ (<span class="math inline">\(\hat{x}\)</span>) diacritic (i.e. little symbol) in mathematical notation, which goes above variables to indicate that they represent modeled quantities rather than (unknown) population quantities. We can get the intercept from the model using the <code>fixef</code> function and asking for the column called “Intercept” from the output.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-1" aria-hidden="true" tabindex="-1"></a>Intercept_hat <span class="ot">=</span> </span>
<span id="cb156-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fixef</span>(model_sum_coding, <span class="at">summary =</span> <span class="cn">FALSE</span>)[,<span class="st">&quot;Intercept&quot;</span>]</span>
<span id="cb156-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb156-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-4" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span> (Intercept_hat)</span>
<span id="cb156-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-5" aria-hidden="true" tabindex="-1"></a><span class="do">##  Named num [1:5000] 153 155 152 156 155 ...</span></span>
<span id="cb156-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb156-6" aria-hidden="true" tabindex="-1"></a><span class="do">##  - attr(*, &quot;names&quot;)= chr [1:5000] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ...</span></span></code></pre></div>
<p>We can combine the above samples and summarize these to get the conditional means and the listener effects, according to our model.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="co"># add the intercept and listener random effects, and summarize</span></span>
<span id="cb157-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-2" aria-hidden="true" tabindex="-1"></a>listener_means_hat <span class="ot">=</span> </span>
<span id="cb157-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-3" aria-hidden="true" tabindex="-1"></a>  brms<span class="sc">::</span><span class="fu">posterior_summary</span> (Intercept_hat <span class="sc">+</span> listener_effects_hat)</span>
<span id="cb157-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb157-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-5" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize listener effects</span></span>
<span id="cb157-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb157-6" aria-hidden="true" tabindex="-1"></a>listener_effects_hat <span class="ot">=</span> brms<span class="sc">::</span><span class="fu">posterior_summary</span> (listener_effects_hat)</span></code></pre></div>
<p>We can calculate analogous values directly from the data, as seen below. First we find the average for each listener across each adult and child groups, and then we find the average of that. The reason for this is to control for the fact that adult and child responses may not be balanced within listeners, and we want the listener average to be half-way between the adult and child <em>category means</em> rather than simply reflecting the distribution of responses overall. For example if a listener identified 90% of speakers as adults, their overall mean would obviously be closer to their adult responses than their child responses.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="co"># find average apparent height for each listener and apparent age</span></span>
<span id="cb158-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb158-2" aria-hidden="true" tabindex="-1"></a>listener_means <span class="ot">=</span> <span class="fu">tapply</span> (notmen<span class="sc">$</span>height, notmen[,<span class="fu">c</span>(<span class="st">&#39;A&#39;</span>,<span class="st">&#39;L&#39;</span>)], mean)</span>
<span id="cb158-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb158-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb158-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb158-4" aria-hidden="true" tabindex="-1"></a><span class="co"># find average apparent height for each listener </span></span>
<span id="cb158-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb158-5" aria-hidden="true" tabindex="-1"></a>listener_means <span class="ot">=</span> <span class="fu">colMeans</span> (listener_means)</span></code></pre></div>
<p>After finding the listener means we calculate the mean of the means (the <code>Intercept</code>), and subtract this from the listener means to get the listener effects (i.e., the listener dependent deviations from the intercept).</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb159-1" aria-hidden="true" tabindex="-1"></a>Intercept <span class="ot">=</span> <span class="fu">mean</span> (listener_means)</span>
<span id="cb159-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb159-2" aria-hidden="true" tabindex="-1"></a>listener_effects <span class="ot">=</span> listener_means <span class="sc">-</span> Intercept</span></code></pre></div>
<p>The above values represent the no pooling estimates of the listener means and effects, since these values were each estimated entirely independently for each listener. In figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-6">5.6</a> we plot the listener effects and means estimated using adaptive pooling with <code>brms</code> (<code>listener_effects_hat</code>, <code>listener_means_hat</code>) and compare these to the equivalent values we calculated directly from the data (<code>listener_effects</code>, <code>listener_means</code>). Clearly, these are a good match. A benefit of using the modeled parameters is that these come with credible intervals, so that we can make statements about likely bounds for values in addition to providing point estimates.</p>
<div class="figure"><span style="display:block;" id="fig:F5-6"></span>
<img src="_main_files/figure-html/F5-6-1.jpeg" alt="(left) Estimated listener means and 95% credible intervals. Crosses indicate no pooling estimates. (right) Estimated listener effects and 95% credible intervals. Crosses indicate centered no pooling estimates." width="4800" />
<p class="caption">
Figure 5.6: (left) Estimated listener means and 95% credible intervals. Crosses indicate no pooling estimates. (right) Estimated listener effects and 95% credible intervals. Crosses indicate centered no pooling estimates.
</p>
</div>
<p>Random effects can be investigated using the <code>hypothesis</code> (or <code>short_hypothesis</code>) function by setting appropriate values for the <code>scope</code> and <code>group</code> parameters. For example, below we repeat the code to test the hypothesis that the overall, fixed-effect intercept is equal to zero.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">short_hypothesis</span>(model_sum_coding, <span class="st">&quot;Intercept = 0&quot;</span>)</span>
<span id="cb160-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error  Q2.5 Q97.5      hypothesis</span></span>
<span id="cb160-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb160-3" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    155.2     1.405 152.4   158 (Intercept) = 0</span></span></code></pre></div>
<p>However, if we set <code>scope=ranef</code> we tell the function to check for intercepts in the random effects, rather than our <code>population level</code> intercept. In addition, by setting <code>group=L</code> we tell the function to check for the random intercepts of the <code>L</code> factor specifically. Below we compare this output:</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">short_hypothesis</span>(model_sum_coding, <span class="st">&quot;Intercept = 0&quot;</span>,</span>
<span id="cb161-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">scope =</span> <span class="st">&quot;ranef&quot;</span>,<span class="at">group=</span><span class="st">&quot;L&quot;</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb161-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-3" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error    Q2.5  Q97.5      hypothesis group</span></span>
<span id="cb161-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-4" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    9.690     1.585   6.603 12.832 (Intercept) = 0     1</span></span>
<span id="cb161-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-5" aria-hidden="true" tabindex="-1"></a><span class="do">## H2   -1.792     1.597  -4.941  1.297 (Intercept) = 0     2</span></span>
<span id="cb161-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-6" aria-hidden="true" tabindex="-1"></a><span class="do">## H3   -7.376     1.602 -10.636 -4.255 (Intercept) = 0     3</span></span>
<span id="cb161-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-7" aria-hidden="true" tabindex="-1"></a><span class="do">## H4    5.121     1.566   2.104  8.283 (Intercept) = 0     4</span></span>
<span id="cb161-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb161-8" aria-hidden="true" tabindex="-1"></a><span class="do">## H5   -4.393     1.570  -7.598 -1.383 (Intercept) = 0     5</span></span></code></pre></div>
<p>With those calculated ‘manually’ above, and see that they are the same.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-1" aria-hidden="true" tabindex="-1"></a>listener_effects_hat[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb162-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   Estimate Est.Error    Q2.5  Q97.5</span></span>
<span id="cb162-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1    9.690     1.585   6.603 12.832</span></span>
<span id="cb162-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2   -1.792     1.597  -4.941  1.297</span></span>
<span id="cb162-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3   -7.376     1.602 -10.636 -4.255</span></span>
<span id="cb162-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4    5.121     1.566   2.104  8.283</span></span>
<span id="cb162-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb162-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5   -4.393     1.570  -7.598 -1.383</span></span></code></pre></div>
<p>Setting <code>scope=ranef</code> returns the random effects themselves. By changing the <code>scope</code> parameter to <code>coef</code> rather than <code>ranef</code>, we tell <code>hypothesis</code> to consider the value of the intercept coefficient (i.e., Intercept + random effect) rather than the random effect itself. Since <code>group=L</code>, this is done for the grouping factor <code>L</code> (i.e. across listeners). Below, we see that this approach:</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="fu">short_hypothesis</span>(model_sum_coding, <span class="st">&quot;Intercept = 0&quot;</span>,</span>
<span id="cb163-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-2" aria-hidden="true" tabindex="-1"></a>                 <span class="at">scope =</span> <span class="st">&quot;coef&quot;</span>,<span class="at">group=</span><span class="st">&quot;L&quot;</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb163-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-3" aria-hidden="true" tabindex="-1"></a><span class="do">##    Estimate Est.Error  Q2.5 Q97.5      hypothesis group</span></span>
<span id="cb163-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-4" aria-hidden="true" tabindex="-1"></a><span class="do">## H1    164.9    0.9516 163.1 166.8 (Intercept) = 0     1</span></span>
<span id="cb163-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-5" aria-hidden="true" tabindex="-1"></a><span class="do">## H2    153.4    0.9438 151.6 155.3 (Intercept) = 0     2</span></span>
<span id="cb163-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-6" aria-hidden="true" tabindex="-1"></a><span class="do">## H3    147.8    0.9585 146.0 149.8 (Intercept) = 0     3</span></span>
<span id="cb163-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-7" aria-hidden="true" tabindex="-1"></a><span class="do">## H4    160.3    0.9556 158.5 162.2 (Intercept) = 0     4</span></span>
<span id="cb163-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb163-8" aria-hidden="true" tabindex="-1"></a><span class="do">## H5    150.8    0.9475 149.0 152.7 (Intercept) = 0     5</span></span></code></pre></div>
<p>Also yields identical results to obtaining the individual samples, and adding and summarizing those (as we did above).</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-1" aria-hidden="true" tabindex="-1"></a>listener_means_hat[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,]</span>
<span id="cb164-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="do">##   Estimate Est.Error  Q2.5 Q97.5</span></span>
<span id="cb164-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-3" aria-hidden="true" tabindex="-1"></a><span class="do">## 1    164.9    0.9516 163.1 166.8</span></span>
<span id="cb164-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 2    153.4    0.9438 151.6 155.3</span></span>
<span id="cb164-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-5" aria-hidden="true" tabindex="-1"></a><span class="do">## 3    147.8    0.9585 146.0 149.8</span></span>
<span id="cb164-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-6" aria-hidden="true" tabindex="-1"></a><span class="do">## 4    160.3    0.9556 158.5 162.2</span></span>
<span id="cb164-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb164-7" aria-hidden="true" tabindex="-1"></a><span class="do">## 5    150.8    0.9475 149.0 152.7</span></span></code></pre></div>
<p>Finally, in section <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-working-with-posteriors">5.8</a> we combined fixed-effect parameters, adding and subtracting these to answer specific questions. In our Bayesian models, we can do this same thing using our random effects, and in fact we just did so to recover our listener means above. However, we can also do this to compare levels of our random effects among themselves. For example, in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-6">5.6</a> we see that listeners two and three appear to have reported different average apparent heights. Is this conclusion supported by our model? To answer this question we can subtract the samples corresponding to the two parameters, and then summarize the distribution of the difference, as seen below.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get listener effects</span></span>
<span id="cb165-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-2" aria-hidden="true" tabindex="-1"></a>listener_effects_hat <span class="ot">=</span> </span>
<span id="cb165-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranef</span>(model_sum_coding, <span class="at">summary =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>L[,,<span class="st">&quot;Intercept&quot;</span>]</span>
<span id="cb165-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-5" aria-hidden="true" tabindex="-1"></a><span class="co"># find the difference between the second and third listener effect</span></span>
<span id="cb165-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-6" aria-hidden="true" tabindex="-1"></a>difference_2_3 <span class="ot">=</span> listener_effects_hat[,<span class="dv">2</span>] <span class="sc">-</span> listener_effects_hat[,<span class="dv">3</span>]</span>
<span id="cb165-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb165-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-8" aria-hidden="true" tabindex="-1"></a><span class="co"># summarize the difference</span></span>
<span id="cb165-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-9" aria-hidden="true" tabindex="-1"></a><span class="fu">posterior_summary</span> (difference_2_3)</span>
<span id="cb165-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-10" aria-hidden="true" tabindex="-1"></a><span class="do">##      Estimate Est.Error  Q2.5 Q97.5</span></span>
<span id="cb165-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb165-11" aria-hidden="true" tabindex="-1"></a><span class="do">## [1,]    5.585     1.234 3.188  7.95</span></span></code></pre></div>
<p>We see that the average difference is 5.6 cm and the 95% credible interval is between 3.2 and 8.0 cm. Based on this, it seems likely that listener 2 <em>really does</em> rate speakers as taller overall relative to listener 3. A minimum difference of 3.2 cm may seem odd if we look at the intervals of the effects for listeners two and three in the right plot in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-6">5.6</a>, which seem to overlap. The mismatch is related to the difference between summarizing and then comparing and comparing and then summarizing.</p>
<p>Imagine listeners 2 and 3 have average apparent height judgments of 162 and 164 cm, and that the intercept is 156 cm. If for some sample the intercept is 157, then the listener effects for that sample would need to be +5 (157+5=162) and +7 (157+7=164). If, for the next sample the intercept were 153, now the listener effects would need to be +9 (153+9=162) and +11 (153+11=164). In this way, model parameters (including random effects) can rise and fall together across posterior samples. This ‘rising and falling together’ can result in a <em>correlation</em> between parameters which, as noted above, can affect the credible intervals around combinations of parameters.</p>
<p>Note that in our example above, the range for the first listener spanned from +5 to +9 across samples, and the second range spanned from +7 to +11. This gives the impression that these parameters overlap, but we know that this is somewhat artificial. The listeners in our hypothetical example above had varying effect estimates across samples, however, the difference between the parameters was 2 <em>within</em> each sample. In the right plot of figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-6">5.6</a>, we are showing the marginal distributions of the listener effects. This provides information about the individual credible range of these parameters but makes it difficult to consider the distribution of the <em>differences</em> between pairs of parameters. In this case it obscures the fact that the effects for listeners 2 and 3 are more dissimilar than they appear.</p>
<p>Instead, we can consider the distribution of the differences in listener effects directly as we did in <code>difference_2_3</code> above. This gives us information about the difference between these parameters and correctly calculates the credible interval around this difference, however, information about the ranges of the individual parameters is obviously lost. So, we effectively represent different information when we plot (or summarize) marginal parameter distributions as opposed to combinations (including differences) of these. If we are interested primarily in highlighting the difference between parameters, focusing on the marginal distribution of each parameter may paint a misleading picture for the reader.</p>
</div>
</div>
<div id="c5-robustness" class="section level2 hasAnchor" number="5.9">
<h2><span class="header-section-number">5.9</span> Making our models more robust: The (non-standardized) t distribution<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-robustness" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>By almost any objective measure, a Ferrari is a ‘good’ car. A Ferrari will be fast, beautiful, and precisely made. And yet a Ferrari will not do well on a bumpy dirt road or even over speed bumps. You could say that the design of the Ferrari assumes that it will be used on flat, clean(ish) roads. Someone who damaged their Ferrari driving fast on a bumpy dirt road would be foolish to blame the car, they used it ‘incorrectly’ by violating the assumptions implicit in the design of a Ferrari. You don’t buy a Ferrari to drive it down dirt roads, because that’s not what it was designed for.</p>
<p>However, not everything breaks just because you use it for something it wasn’t designed for. One way to think of this is that a Ferrari is not very <em>robust</em>, it only works well if you stick to its design assumptions. A more robust car, like a reasonably-priced mid-sized sedan, may not be as ‘good’ a car as the Ferrari, however, it can be used successfully in a very wide range of circumstances. Similarly, a statistical model is <strong>robust</strong> when it provides useful, reliable results in a wide range of situations. If we think of robustness as a continuous (rather than discrete) property, more-robust statistical models are more reliable in a wider range of situations than less-robust statistical models. Since all statistical models rely on certain assumptions implicit in their structure, more robust statistical models are those which are either more tolerant to violations of their assumptions, or those that make assumptions that are violated in a smaller number of cases.</p>
<p>One of the simplest ways for us to increase the robustness of our models is to think about their <strong>distributional robustness</strong>, that is robustness related to the distributional assumptions made by the model. For example, using <strong>t distributions</strong> in place of normal distributions can lead to more robust models in many situations. This is because the t distribution is substantially more tolerant to outliers than the normal distribution, and thus can be substantially more robust in the presence of outliers.</p>
<p>Rather than focusing on the mathematical properties of priors in the abstract, it’s more useful to focus on whether or not the <em>shapes</em> of their densities reflect the distributions of interest. This is because, ultimately, any distribution you choose is at best an approximation and will not exactly correspond to the <em>true</em> underlying distribution (which we can never know anyway), and the characteristics of the shape of the distribution can have a <em>direct</em> and practical effect on your outcomes.</p>
<p>The shape of the <strong>t distribution</strong> is broadly similar to the standard normal distribution. It is symmetrical about its mean and has a similar ‘bell’ shape to it. However, the t distribution has a <em>degrees of freedom</em> parameter (<span class="math inline">\(\nu\)</span>, nu pronounced “noo”) that affects the shape of the distribution. Lower values of <span class="math inline">\(\nu\)</span> result in ‘pointier’ distributions that also have more mass in the ‘tails’, far away from the mean of the distribution. We can see the effect of <span class="math inline">\(\nu\)</span> on the shape of the t distribution in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-7">5.7</a>. When <span class="math inline">\(\nu=\infty\)</span>, the t distribution converges on the normal distribution. As <span class="math inline">\(\nu\)</span> decreases in value, the t distribution becomes less like the normal distribution and more distinctively ‘t like’.</p>
<div class="figure"><span style="display:block;" id="fig:F5-7"></span>
<img src="_main_files/figure-html/F5-7-1.jpeg" alt="(left) A comparison of the density of a standard normal distribution (red curve) with the densities of t distributions with different degrees of freedom. (middle) The log-densities of the distributions in the left plot. (right) The same as the middle plot, except across a wider domain." width="4800" />
<p class="caption">
Figure 5.7: (left) A comparison of the density of a standard normal distribution (red curve) with the densities of t distributions with different degrees of freedom. (middle) The log-densities of the distributions in the left plot. (right) The same as the middle plot, except across a wider domain.
</p>
</div>
<p>In the middle plot of figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-7">5.7</a> we see that, apart from when <span class="math inline">\(\nu=1\)</span>, the shape of the distributions are all pretty similar within about two standard deviations of the mean. Since we expect the large majority of our observations to fall inside this area, this means that <span class="math inline">\(\nu\)</span> is not expected to have a large effect on inference in many cases where data falls within ‘typical’ ranges (when <span class="math inline">\(\nu&gt;1\)</span>). In contrast, in the right plot we see that the differences can be quite large in the ‘tails’ of the distributions, the areas outside of three standard deviations or so.</p>
<p>The most common implementation of the t distribution has only one parameter, <span class="math inline">\(\nu\)</span>. This <em>standardized</em> t distribution always has a mean equal to zero and a variance equal to exactly <span class="math inline">\(\nu / (\nu-2)\)</span>. In this way, the standard t distribution is similar to the standard normal distribution, discussed in section <a href="probabilities-likelihood-and-inference.html#c2-standard-normal">2.5.4</a>. In order to use the t distribution for variables with other means and variances, we need to refer to the <strong>non-standardized t distribution</strong>, a three-parameter distribution consisting of mean (<span class="math inline">\(\mu\)</span>), scale (<span class="math inline">\(s\)</span>), and degrees of freedom (<span class="math inline">\(\nu\)</span>). The non-standardized t distribution consist of a (standard) t distributed variable (<span class="math inline">\(t\)</span>) that has been scaled up by some value <span class="math inline">\(s\)</span> and then has had some value <span class="math inline">\(\mu\)</span> added to it, as in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-2">(5.3)</a>. Compare the equation below to the way that we turn the standard normal into a wide range of normal distributions, presented in equation <a href="probabilities-likelihood-and-inference.html#eq:2-8">(2.9)</a>.</p>
<p><span class="math display" id="eq:5-2">\[
\begin{equation}
\begin{split}
x = \mu + s \cdot t
\end{split}
\tag{5.3}
\end{equation}
\]</span></p>
<p>The <span class="math inline">\(\mu\)</span> parameter allows for the probability distribution to be centered at different locations along the number line, and represents the population mean. The <span class="math inline">\(s\)</span> parameter allows the distribution to have wider/narrower distributions than those seen in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-7">5.7</a>, but does <em>not</em> represent the standard deviation. Since we know that the variance of the (standardized) t distribution is <span class="math inline">\(\nu / (\nu-2)\)</span>, the standard deviation must be <span class="math inline">\(\sqrt{\nu / (\nu-2)}\)</span>. Since the <span class="math inline">\(s\)</span> parameter simply scales the standard deviation up or down, the relation of <span class="math inline">\(s\)</span> to the standard deviation and variance of the non-standardized t are presented in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-3">(5.4)</a>.</p>
<p><span class="math display" id="eq:5-3">\[
\begin{equation}
\begin{split}
\sigma = s \cdot \sqrt{\nu / (\nu-2)} \\ \\
\sigma^2 = s^2 \cdot \nu / (\nu-2)
\end{split}
\tag{5.4}
\end{equation}
\]</span></p>
</div>
<div id="re-fitting-with-t-distributed-errors." class="section level2 hasAnchor" number="5.10">
<h2><span class="header-section-number">5.10</span> Re-fitting with t-distributed errors<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#re-fitting-with-t-distributed-errors." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Eagle-eyed readers may have noticed the presence of many outliers in some of our boxplots, which are not in line with a normal distribution. Below we get the residuals from our sum-coded model and take only the first column (the posterior estimates).</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb166-1" aria-hidden="true" tabindex="-1"></a>resids <span class="ot">=</span> <span class="fu">residuals</span> (model_sum_coding)[,<span class="dv">1</span>]</span></code></pre></div>
<p>We scale our data, which means we subtract the mean and divide by the standard deviation. This makes the distribution of our residuals resemble a standard normal distribution, and expresses all deviations from the mean in units of standard deviations. We do this because we know that the standard normal distribution has very little of its mass beyond three standard deviations from the mean. This means scaled residuals with magnitudes greater than three should be relatively rare. When we check the range of our scaled residuals we see that our smallest value is 4.1 standard deviations from the mean, while our largest value is 3.4 standard deviations from the mean.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span> (<span class="fu">scale</span>(resids))</span>
<span id="cb167-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb167-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -4.144  3.471</span></span></code></pre></div>
<p>Below, we see that this is not just two very deviant outliers, since there are several between -4 and -3.5 standard deviations from the mean.</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span> (<span class="fu">sort</span>(<span class="fu">scale</span>(resids)))</span>
<span id="cb168-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb168-2" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] -4.144 -3.846 -3.785 -3.679 -3.668 -3.613</span></span></code></pre></div>
<p>We can use the <code>pnorm</code> function to consider how likely these observations are given our model. The <code>pnorm</code> function takes in an <span class="math inline">\(x\)</span> value, values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, and tells you how much of the mass of the probability density is to the <em>left</em> of the value <span class="math inline">\(x\)</span> (see figure <a href="probabilities-likelihood-and-inference.html#fig:F2-5">2.5</a>). So, the code below tells us that the probability of finding a value smaller than our furthest outlier is only 0.000017.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">=</span> <span class="fu">mean</span>(resids)</span>
<span id="cb169-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fu">sd</span>(resids)</span>
<span id="cb169-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb169-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-4" aria-hidden="true" tabindex="-1"></a><span class="co"># probability of value smaller than smallest outlier</span></span>
<span id="cb169-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-5" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span> (<span class="fu">min</span> (resids),mu,sigma)</span>
<span id="cb169-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb169-6" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 1.704e-05</span></span></code></pre></div>
<p>We can use this probability to estimate the sample size we would expect before seeing an outlier this far out by inverting it. For example, imagine the probability were 1/10, meaning about one tenth of the population is as extreme as our observation. If we invert that we get 10, meaning that a sample of 10 can reasonably be expected to contain an observation as extreme as this, on average. When we do this for our probability above (0.000017), we see that the furthest outlier is extremely improbable, and would be expected in a sample of about 58,680 observations (we have 1401).</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="co"># sample size before outlier this big expected</span></span>
<span id="cb170-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span><span class="fu">pnorm</span> (<span class="fu">min</span> (resids),mu,sigma)</span>
<span id="cb170-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb170-3" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 58680</span></span></code></pre></div>
<p>If this were the only outlier this extreme we might adopt an “outliers happen” attitude and leave it at that. However, the fact that we have several such improbable outliers suggests three possibilities: 1) Our data is from a distribution with more of its density in its tails, 2) the real standard deviation of the error is much larger than we think it is, 3) something else is wrong with our model or data. We can use the <code>fitdistr</code> function from the <code>MASS</code> package to get maximum-likelihood estimates for <span class="math inline">\(\nu\)</span>, <span class="math inline">\(s\)</span>, and <span class="math inline">\(\mu\)</span> given our data, and assuming a non-standardized t distribution. We can see that the estimate for <span class="math inline">\(\nu\)</span> is a relatively small number, suggesting substantial deviations from a normal distribution in the tails of the data.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="co"># get maximum likelihood estimates of t parameters</span></span>
<span id="cb171-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-2" aria-hidden="true" tabindex="-1"></a><span class="co"># the &#39;lower&#39; bounds are for the sd and df respectively</span></span>
<span id="cb171-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-3" aria-hidden="true" tabindex="-1"></a>tparams <span class="ot">=</span> MASS<span class="sc">::</span><span class="fu">fitdistr</span> (resids, <span class="st">&#39;t&#39;</span>, <span class="at">lower =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb171-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb171-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-5" aria-hidden="true" tabindex="-1"></a><span class="co"># check out mean, scale and nu. bottom row is standard errors</span></span>
<span id="cb171-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-6" aria-hidden="true" tabindex="-1"></a>tparams</span>
<span id="cb171-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-7" aria-hidden="true" tabindex="-1"></a><span class="do">##      m        s        df  </span></span>
<span id="cb171-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-8" aria-hidden="true" tabindex="-1"></a><span class="do">##   0.2902   7.1651   7.5753 </span></span>
<span id="cb171-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb171-9" aria-hidden="true" tabindex="-1"></a><span class="do">##  (0.2160) (0.2335) (1.5075)</span></span></code></pre></div>
<p>Just to show that this is not always the case, below we generate 1401 samples from a standard normal distribution, and then estimate its t parameters. We can see that the <span class="math inline">\(\nu\)</span> (<code>df</code>) estimate is a very large number (3607), indicating that the shape of the distribution is very much like a normal distribution.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb172-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-2" aria-hidden="true" tabindex="-1"></a><span class="co"># generate standard normal data</span></span>
<span id="cb172-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-3" aria-hidden="true" tabindex="-1"></a>x_norm <span class="ot">=</span> <span class="fu">rnorm</span> (<span class="dv">1401</span>)</span>
<span id="cb172-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-4" aria-hidden="true" tabindex="-1"></a>norm_params <span class="ot">=</span> MASS<span class="sc">::</span><span class="fu">fitdistr</span> (x_norm, <span class="st">&#39;t&#39;</span>, <span class="at">lower =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span>
<span id="cb172-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb172-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-6" aria-hidden="true" tabindex="-1"></a><span class="co"># nu is very large</span></span>
<span id="cb172-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-7" aria-hidden="true" tabindex="-1"></a>norm_params</span>
<span id="cb172-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-8" aria-hidden="true" tabindex="-1"></a><span class="do">##        m           s          df    </span></span>
<span id="cb172-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-9" aria-hidden="true" tabindex="-1"></a><span class="do">##   0.000e+00   1.025e+00   3.607e+03 </span></span>
<span id="cb172-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb172-10" aria-hidden="true" tabindex="-1"></a><span class="do">##  (2.740e-02) (1.043e-04) (      NaN)</span></span></code></pre></div>
<p>We can use the t parameters estimated for our residual distribution to find the probability of observing outliers as extreme as those seen above from a t distribution. We do this with the <code>ptns</code> function which works very much like the <code>pnorm</code> function, except for non-standardized t distributions. This function takes in an <span class="math inline">\(x\)</span> value, and values of <code>m</code> (<span class="math inline">\(\mu\)</span>), <code>s</code>, and <code>df</code> (i.e., <span class="math inline">\(\nu\)</span>), and tells you how much of the mass of the probability density is to the <em>left</em> of the value <span class="math inline">\(x\)</span>. So, the function below tells us what the probability is of finding a value smaller than our furthest outlier from a t distribution. As we can see, the outliers in our height judgments are unlikely but not <em>too</em> unlikely given a t distribution with <span class="math inline">\(\nu=7.58\)</span>. For example, our sample size is 1401 and we would expect to see an observation as unusual as our furthest outlier about one in every 1354 samples.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">=</span> tparams[[<span class="dv">1</span>]][<span class="dv">1</span>]</span>
<span id="cb173-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-2" aria-hidden="true" tabindex="-1"></a>s <span class="ot">=</span> tparams[[<span class="dv">1</span>]][<span class="dv">2</span>]</span>
<span id="cb173-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-3" aria-hidden="true" tabindex="-1"></a>df <span class="ot">=</span> tparams[[<span class="dv">1</span>]][<span class="dv">3</span>]</span>
<span id="cb173-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-5" aria-hidden="true" tabindex="-1"></a><span class="co"># probability of value smaller than smallest outlier</span></span>
<span id="cb173-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-6" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">ptns</span> (<span class="fu">min</span> (resids),m, s, df)</span>
<span id="cb173-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-7" aria-hidden="true" tabindex="-1"></a><span class="do">##         m </span></span>
<span id="cb173-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-8" aria-hidden="true" tabindex="-1"></a><span class="do">## 0.0007384</span></span>
<span id="cb173-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb173-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-10" aria-hidden="true" tabindex="-1"></a><span class="co"># sample size before outlier thie big expected</span></span>
<span id="cb173-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-11" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span>bmmb<span class="sc">::</span><span class="fu">ptns</span> (<span class="fu">min</span> (resids),m, s, df)</span>
<span id="cb173-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-12" aria-hidden="true" tabindex="-1"></a><span class="do">##    m </span></span>
<span id="cb173-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb173-13" aria-hidden="true" tabindex="-1"></a><span class="do">## 1354</span></span></code></pre></div>
<p>Below, we see that our largest outlier is about 43 times more likely in the t distribution with <span class="math inline">\(\nu=7.58\)</span> than the normal distribution.</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ptns</span> (<span class="fu">min</span> (resids),m, s, df) <span class="sc">/</span> </span>
<span id="cb174-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb174-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pnorm</span> (<span class="fu">min</span> (resids),mu,sigma)</span>
<span id="cb174-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb174-3" aria-hidden="true" tabindex="-1"></a><span class="do">##     m </span></span>
<span id="cb174-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb174-4" aria-hidden="true" tabindex="-1"></a><span class="do">## 43.33</span></span></code></pre></div>
<p>The benefit of using t distributions is that they allow for outliers, that is observations that are very unlike the ‘typical’ observation in a normal model, without such a strong effect on your analysis. Basically, the normal distribution doesn’t like extreme events. When an extreme event <em>does</em> occur, this will result in an increase in your standard deviation estimate so that the extreme event seems less extreme. Since the t distribution encompasses more extreme events, these do not have such a strong effect on estimates of the distribution scale parameter.</p>
<div id="description-of-the-model-1" class="section level3 hasAnchor" number="5.10.1">
<h3><span class="header-section-number">5.10.1</span> Description of the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#description-of-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We update the first line of our model description to show that we are now modeling our height responses using a t-distribution. We also add the prior for the <span class="math inline">\(\nu\)</span> (degrees of freedom) parameter in the last line of the model. In addition, we are going to begin using t distributions for our priors instead of normal distributions. This is the default in brms (as noted in section <a href="fitting-bayesian-regression-models-with-brms.html#c3-specifying-priors">3.7</a>), and serves to allow possible ‘outliers’ that are well-supported by data, while still having a majority of their mass within 2-3 standard deviations from the mean. We’re going to keep using <span class="math inline">\(\sigma\)</span> to represent the model error parameter, even though this represents the <em>scale</em> and not the standard deviation of the distribution. We do this for consistency, and because <code>brms</code> keeps referring to it as <code>sigma</code>, but it’s important to keep in mind the different roles this parameter plays in the normal and t distributions.</p>
<p><span class="math display" id="eq:5-4">\[
\begin{equation}
\begin{split}
height_{[i]} \sim \mathrm{t}(\nu, \mu_{[i]},\sigma) \\
\mu_{[i]} = \mathrm{Intercept} + A  + L_{[\mathsf{L}_{[i]}]} + S_{[\mathsf{S}_{[i]}]} \\ \\
\mathrm{Priors:} \\
L_{[\bullet]} \sim \mathrm{N}(0,\sigma_L) \\
S_{[\bullet]} \sim \mathrm{N}(0,\sigma_S) \\
\\
\mathrm{Intercept} \sim \mathrm{t}(3, 156,12) \\
A \sim \mathrm{t}(3,0,12) \\
\sigma \sim \mathrm{t}(3,0,12) \\
\sigma_L \sim \mathrm{t}(3,0,12) \\
\sigma_S \sim \mathrm{t}(3,0,12) \\
\nu \sim \mathrm{gamma}(2, 0.1) \\
\end{split}
\tag{5.5}
\end{equation}
\]</span></p>
<p>We are using the default prior for <span class="math inline">\(\nu\)</span> set by <code>brms</code> but we are explicitly stating it just to be transparent. We can see what this prior looks like using the <code>dgamma</code> and <code>curve</code> functions to draw the density of a gamma distribution with those parameters. For example, the code below will draw the density of the default prior for <span class="math inline">\(\nu\)</span>:</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dgamma</span>(x,<span class="dv">2</span>,<span class="fl">0.1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">250</span>), <span class="at">xaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>,</span>
<span id="cb175-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb175-2" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">lwd=</span><span class="dv">4</span>, <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.045</span>))</span></code></pre></div>
<p>This approach can also be used to investigate the consequences of tweaking the distributional parameters. In the first two plots of figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-8">5.8</a> we show the density and log density of the curve generated by <code>dgamma(x,2,0.1)</code> (the default), and in the second two plots we see the same for <code>dgamma(x,2,0.02)</code>. For most people, this approach will be more convenient for understanding the relations between parameter setting and density shapes than reading equations. Remember that it is not so important if the prior of <span class="math inline">\(\nu\)</span> <em>really</em> has the shape of a gamma distribution with those parameters. Instead we need to worry about whether the density distributed credibility in the right places, and the default one basically does.</p>
<div class="figure"><span style="display:block;" id="fig:F5-8"></span>
<img src="_main_files/figure-html/F5-8-1.jpeg" alt="(left) The density of a gamma distribution with the parameters specified in our model (`dgamma(x,2,0.1)`). (left middle) The log-density of the distribution in the left plot. (right middle) The density of a gamma distribution with alternate parameters (`dgamma(x,2,0.02)`). (right) The log-density of the distribution in the right-middle plot." width="4800" />
<p class="caption">
Figure 5.8: (left) The density of a gamma distribution with the parameters specified in our model (<code>dgamma(x,2,0.1)</code>). (left middle) The log-density of the distribution in the left plot. (right middle) The density of a gamma distribution with alternate parameters (<code>dgamma(x,2,0.02)</code>). (right) The log-density of the distribution in the right-middle plot.
</p>
</div>
</div>
<div id="fitting-and-interpreting-the-model-1" class="section level3 hasAnchor" number="5.10.2">
<h3><span class="header-section-number">5.10.2</span> Fitting and interpreting the model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fitting-and-interpreting-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Below we fit the new model described in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-4">(5.5)</a>. This model is exactly like our <code>model_sum_coding</code> model save for three differences. First, we specify that our error distribution is a t-distribution rather than Gaussian by setting <code>family="student"</code>. Second, we set the prior probability for a new special class of parameter (<code>nu</code>) that is specific to the t distribution. We use the default prior for <code>nu</code> used by <code>brm</code>, but we explicitly state it in the model for clarity. Third, we are now using <code>student_t</code> for our priors for all of our other classes of parameters where we previously used <code>sigma</code>.</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the model yourself</span></span>
<span id="cb176-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-2" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&#39;contr.sum&#39;</span>,<span class="st">&#39;contr.sum&#39;</span>))</span>
<span id="cb176-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-3" aria-hidden="true" tabindex="-1"></a>model_sum_coding_t <span class="ot">=</span>  brms<span class="sc">::</span><span class="fu">brm</span> (</span>
<span id="cb176-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-4" aria-hidden="true" tabindex="-1"></a>  height <span class="sc">~</span> A <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data =</span> notmen, <span class="at">chains =</span> <span class="dv">4</span>, </span>
<span id="cb176-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">cores =</span> <span class="dv">4</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">iter =</span> <span class="dv">3500</span>, <span class="at">thin =</span> <span class="dv">2</span>, <span class="at">family=</span><span class="st">&quot;student&quot;</span>,</span>
<span id="cb176-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">prior =</span> <span class="fu">c</span>(brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 156, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb176-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-7" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;b&quot;</span>),</span>
<span id="cb176-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-8" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sd&quot;</span>),</span>
<span id="cb176-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-9" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;gamma(2, 0.1)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;nu&quot;</span>),</span>
<span id="cb176-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb176-10" aria-hidden="true" tabindex="-1"></a>            brms<span class="sc">::</span><span class="fu">set_prior</span>(<span class="st">&quot;student_t(3, 0, 12)&quot;</span>, <span class="at">class =</span> <span class="st">&quot;sigma&quot;</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb177-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Or download it from the GitHub page:</span></span>
<span id="cb177-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb177-2" aria-hidden="true" tabindex="-1"></a>model_sum_coding_t <span class="ot">=</span> bmmb<span class="sc">::</span><span class="fu">get_model</span> (<span class="st">&#39;5_model_sum_coding_t.RDS&#39;</span>)</span></code></pre></div>
<p>We inspect the short summary:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect model</span></span>
<span id="cb178-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-2" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">short_summary</span> (model_sum_coding_t)</span>
<span id="cb178-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Formula:  height ~ A + (1 | L) + (1 | S)</span></span>
<span id="cb178-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-4" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb178-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Group-Level Effects:</span></span>
<span id="cb178-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-6" aria-hidden="true" tabindex="-1"></a><span class="do">## ~L (Number of levels: 15)</span></span>
<span id="cb178-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-7" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb178-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-8" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     5.08      1.12     3.46     7.81</span></span>
<span id="cb178-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-9" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb178-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-10" aria-hidden="true" tabindex="-1"></a><span class="do">## ~S (Number of levels: 94)</span></span>
<span id="cb178-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-11" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb178-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-12" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     3.36      0.42      2.6     4.21</span></span>
<span id="cb178-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-13" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb178-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-14" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects:</span></span>
<span id="cb178-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-15" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb178-16"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-16" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept   155.59      1.38   152.85   158.31</span></span>
<span id="cb178-17"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-17" aria-hidden="true" tabindex="-1"></a><span class="do">## A1            8.44      0.34     7.78     9.12</span></span>
<span id="cb178-18"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-18" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb178-19"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-19" aria-hidden="true" tabindex="-1"></a><span class="do">## Family Specific Parameters:</span></span>
<span id="cb178-20"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-20" aria-hidden="true" tabindex="-1"></a><span class="do">##       Estimate Est.Error l-95% CI u-95% CI</span></span>
<span id="cb178-21"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-21" aria-hidden="true" tabindex="-1"></a><span class="do">## sigma     7.23      0.27     6.71     7.76</span></span>
<span id="cb178-22"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb178-22" aria-hidden="true" tabindex="-1"></a><span class="do">## nu        6.90      1.52     4.72    10.40</span></span></code></pre></div>
<p>And see that there is a new line in the family-specific parameters corresponding to our estimate of <span class="math inline">\(\nu\)</span>, and we get a mean and credible interval for this parameter. As noted above, the <code>sigma</code> parameter reported by this model corresponds to the scale parameter of the non-standardized t distribution, and not the standard deviation. To recover the standard deviation we can carry out the operation given in <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#eq:5-3">(5.4)</a>. The result of this is that our model is actually estimating a very similar standard deviation to what we find using a normal error (8.58 in <code>model_sum_coding</code>).</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb179-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb179-1" aria-hidden="true" tabindex="-1"></a>nu <span class="ot">=</span> <span class="fl">6.90</span></span>
<span id="cb179-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb179-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">=</span> <span class="fl">7.23</span></span>
<span id="cb179-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb179-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="sc">*</span> <span class="fu">sqrt</span> (nu <span class="sc">/</span> (nu<span class="dv">-2</span>))</span>
<span id="cb179-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb179-4" aria-hidden="true" tabindex="-1"></a><span class="do">## [1] 8.58</span></span></code></pre></div>
<p>If we compare the means and intervals around our fixed effects, we see that the two models provide very similar conclusions.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span> (model_sum_coding)</span>
<span id="cb180-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-2" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error    Q2.5   Q97.5</span></span>
<span id="cb180-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  155.218    1.4050 152.434 157.965</span></span>
<span id="cb180-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-4" aria-hidden="true" tabindex="-1"></a><span class="do">## A1           8.711    0.3602   8.003   9.416</span></span>
<span id="cb180-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb180-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-6" aria-hidden="true" tabindex="-1"></a><span class="fu">fixef</span> (model_sum_coding_t)</span>
<span id="cb180-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-7" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error   Q2.5   Q97.5</span></span>
<span id="cb180-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-8" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept  155.588    1.3803 152.85 158.311</span></span>
<span id="cb180-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb180-9" aria-hidden="true" tabindex="-1"></a><span class="do">## A1           8.443    0.3386   7.78   9.119</span></span></code></pre></div>
<p>We may wonder, is it worth using t-distributed errors? On the one hand, we know that our error residuals don’t seem to be normally distributed, which suggests that an important assumption of the model we used in <code>model_sum_coding</code> is being violated. On the other hand, we know that no model is perfect and that we should never expect that our model will exactly match an underlying process. As a result we may often have to accept slight misalignments between our model and ‘reality’. So, when do we care that a model is ‘wrong’ and when do we not care that it’s wrong? We need a principled way to think about whether an addition to a model is “worth it”, and our approach will have to be more sophisticated than glancing at model output and seeing if things have changed. We will return to this topic in the next chapter.</p>
</div>
</div>
<div id="c5-simulating" class="section level2 hasAnchor" number="5.11">
<h2><span class="header-section-number">5.11</span> Simulating the two-group model<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-simulating" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As in the last chapter, we’re going to make fake data that has the same properties as our real data by adding up its component parts. We’re going to base this on the parameters of <code>model_sum_coding</code> because t-distributed errors can sometimes be quite large.</p>
<p>First, there is an intercept equal to 155 cm. The next step is to create a vector of length two that contains the effects for the adult and child groups (<code>A1</code> and <code>-A1</code>). Notice that we are <em>not</em> drawing these values from a probability distribution. Instead we are treating these effects as fixed for all speakers, for future experiments, etc. (hence the ‘fixed effects’ nomenclature). For the purposes of our simulated data, this means that these effects will be consistent across any number of simulations you run. In contrast, the <code>L_</code> and <code>S_</code> values (representing <span class="math inline">\(L_{[\bullet]}\)</span> and <span class="math inline">\(S_{[\bullet]}\)</span>) <em>are</em> drawn from probability distributions. This is because every time we simulate our data (or re-run our experiment), we may encounter different speakers and listeners, and these may vary in unpredictable ways.</p>
<div class="sourceCode" id="cb181"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb181-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-1" aria-hidden="true" tabindex="-1"></a>n_listeners <span class="ot">=</span> <span class="dv">15</span></span>
<span id="cb181-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-2" aria-hidden="true" tabindex="-1"></a>n_speakers <span class="ot">=</span> <span class="dv">94</span> <span class="co"># must be even!</span></span>
<span id="cb181-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-4" aria-hidden="true" tabindex="-1"></a><span class="co"># don&#39;t run this line if you want a new simulated dataset. </span></span>
<span id="cb181-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb181-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-6" aria-hidden="true" tabindex="-1"></a><span class="co"># this is the value of our intercept</span></span>
<span id="cb181-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-7" aria-hidden="true" tabindex="-1"></a>Intercept <span class="ot">=</span> <span class="dv">155</span></span>
<span id="cb181-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-9" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector of adultness fixed effects</span></span>
<span id="cb181-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-10" aria-hidden="true" tabindex="-1"></a>A_ <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">8.7</span>, <span class="sc">-</span><span class="fl">8.7</span>)</span>
<span id="cb181-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-12" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector indicating which adultness group the observation is in</span></span>
<span id="cb181-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-13" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">rep</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, (n_listeners<span class="sc">*</span>n_speakers<span class="sc">/</span><span class="dv">2</span>))</span>
<span id="cb181-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-15" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector of 15 listener effects</span></span>
<span id="cb181-16"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-16" aria-hidden="true" tabindex="-1"></a>L_ <span class="ot">=</span> <span class="fu">rnorm</span> (n_listeners, <span class="dv">0</span>, <span class="fl">5.2</span>)</span>
<span id="cb181-17"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-18"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-18" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector indicating which listener provided which observation</span></span>
<span id="cb181-19"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-19" aria-hidden="true" tabindex="-1"></a>L <span class="ot">=</span> <span class="fu">rep</span> (<span class="dv">1</span><span class="sc">:</span>n_listeners, <span class="at">each =</span> n_speakers)</span>
<span id="cb181-20"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-21"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-21" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector of 94 speaker effects</span></span>
<span id="cb181-22"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-22" aria-hidden="true" tabindex="-1"></a>S_ <span class="ot">=</span> <span class="fu">rnorm</span> (n_speakers, <span class="dv">0</span>, <span class="fl">3.6</span>)</span>
<span id="cb181-23"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-24"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-24" aria-hidden="true" tabindex="-1"></a><span class="co"># this is a vector indicating which speaker produced which utterance</span></span>
<span id="cb181-25"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-25" aria-hidden="true" tabindex="-1"></a>S <span class="ot">=</span> <span class="fu">rep</span> (<span class="dv">1</span><span class="sc">:</span>n_speakers, <span class="at">each =</span> n_listeners)</span>
<span id="cb181-26"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-27"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-27" aria-hidden="true" tabindex="-1"></a><span class="co"># this vector contains the error</span></span>
<span id="cb181-28"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-28" aria-hidden="true" tabindex="-1"></a>epsilon <span class="ot">=</span> <span class="fu">rnorm</span> (n_speakers<span class="sc">*</span>n_listeners, <span class="dv">0</span>, <span class="fl">8.6</span>)</span>
<span id="cb181-29"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb181-30"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-30" aria-hidden="true" tabindex="-1"></a><span class="co"># the sum of the above components equals our observations</span></span>
<span id="cb181-31"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb181-31" aria-hidden="true" tabindex="-1"></a>height_rep <span class="ot">=</span> Intercept <span class="sc">+</span> A_[A] <span class="sc">+</span> L_[L] <span class="sc">+</span> S_[S] <span class="sc">+</span> epsilon</span></code></pre></div>
<p>We need to highlight something that’s very important about the way we are simulating our speaker and listener effects. When we simulated data last chapter, we saw that <span class="math inline">\(\varepsilon\)</span> does not distinguish between listeners. Instead our error variable is ‘the same’ across groups and is divided arbitrarily among them. In the same way, our draws of <span class="math inline">\(S_{[\bullet]}\)</span> do not distinguish between our child and adult groups. Notice that all 94 speaker effects are drawn from the same distribution of speakers. We can see this same behavior reflected in the print statement of our <code>model_sum_coding</code> model, which contains this text:</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb182-1" aria-hidden="true" tabindex="-1"></a><span class="do">## ~S (Number of levels: 94) </span></span>
<span id="cb182-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb182-2" aria-hidden="true" tabindex="-1"></a><span class="do">##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb182-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb182-3" aria-hidden="true" tabindex="-1"></a><span class="do">## sd(Intercept)     3.58      0.42     2.82     4.45 1.00     2878     4054</span></span></code></pre></div>
<p>We know that these speakers are divided into two groups, adults and children. However, our model is treating these as 94 observations from a single group with a standard deviation of 3.58 and a mean of zero. Rather than reflect differences between adult and child speakers in the characteristics of the random effects, our model does so with its fixed effect structure. What we mean by this is that our model represents differences between apparent children and adults using the <code>A1</code> parameter, and so does not need to do so using the random effects. This is analogous to the way in which we draw our random error around 0, and then move these errors around the number line by adding them to (for instance) our listener effects.</p>
<p>Below we make five data sets that are ‘incomplete’: The first contains the intercept and noise only, the second contains the intercept and adultness effects only, the third contains the intercept and listener effects, and the fourth contains the intercept, adultness effect and the error. The fifth ‘incomplete’ data set is <em>almost</em> complete, it contains everything in our full model save for the speaker effects.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only intercept and error</span></span>
<span id="cb183-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-2" aria-hidden="true" tabindex="-1"></a>height_rep_1 <span class="ot">=</span> Intercept <span class="sc">+</span> epsilon</span>
<span id="cb183-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-4" aria-hidden="true" tabindex="-1"></a><span class="co"># only intercept and adultness</span></span>
<span id="cb183-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-5" aria-hidden="true" tabindex="-1"></a>height_rep_2 <span class="ot">=</span> Intercept <span class="sc">+</span> A_[A]</span>
<span id="cb183-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-7" aria-hidden="true" tabindex="-1"></a><span class="co"># only intercept and speaker</span></span>
<span id="cb183-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-8" aria-hidden="true" tabindex="-1"></a>height_rep_3 <span class="ot">=</span> Intercept <span class="sc">+</span> L_[L]</span>
<span id="cb183-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-10" aria-hidden="true" tabindex="-1"></a><span class="co"># intercept, adultness and error</span></span>
<span id="cb183-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-11" aria-hidden="true" tabindex="-1"></a>height_rep_4 <span class="ot">=</span> Intercept <span class="sc">+</span> A_[A] <span class="sc">+</span> epsilon</span>
<span id="cb183-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb183-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-13" aria-hidden="true" tabindex="-1"></a><span class="co"># intercept, adutlness and speaker</span></span>
<span id="cb183-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb183-14" aria-hidden="true" tabindex="-1"></a>height_rep_5 <span class="ot">=</span> Intercept <span class="sc">+</span> A_[A] <span class="sc">+</span> L_[L] <span class="sc">+</span> epsilon</span></code></pre></div>
<p>In figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-9">5.9</a> we compare our incomplete, simulated data to our real data. In each of the figures, we can see what each source of variance contributes to the data by seeing how the figures change when the source is omitted from the replicated data.</p>
<div class="figure"><span style="display:block;" id="fig:F5-9"></span>
<img src="_main_files/figure-html/F5-9-1.jpeg" alt="Boxplots comparing different simulated datasets to the real data. Each color represents a different simulated listener." width="4800" />
<p class="caption">
Figure 5.9: Boxplots comparing different simulated datasets to the real data. Each color represents a different simulated listener.
</p>
</div>
</div>
<div id="c5-answering-qs" class="section level2 hasAnchor" number="5.12">
<h2><span class="header-section-number">5.12</span> Answering our research questions<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-answering-qs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We’ve fit and interpreted a model, discussed the details of the results, and seen several representations of the data. At this point we need to think about what it all ‘means’ in terms of our research questions:</p>
<p>(Q1) How tall do speakers perceived as adult females sound?</p>
<p>(Q2) How tall do speakers perceived as children sound?</p>
<p>(Q3) What is the difference in apparent height associated with the perception of adultness?</p>
<p>Although these questions are framed in terms of differences between means, a full accounting of the patterns in our data will also discuss the random and systematic variation found therein. in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-10">5.10</a>, we consider the distribution of height judgments across listeners and age groups, as in figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-1">5.1</a>. However, this time information about the grand mean and the expected adult and child average apparent heights is presented on the figure.</p>
<div class="figure"><span style="display:block;" id="fig:F5-10"></span>
<img src="_main_files/figure-html/F5-10-1.jpeg" alt="(left) Distribution of apparent heights according to apparent age group, across all speakers. (right) Same as left plot but presented individually for each listener. In each case, the first box of each color (the upper box) indicates responses for apparent adults. The horizontal lines running through the plots represent the grand mean (black), the adult mean (blue), and the child mean (green)." width="4800" />
<p class="caption">
Figure 5.10: (left) Distribution of apparent heights according to apparent age group, across all speakers. (right) Same as left plot but presented individually for each listener. In each case, the first box of each color (the upper box) indicates responses for apparent adults. The horizontal lines running through the plots represent the grand mean (black), the adult mean (blue), and the child mean (green).
</p>
</div>
<p>A look at <code>model_sum_coding_t</code> (and figure <a href="comparing-two-groups-of-observations-factors-and-contrasts.html#fig:F5-10">5.10</a>) suggests that:</p>
<ul>
<li><p>The magnitude of between-listener and speaker variation is much smaller than the difference between the adult mean and the child mean (5.1 and 3.4 cm, vs 17 cm). This means that the effect for apparent age on apparent height is not overwhelmed by random variation due to differences between the characteristics of speakers and the tendencies of listeners.</p></li>
<li><p>The magnitude of the random error, i.e. the variation given a certain listener, speaker <em>and</em> apparent age judgment, is 8.6 cm (<code>sqrt(6.90/(6.90-2))*7.23</code>). This is larger than the between-listener and between-speaker variation in our data. This means that for any two adults or children selected at random, the expected difference between them will be smaller than the variability in repeated height estimation for any given voice. So, we see that our height judgments are noisy and that this noisiness can potentially overwhelm at least some of the systematic variation in our data.</p></li>
<li><p>However, the difference in apparent height due to apparent age (17 cm in total) is twice as large as the random error and larger than the between speaker and between listener variation. This means that the systematic variation in apparent height due to apparent age is expected to be quite salient even in the face of the noisiness of our data.</p></li>
</ul>
<p>If we were reporting this in a paper, based on the sum coded model we might say something like:</p>
<blockquote>
<p>“The overall mean apparent height across all speakers was 156 cm (s.d. = 1.38, 95% C.I = [152.85, 158.31]). We found a difference of 17 cm (s.d. = 0.68, 95% C.I = [15.56, 18.24]) in apparent height associated with the perception of adultness in speakers. The standard deviation of the listener and speaker effects were 5.1 cm (s.d = 1.1, 95% CI = [3.5, 7.8]) and 3.4 cm (s.d = 0.4, 95% CI = [2.6, 4.2]) respectively. Overall, results indicate a reliable difference in apparent speaker height due to apparent age, which is larger than the expected random variation in apparent height judgments due to variation between speakers and listeners”.</p>
</blockquote>
<p>Notice that to report the difference between groups, we just double the value of the estimated effect for <code>A1</code>. This is because the <code>A1</code> coefficient reflects the distance between each group mean and the intercept, and therefore <em>half</em> of the distance between the two groups.</p>
</div>
<div id="c5-frequentist" class="section level2 hasAnchor" number="5.13">
<h2><span class="header-section-number">5.13</span> ‘Traditionalists’ corner<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#c5-frequentist" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In traditionalists corner, we’re going to compare the output of <code>brms</code> to some more ‘traditional’ approaches. We’re not going to talk about the traditional models in any detail, the focus of this section is simply to highlight the similarities between different approaches, and to point out where to find equivalent information in the different models. If you are already familiar with these approaches, these sections may be helpful. If not, some of the information provided here may not make much sense, although it may still be helpful. If you want to know more about the statistical methods being discussed here, please see the preface for a list of suggested background reading in statistics.</p>
<div id="bayesian-multilevel-models-vs.-lmer" class="section level3 hasAnchor" number="5.13.1">
<h3><span class="header-section-number">5.13.1</span> Bayesian multilevel models vs. lmer<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#bayesian-multilevel-models-vs.-lmer" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here we compare the output of <code>brms</code> to the output of the <code>lmer</code> (“linear mixed-effects regression”) function, a very popular function for fitting multilevel models in the <code>lme4</code> package in R. Below we fit a model that is analogous to <code>model_sum_coding</code>. Since we set contrasts to sum coding using the options above, this will still be in effect for this model. If you have not done so, run the line:</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb184-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span> (<span class="at">contrasts =</span> <span class="fu">c</span>(<span class="st">&quot;contr.sum&quot;</span>,<span class="st">&quot;contr.sum&quot;</span>))</span></code></pre></div>
<p>Before fitting the model below so that its output looks as expected.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span> (lme4)</span>
<span id="cb185-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-2" aria-hidden="true" tabindex="-1"></a>lmer_model <span class="ot">=</span> <span class="fu">lmer</span> (height <span class="sc">~</span> A <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>L) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>S), <span class="at">data =</span> notmen)</span>
<span id="cb185-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb185-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span> (lmer_model)</span>
<span id="cb185-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-5" aria-hidden="true" tabindex="-1"></a><span class="do">## Linear mixed model fit by REML [&#39;lmerMod&#39;]</span></span>
<span id="cb185-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-6" aria-hidden="true" tabindex="-1"></a><span class="do">## Formula: height ~ A + (1 | L) + (1 | S)</span></span>
<span id="cb185-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-7" aria-hidden="true" tabindex="-1"></a><span class="do">##    Data: notmen</span></span>
<span id="cb185-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-8" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb185-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-9" aria-hidden="true" tabindex="-1"></a><span class="do">## REML criterion at convergence: 10161</span></span>
<span id="cb185-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-10" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb185-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-11" aria-hidden="true" tabindex="-1"></a><span class="do">## Scaled residuals: </span></span>
<span id="cb185-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-12" aria-hidden="true" tabindex="-1"></a><span class="do">##    Min     1Q Median     3Q    Max </span></span>
<span id="cb185-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-13" aria-hidden="true" tabindex="-1"></a><span class="do">## -4.023 -0.562  0.058  0.603  3.364 </span></span>
<span id="cb185-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-14" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb185-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-15" aria-hidden="true" tabindex="-1"></a><span class="do">## Random effects:</span></span>
<span id="cb185-16"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-16" aria-hidden="true" tabindex="-1"></a><span class="do">##  Groups   Name        Variance Std.Dev.</span></span>
<span id="cb185-17"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-17" aria-hidden="true" tabindex="-1"></a><span class="do">##  S        (Intercept) 12.4     3.52    </span></span>
<span id="cb185-18"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-18" aria-hidden="true" tabindex="-1"></a><span class="do">##  L        (Intercept) 22.9     4.79    </span></span>
<span id="cb185-19"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-19" aria-hidden="true" tabindex="-1"></a><span class="do">##  Residual             73.5     8.57    </span></span>
<span id="cb185-20"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-20" aria-hidden="true" tabindex="-1"></a><span class="do">## Number of obs: 1401, groups:  S, 94; L, 15</span></span>
<span id="cb185-21"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-21" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb185-22"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-22" aria-hidden="true" tabindex="-1"></a><span class="do">## Fixed effects:</span></span>
<span id="cb185-23"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-23" aria-hidden="true" tabindex="-1"></a><span class="do">##             Estimate Std. Error t value</span></span>
<span id="cb185-24"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-24" aria-hidden="true" tabindex="-1"></a><span class="do">## (Intercept)  155.193      1.310   118.5</span></span>
<span id="cb185-25"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-25" aria-hidden="true" tabindex="-1"></a><span class="do">## A1             8.729      0.312    27.9</span></span>
<span id="cb185-26"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-26" aria-hidden="true" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb185-27"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-27" aria-hidden="true" tabindex="-1"></a><span class="do">## Correlation of Fixed Effects:</span></span>
<span id="cb185-28"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-28" aria-hidden="true" tabindex="-1"></a><span class="do">##    (Intr)</span></span>
<span id="cb185-29"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb185-29" aria-hidden="true" tabindex="-1"></a><span class="do">## A1 0.046</span></span></code></pre></div>
<p>We can see that this contains estimates that are very similar to those of our model. The ‘fixed’ effects above correspond closely to their ‘Population-Level’ counterparts, and the rest of the information provided by the models (see section <a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html#c4-vs-lmer">4.11.1</a>) is also a reasonable match.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Population-Level Effects: </span></span>
<span id="cb186-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb186-2" aria-hidden="true" tabindex="-1"></a><span class="do">##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS</span></span>
<span id="cb186-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb186-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Intercept   155.22      1.41   152.43   157.96 1.00     1687     2492</span></span>
<span id="cb186-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb186-4" aria-hidden="true" tabindex="-1"></a><span class="do">## A1            8.71      0.36     8.00     9.42 1.00     3883     4065</span></span></code></pre></div>
</div>
</div>
<div id="exercises-4" class="section level2 hasAnchor" number="5.14">
<h2><span class="header-section-number">5.14</span> Exercises<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#exercises-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The analyses in the main body of the text all involve only the unmodified ‘actual’ resonance level (in <code>exp_data</code>). Responses for the stimuli with the simulate ‘big’ resonance are reserved for exercises throughout. You can get the ‘big’ resonance in the <code>exp_ex</code> data frame, or all data in the <code>exp_data_all</code> data frame.</p>
<p>Fit and interpret one or more of the suggested models:</p>
<ol style="list-style-type: decimal">
<li><p>Easy: Analyze the (pre-fit) model that’s exactly like <code>model_sum_coding_t</code>, except using the data in <code>exp_ex</code> (<code>bmmb::get_model("5_model_sum_coding_t_ex.RDS")</code>).</p></li>
<li><p>Medium: Fit a model like <code>model_sum_coding_t</code>, but comparing any two groups across resonance levels.</p></li>
<li><p>Hard: Fit two models like <code>model_sum_coding_t</code>, but comparing any two groups across resonance levels. Compare results across models to think about group differences.</p></li>
</ol>
<p>In any case, describe the model, present and explain the results, and include some figures.</p>
</div>
<div id="plot-code-4" class="section level2 hasAnchor" number="5.15">
<h2><span class="header-section-number">5.15</span> Plot Code<a href="comparing-two-groups-of-observations-factors-and-contrasts.html#plot-code-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-2"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-2" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">&quot;../_main_files/figure-html/Figure 5.1.jpg&quot;</span>)</span>
<span id="cb187-3"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-4"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-4" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-5"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-5" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.2</span></span>
<span id="cb187-6"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-6" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-7"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-8"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-8" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb187-9"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-10"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-10" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A_v <span class="sc">+</span> A, <span class="at">data =</span> notmen, <span class="at">col =</span> bmmb<span class="sc">::</span>cols[<span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">4</span>,<span class="dv">9</span>,<span class="dv">4</span>)], </span>
<span id="cb187-11"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">&quot;Perceived Age&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Apparent height (cm)&quot;</span>, <span class="at">horizontal =</span> <span class="cn">TRUE</span>,</span>
<span id="cb187-12"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">names=</span><span class="fu">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>),<span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>)</span>
<span id="cb187-13"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-13" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span> (<span class="at">side=</span><span class="dv">2</span>,<span class="at">at =</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.5</span>),<span class="fu">c</span>(<span class="st">&quot;Adult&quot;</span>,<span class="st">&quot;Child&quot;</span>))</span>
<span id="cb187-14"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-15"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-15" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span> (<span class="dv">108</span>,<span class="dv">2</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;Veridical adults&quot;</span>,</span>
<span id="cb187-16"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-16" aria-hidden="true" tabindex="-1"></a>                           <span class="st">&quot;Veridical children&quot;</span>),</span>
<span id="cb187-17"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-17" aria-hidden="true" tabindex="-1"></a>         <span class="at">pch=</span><span class="dv">15</span>,<span class="at">col =</span> bmmb<span class="sc">::</span>cols[<span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">4</span>)], <span class="at">bty=</span><span class="st">&#39;n&#39;</span>,<span class="at">pt.cex=</span><span class="fl">1.5</span>)</span>
<span id="cb187-18"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-19"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-19" aria-hidden="true" tabindex="-1"></a><span class="co"># aa = notmen$height[notmen$A_v==&quot;a&quot; &amp; notmen$A==&quot;a&quot;]</span></span>
<span id="cb187-20"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-20" aria-hidden="true" tabindex="-1"></a><span class="co"># ac = notmen$height[notmen$A_v==&quot;a&quot; &amp; notmen$A==&quot;c&quot;]</span></span>
<span id="cb187-21"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ca = notmen$height[notmen$A_v==&quot;c&quot; &amp; notmen$A==&quot;a&quot;]</span></span>
<span id="cb187-22"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-22" aria-hidden="true" tabindex="-1"></a><span class="co"># cc = notmen$height[notmen$A_v==&quot;c&quot; &amp; notmen$A==&quot;c&quot;]</span></span>
<span id="cb187-23"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-23" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb187-24"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-24" aria-hidden="true" tabindex="-1"></a><span class="co"># plot (density (aa), xlim = c(110,185), lwd=4, col= bmmb::cols[9],</span></span>
<span id="cb187-25"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-25" aria-hidden="true" tabindex="-1"></a><span class="co">#       main=&quot;&quot;,xlab = &quot;Apparent height (cm)&quot;, ylim = c(0,0.15),yaxs=&#39;i&#39;)</span></span>
<span id="cb187-26"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-26" aria-hidden="true" tabindex="-1"></a><span class="co"># lines (density (ac), lwd=4, col= bmmb::cols[4])</span></span>
<span id="cb187-27"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-27" aria-hidden="true" tabindex="-1"></a><span class="co"># lines (density (ca), lwd=4, col= bmmb::cols[9],lty=2)</span></span>
<span id="cb187-28"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-28" aria-hidden="true" tabindex="-1"></a><span class="co"># lines (density (cc), lwd=4, col= bmmb::cols[4],lty=2)</span></span>
<span id="cb187-29"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-29" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb187-30"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-30" aria-hidden="true" tabindex="-1"></a><span class="co"># legend (108,0.13,legend=c(&quot;Veridical adults, identified as adults&quot;,</span></span>
<span id="cb187-31"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-31" aria-hidden="true" tabindex="-1"></a><span class="co">#                           &quot;Veridical children, identified as adults&quot;,</span></span>
<span id="cb187-32"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-32" aria-hidden="true" tabindex="-1"></a><span class="co">#                           &quot;Veridical adults, identified as children&quot;,</span></span>
<span id="cb187-33"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-33" aria-hidden="true" tabindex="-1"></a><span class="co">#                           &quot;Veridical children, identified as children&quot;),</span></span>
<span id="cb187-34"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-34" aria-hidden="true" tabindex="-1"></a><span class="co">#         lwd=6,col = bmmb::cols[c(9,9,4,4)], bty=&#39;n&#39;,lty=c(1,3,1,3))</span></span>
<span id="cb187-35"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-36"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-36" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-37"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-37" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.3</span></span>
<span id="cb187-38"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-38" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-39"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-40"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-40" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.1</span>,.<span class="dv">1</span>,.<span class="dv">5</span>,.<span class="dv">1</span>),<span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">0</span>,.<span class="dv">50</span>)); <span class="fu">layout</span> (<span class="at">mat =</span> <span class="fu">t</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)), <span class="at">widths =</span> <span class="fu">c</span>(.<span class="dv">2</span>,.<span class="dv">8</span>))</span>
<span id="cb187-41"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-42"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-42" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">c</span>(beige,lightpink),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>), <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb187-43"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-43" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side=</span><span class="dv">1</span>, <span class="st">&quot;Apparent Age Group&quot;</span>, <span class="at">line=</span><span class="dv">3</span>)</span>
<span id="cb187-44"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-45"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-45" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side =</span> <span class="dv">2</span>, <span class="at">outer =</span> <span class="cn">FALSE</span>, <span class="st">&quot;Apparent height (cm)&quot;</span>, <span class="at">line =</span> <span class="fl">2.75</span>)</span>
<span id="cb187-46"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-46" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A<span class="sc">+</span>L, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">rep</span>(cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>),</span>
<span id="cb187-47"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-47" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Listener&quot;</span>)</span>
<span id="cb187-48"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-48" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span> (<span class="at">side=</span><span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="fl">1.5</span>,<span class="fl">30.5</span>,<span class="dv">2</span>), <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>)</span>
<span id="cb187-49"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-50"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-51"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-51" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-52"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-52" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.4</span></span>
<span id="cb187-53"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-53" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-54"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-55"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-55" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">&quot;../_main_files/figure-html/Figure 5.4.jpg&quot;</span>)</span>
<span id="cb187-56"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-57"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-57" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-58"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-58" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.5</span></span>
<span id="cb187-59"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-59" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-60"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-60" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">3</span>,<span class="dv">1</span>))</span>
<span id="cb187-61"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-61" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="st">&#39;Intercept&#39;</span>],<span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col =</span> skyblue,<span class="at">main=</span><span class="st">&#39;Intercept&#39;</span>,</span>
<span id="cb187-62"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-62" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)  </span>
<span id="cb187-63"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-63" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col =</span> deeppurple,<span class="at">main=</span><span class="st">&#39;A1&#39;</span>,</span>
<span id="cb187-64"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-64" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)</span>
<span id="cb187-65"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-65" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="st">&#39;Intercept&#39;</span>]<span class="sc">-</span>samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">freq=</span><span class="cn">FALSE</span>, <span class="at">col =</span> teal,<span class="at">main=</span><span class="st">&#39;Intercept-A1&#39;</span>,</span>
<span id="cb187-66"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-66" aria-hidden="true" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)</span>
<span id="cb187-67"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-67" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span> (samples[,<span class="st">&#39;Intercept&#39;</span>]<span class="sc">+</span>samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">freq=</span><span class="cn">FALSE</span>, </span>
<span id="cb187-68"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-68" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> yellow,<span class="at">main=</span><span class="st">&#39;Intercept+A1&#39;</span>,<span class="at">xlab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)</span>
<span id="cb187-69"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-69" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="st">&#39;Intercept&#39;</span>], <span class="at">col =</span> skyblue,<span class="at">pch=</span><span class="dv">16</span>,<span class="at">ylab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)  </span>
<span id="cb187-70"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-70" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">col =</span> deeppurple, <span class="at">pch=</span><span class="dv">16</span>,<span class="at">ylab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)  </span>
<span id="cb187-71"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-71" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="st">&#39;Intercept&#39;</span>]<span class="sc">-</span>samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">col =</span> teal, <span class="at">pch=</span><span class="dv">16</span>,<span class="at">ylab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)</span>
<span id="cb187-72"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-72" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span> (samples[,<span class="st">&#39;Intercept&#39;</span>]<span class="sc">+</span>samples[,<span class="st">&#39;A1&#39;</span>], <span class="at">col =</span> yellow,</span>
<span id="cb187-73"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-73" aria-hidden="true" tabindex="-1"></a>      <span class="at">pch=</span><span class="dv">16</span>,<span class="at">ylab=</span><span class="st">&quot;Apparent Height (cm)&quot;</span>)  </span>
<span id="cb187-74"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-75"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-75" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-76"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-76" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.6</span></span>
<span id="cb187-77"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-77" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-78"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-79"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-79" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="fl">2.5</span>,.<span class="dv">1</span>,.<span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb187-80"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-80" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">brmplot</span> (listener_means_hat, <span class="at">col =</span> cols,<span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">143</span>,<span class="dv">168</span>),<span class="at">xlab=</span><span class="st">&quot;Listener&quot;</span>)</span>
<span id="cb187-81"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-81" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span> (listener_means, <span class="at">cex=</span><span class="dv">2</span>, <span class="at">col =</span> cols, <span class="at">pch =</span> <span class="dv">4</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb187-82"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-82" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> Intercept)</span>
<span id="cb187-83"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-83" aria-hidden="true" tabindex="-1"></a>bmmb<span class="sc">::</span><span class="fu">brmplot</span> (listener_effects_hat, <span class="at">col =</span> cols,<span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">12</span>,<span class="dv">13</span>),<span class="at">xlab=</span><span class="st">&quot;Listener&quot;</span>)</span>
<span id="cb187-84"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-84" aria-hidden="true" tabindex="-1"></a><span class="fu">points</span> (listener_effects, <span class="at">cex=</span><span class="dv">2</span>, <span class="at">col =</span> cols, <span class="at">pch =</span> <span class="dv">4</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb187-85"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-85" aria-hidden="true" tabindex="-1"></a><span class="co">#bmmb::brmplot (qq, col = cols,ylim=c(-12,13))</span></span>
<span id="cb187-86"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-86" aria-hidden="true" tabindex="-1"></a><span class="co">#points (listener_effects, cex=2, col = cols, pch = 4,lwd=2)</span></span>
<span id="cb187-87"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-88"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-88" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side=</span><span class="dv">2</span>,<span class="at">text=</span><span class="st">&quot;Centimeters&quot;</span>, <span class="at">outer =</span> <span class="cn">TRUE</span>, <span class="at">line=</span><span class="dv">0</span>, <span class="at">adj =</span> <span class="fl">0.6</span>)</span>
<span id="cb187-89"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-90"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-90" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################</span></span>
<span id="cb187-91"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-91" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.7</span></span>
<span id="cb187-92"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-92" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################</span></span>
<span id="cb187-93"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-94"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-94" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="fl">4.2</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb187-95"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-95" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dnorm</span> (x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">col =</span> <span class="dv">2</span>,<span class="at">lwd=</span><span class="dv">3</span>, </span>
<span id="cb187-96"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-96" aria-hidden="true" tabindex="-1"></a>       <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>,<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.45</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>,<span class="dv">6</span>),<span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>,<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-97"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-97" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>deeppurple)</span>
<span id="cb187-98"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-98" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">5</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>skyblue)</span>
<span id="cb187-99"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-99" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">15</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>deepgreen)</span>
<span id="cb187-100"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-100" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">50</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>darkorange)</span>
<span id="cb187-101"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-101" aria-hidden="true" tabindex="-1"></a><span class="co">#abline (h = 1/10^seq(1,5,1),lty=3,col=&#39;grey&#39;)</span></span>
<span id="cb187-102"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-103"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-103" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span> (<span class="dv">2</span>,.<span class="dv">4</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;1&quot;</span>,<span class="st">&quot;5&quot;</span>,<span class="st">&quot;15&quot;</span>,<span class="st">&quot;50&quot;</span>,<span class="st">&quot;\u221E&quot;</span>),<span class="at">bty=</span><span class="st">&#39;n&#39;</span>,<span class="at">title=</span><span class="st">&#39;d.f.&#39;</span>,<span class="at">lwd=</span><span class="dv">3</span>,</span>
<span id="cb187-104"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-104" aria-hidden="true" tabindex="-1"></a>        <span class="at">col=</span><span class="fu">c</span>(deeppurple,skyblue,deepgreen,darkorange,<span class="st">&quot;red&quot;</span>),<span class="at">cex=</span><span class="fl">1.2</span>)</span>
<span id="cb187-105"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-106"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-106" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dnorm</span> (x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">col =</span> <span class="dv">2</span>,<span class="at">lwd=</span><span class="dv">3</span>, </span>
<span id="cb187-107"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-107" aria-hidden="true" tabindex="-1"></a>       <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>,<span class="at">log=</span><span class="st">&#39;y&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.001</span>,.<span class="dv">6</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>,<span class="dv">3</span>),</span>
<span id="cb187-108"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-108" aria-hidden="true" tabindex="-1"></a>       <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">ylab=</span><span class="st">&quot;Log Density&quot;</span>,<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-109"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-109" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>deeppurple)</span>
<span id="cb187-110"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-110" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">5</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>skyblue)</span>
<span id="cb187-111"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-111" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">15</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">col=</span>deepgreen)</span>
<span id="cb187-112"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-112" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">50</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>darkorange)</span>
<span id="cb187-113"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-113" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>,<span class="dv">1</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>)</span>
<span id="cb187-114"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-114" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">v =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>,<span class="dv">7</span>,<span class="dv">1</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>)</span>
<span id="cb187-115"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-116"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-116" aria-hidden="true" tabindex="-1"></a>lab <span class="ot">=</span> <span class="fu">expression</span>(<span class="dv">10</span><span class="sc">^-</span><span class="dv">1</span>)</span>
<span id="cb187-117"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-118"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-118" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">8</span>,<span class="sc">-</span><span class="dv">1</span>)){</span>
<span id="cb187-119"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-119" aria-hidden="true" tabindex="-1"></a>  lab[[<span class="dv">1</span>]][[<span class="dv">3</span>]] <span class="ot">=</span> i</span>
<span id="cb187-120"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-120" aria-hidden="true" tabindex="-1"></a>  <span class="fu">axis</span> (<span class="at">side=</span><span class="dv">2</span>, <span class="at">at =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">10</span><span class="sc">^-</span>i), <span class="at">labels =</span> lab, <span class="at">las=</span><span class="dv">2</span>)</span>
<span id="cb187-121"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-121" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb187-122"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-123"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-123" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dnorm</span> (x, <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">col =</span> <span class="dv">2</span>,<span class="at">lwd=</span><span class="dv">3</span>, </span>
<span id="cb187-124"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-124" aria-hidden="true" tabindex="-1"></a>       <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>,<span class="at">log=</span><span class="st">&#39;y&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.000000001</span>,.<span class="dv">6</span>), </span>
<span id="cb187-125"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-125" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">6</span>,<span class="dv">6</span>), <span class="at">yaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">ylab=</span><span class="st">&quot;Log Density&quot;</span>,<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-126"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-126" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">1</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>deeppurple)</span>
<span id="cb187-127"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-127" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">5</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>skyblue)</span>
<span id="cb187-128"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-128" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">15</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>,<span class="at">col=</span>deepgreen)</span>
<span id="cb187-129"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-129" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dt</span> (x, <span class="dv">50</span>), <span class="at">from =</span> <span class="sc">-</span><span class="dv">7</span>, <span class="at">to =</span> <span class="dv">7</span>, <span class="at">add =</span> <span class="cn">TRUE</span>, <span class="at">lwd=</span><span class="dv">3</span>, <span class="at">col=</span>darkorange)</span>
<span id="cb187-130"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-130" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">9</span>,<span class="dv">1</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>)</span>
<span id="cb187-131"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-131" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">v =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>,<span class="dv">7</span>,<span class="dv">1</span>),<span class="at">lty=</span><span class="dv">3</span>,<span class="at">col=</span><span class="st">&#39;grey&#39;</span>)</span>
<span id="cb187-132"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-133"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-133" aria-hidden="true" tabindex="-1"></a>lab <span class="ot">=</span> <span class="fu">expression</span>(<span class="dv">10</span><span class="sc">^-</span><span class="dv">1</span>)</span>
<span id="cb187-134"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-135"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-135" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="sc">-</span><span class="dv">8</span>,<span class="sc">-</span><span class="dv">2</span>)){</span>
<span id="cb187-136"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-136" aria-hidden="true" tabindex="-1"></a>  lab[[<span class="dv">1</span>]][[<span class="dv">3</span>]] <span class="ot">=</span> i</span>
<span id="cb187-137"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-137" aria-hidden="true" tabindex="-1"></a>  <span class="fu">axis</span> (<span class="at">side=</span><span class="dv">2</span>, <span class="at">at =</span> <span class="dv">1</span><span class="sc">/</span>(<span class="dv">10</span><span class="sc">^-</span>i), <span class="at">labels =</span> lab, <span class="at">las=</span><span class="dv">2</span>)</span>
<span id="cb187-138"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-138" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb187-139"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-140"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-140" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-141"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-141" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.8</span></span>
<span id="cb187-142"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-142" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-143"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-144"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-144" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">4</span>,<span class="fl">4.2</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb187-145"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-145" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dgamma</span>(x,<span class="dv">2</span>,<span class="fl">0.1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">250</span>), <span class="at">xaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb187-146"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-146" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">4</span>, <span class="at">col =</span> maroon, <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.045</span>),<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-147"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-147" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dgamma</span>(x,<span class="dv">2</span>,<span class="fl">0.1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">250</span>), <span class="at">log=</span><span class="st">&#39;y&#39;</span>, <span class="at">xaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;Log Density&quot;</span>,</span>
<span id="cb187-148"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-148" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">lwd=</span><span class="dv">4</span>, <span class="at">col =</span> lavender, <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">10</span><span class="sc">^-</span><span class="dv">7</span>,<span class="fl">0.05</span>),<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-149"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-149" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dgamma</span>(x,<span class="dv">2</span>,<span class="fl">0.02</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">250</span>), <span class="at">xaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;Density&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,</span>
<span id="cb187-150"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-150" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd=</span><span class="dv">4</span>, <span class="at">col =</span> maroon, <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.015</span>),<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-151"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-151" aria-hidden="true" tabindex="-1"></a><span class="fu">curve</span> (<span class="fu">dgamma</span>(x,<span class="dv">2</span>,<span class="fl">0.02</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">250</span>), <span class="at">log=</span><span class="st">&#39;y&#39;</span>, <span class="at">xaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylab=</span><span class="st">&quot;Log Density&quot;</span>,</span>
<span id="cb187-152"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-152" aria-hidden="true" tabindex="-1"></a>       <span class="at">xlab=</span><span class="st">&quot;&quot;</span>, <span class="at">lwd=</span><span class="dv">4</span>, <span class="at">col =</span> lavender, <span class="at">yaxs=</span><span class="st">&#39;i&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">10</span><span class="sc">^-</span><span class="dv">7</span>,<span class="fl">0.05</span>),<span class="at">cex.lab=</span><span class="fl">1.4</span>)</span>
<span id="cb187-153"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-154"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-154" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-155"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-155" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.9</span></span>
<span id="cb187-156"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-156" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-157"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-158"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-158" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,.<span class="dv">5</span>,.<span class="dv">1</span>), <span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb187-159"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-159" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height_rep_1 <span class="sc">~</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,</span>
<span id="cb187-160"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-160" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span>bmmb<span class="sc">::</span>cols,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb187-161"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-161" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Intercept + error&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-162"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-162" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-163"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-164"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-164" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height_rep_2 <span class="sc">~</span> A <span class="sc">+</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,</span>
<span id="cb187-165"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-165" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span>bmmb<span class="sc">::</span>cols,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb187-166"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-166" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-167"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-167" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Intercept + A&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-168"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-169"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-169" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height_rep_3 <span class="sc">~</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,</span>
<span id="cb187-170"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-170" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span>bmmb<span class="sc">::</span>cols,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb187-171"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-171" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-172"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-172" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Intercept + L&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-173"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-174"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-174" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height_rep_4 <span class="sc">~</span> A <span class="sc">+</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,</span>
<span id="cb187-175"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-175" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span><span class="fu">rep</span>(bmmb<span class="sc">::</span>cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb187-176"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-176" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Intercept + A + error&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-177"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-177" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-178"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-179"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-179" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height_rep_5 <span class="sc">~</span> A <span class="sc">+</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,</span>
<span id="cb187-180"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-180" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span><span class="fu">rep</span>(bmmb<span class="sc">::</span>cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb187-181"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-181" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-182"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-182" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Intercept + A + L + error&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-183"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-184"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-184" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A <span class="sc">+</span> L, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">200</span>),<span class="at">xaxt=</span><span class="st">&#39;n&#39;</span>,<span class="at">data =</span> notmen,</span>
<span id="cb187-185"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-185" aria-hidden="true" tabindex="-1"></a>         <span class="at">col=</span><span class="fu">rep</span>(bmmb<span class="sc">::</span>cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>)</span>
<span id="cb187-186"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-186" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h=</span><span class="dv">229</span>,<span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb187-187"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-187" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span> (<span class="dv">1</span>, <span class="dv">105</span>, <span class="at">label =</span> <span class="st">&quot;Real Data&quot;</span>, <span class="at">cex =</span> <span class="fl">1.25</span>,<span class="at">pos=</span><span class="dv">4</span>)</span>
<span id="cb187-188"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-189"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-189" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side=</span><span class="dv">2</span>,<span class="at">text=</span><span class="st">&quot;Apparent height (cm)&quot;</span>, <span class="at">outer =</span> <span class="cn">TRUE</span>, <span class="at">line=</span><span class="fl">2.1</span>, <span class="at">cex=</span><span class="fl">0.9</span>)</span>
<span id="cb187-190"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-191"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-191" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-192"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-192" aria-hidden="true" tabindex="-1"></a><span class="do">### Figure 5.10</span></span>
<span id="cb187-193"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-193" aria-hidden="true" tabindex="-1"></a><span class="do">################################################################################</span></span>
<span id="cb187-194"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-195"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-195" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span> (<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">mar =</span> <span class="fu">c</span>(<span class="fl">4.1</span>,.<span class="dv">1</span>,.<span class="dv">5</span>,.<span class="dv">1</span>),<span class="at">oma =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">4</span>,<span class="dv">0</span>,.<span class="dv">50</span>)); <span class="fu">layout</span> (<span class="at">mat =</span> <span class="fu">t</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>)), <span class="at">widths =</span> <span class="fu">c</span>(.<span class="dv">2</span>,.<span class="dv">8</span>))</span>
<span id="cb187-196"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-197"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-197" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">c</span>(beige,lightpink),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>), <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb187-198"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-198" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side=</span><span class="dv">1</span>, <span class="st">&quot;Apparent Age Group&quot;</span>, <span class="at">line=</span><span class="dv">3</span>)</span>
<span id="cb187-199"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-199" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fu">c</span>(<span class="fl">155.3</span>,<span class="fl">155.3+8.8</span>,<span class="fl">155.3-8.8</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">3</span>))</span>
<span id="cb187-200"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-200" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">c</span>(beige,lightpink),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>), <span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">add=</span><span class="cn">TRUE</span>)</span>
<span id="cb187-201"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb187-202"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-202" aria-hidden="true" tabindex="-1"></a><span class="fu">mtext</span> (<span class="at">side =</span> <span class="dv">2</span>, <span class="at">outer =</span> <span class="cn">FALSE</span>, <span class="st">&quot;Apparent height (cm)&quot;</span>, <span class="at">line =</span> <span class="fl">2.75</span>)</span>
<span id="cb187-203"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-203" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A<span class="sc">+</span>L, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">rep</span>(cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>),</span>
<span id="cb187-204"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-204" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Listener&quot;</span>)</span>
<span id="cb187-205"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-205" aria-hidden="true" tabindex="-1"></a><span class="fu">axis</span> (<span class="at">side=</span><span class="dv">1</span>, <span class="at">at =</span> <span class="fu">seq</span>(<span class="fl">1.5</span>,<span class="fl">30.5</span>,<span class="dv">2</span>), <span class="dv">1</span><span class="sc">:</span><span class="dv">15</span>)</span>
<span id="cb187-206"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-206" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span> (<span class="at">h =</span> <span class="fu">c</span>(<span class="fl">155.3</span>,<span class="fl">155.3+8.8</span>,<span class="fl">155.3-8.8</span>), <span class="at">lwd =</span> <span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="at">col =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">4</span>,<span class="dv">3</span>))</span>
<span id="cb187-207"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-207" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span> (height <span class="sc">~</span> A<span class="sc">+</span>L, <span class="at">data=</span>notmen, <span class="at">col =</span> <span class="fu">rep</span>(cols,<span class="at">each=</span><span class="dv">2</span>),<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">103</span>,<span class="dv">185</span>),</span>
<span id="cb187-208"><a href="comparing-two-groups-of-observations-factors-and-contrasts.html#cb187-208" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Listener&quot;</span>, <span class="at">add =</span> <span class="cn">TRUE</span>)</span></code></pre></div>

<div style="page-break-after: always;"></div>
</div>
</div>
<!-- Default Statcounter code for statsbook
https://santiagobarreda.github.io/stats-class/ -->
<script type="text/javascript">
var sc_project=12454226; 
var sc_invisible=1; 
var sc_security="a1959418"; 
</script>
<script type="text/javascript"
src="https://www.statcounter.com/counter/counter.js"
async></script>
<noscript><div class="statcounter"><a title="Web Analytics"
href="https://statcounter.com/" target="_blank"><img
class="statcounter"
src="https://c.statcounter.com/12454226/0/a1959418/1/"
alt="Web Analytics"></a></div></noscript>
<!-- End of Statcounter Code -->
            </section>

          </div>
        </div>
      </div>
<a href="inspecting-a-single-group-of-observations-using-a-bayesian-multilevel-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="variation-in-parameters-random-effects-and-model-comparison.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
